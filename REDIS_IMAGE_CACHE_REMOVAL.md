# âœ… Redis Image Hash Cache ì œê±° í™•ì¸

**ë‚ ì§œ**: 2025-11-06  
**ë¸Œëœì¹˜**: feature/cdn-image-caching  
**ìƒíƒœ**: âœ… ì œê±° ì™„ë£Œ

---

## ğŸ“‹ Redis DB ì‚¬ìš© í˜„í™©

### âŒ Redis DB 1: Image Hash Cache (ì œê±°ë¨)

**ì œê±° ì´ìœ **:
- CloudFront CDNì´ ì´ë¯¸ì§€ íŒŒì¼ ìì²´ë¥¼ Edge Locationì—ì„œ ìºì‹±
- pHash ê³„ì‚°ì„ ìœ„í•´ ì „ì²´ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œê°€ í•„ìš”í–ˆë˜ ë¹„íš¨ìœ¨ì„± í•´ê²°
- Redis ë©”ëª¨ë¦¬ ì ˆì•½
- ì•„í‚¤í…ì²˜ ë‹¨ìˆœí™”

**ì œê±°ëœ ì½”ë“œ**:
```python
# âŒ ì œê±°ë¨
cache_key = f"cache:image:hash:{phash}"
cached = redis_cache.get(cache_key)  # Redis DB 1

if cached:
    return json.loads(cached)

redis_cache.setex(cache_key, 86400 * 7, json.dumps(result))
```

---

### âœ… ê³„ì† ì‚¬ìš©ë˜ëŠ” Redis DB

#### Redis DB 0: Celery Result Backend
- ìš©ë„: Celery ì‘ì—… ê²°ê³¼ ì €ì¥
- ë³´ì¡´: âœ… ìœ ì§€
- TTL: 24ì‹œê°„

#### Redis DB 2: Job Progress Tracking
- ìš©ë„: ì‹¤ì‹œê°„ ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
- ë³´ì¡´: âœ… ìœ ì§€
- TTL: 1ì‹œê°„
- ì˜ˆì‹œ:
  ```python
  redis_progress.setex(
      f"job:{job_id}:progress",
      3600,
      json.dumps({
          "progress": 70,
          "message": "AI ë¶„ì„ ì¤‘...",
          "updated_at": "2025-11-06T15:30:00Z"
      })
  )
  ```

#### Redis DB 3: Session Store
- ìš©ë„: ì‚¬ìš©ì ì„¸ì…˜ ê´€ë¦¬
- ë³´ì¡´: âœ… ìœ ì§€
- TTL: 7ì¼

---

## ğŸ”„ ìƒˆë¡œìš´ ìºì‹± ì „ëµ

### CloudFront CDN ìºì‹±
- **ìœ„ì¹˜**: AWS Edge Location (ì „ ì„¸ê³„)
- **ëŒ€ìƒ**: ì´ë¯¸ì§€ íŒŒì¼ ìì²´
- **TTL**: 24ì‹œê°„ (default), ìµœëŒ€ 7ì¼
- **íˆíŠ¸ìœ¨**: 50-70% ì˜ˆìƒ
- **ì¥ì **:
  - Workerì™€ Frontend ëª¨ë‘ ë¹ ë¥¸ ì´ë¯¸ì§€ ë¡œë“œ
  - pHash ê³„ì‚° ë¶ˆí•„ìš”
  - ê¸€ë¡œë²Œ í™•ì¥ì„±

### job_id ê¸°ë°˜ ê²°ê³¼ ìºì‹± (ì„ íƒì‚¬í•­)
- **ìœ„ì¹˜**: Redis DB 2 (ê¸°ì¡´ Progress DB í™œìš©)
- **ëŒ€ìƒ**: AI ë¶„ì„ ê²°ê³¼
- **TTL**: 7ì¼
- **ì¥ì **:
  - ê°™ì€ job_id ì¬ì¡°íšŒ ì‹œ AI API í˜¸ì¶œ ìƒëµ
  - 70% AI ë¹„ìš© ì ˆê° ìœ ì§€ ê°€ëŠ¥

---

## ğŸ“Š ë¬¸ì„œ ì—…ë°ì´íŠ¸ ìƒíƒœ

### âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ
- `CDN_S3_ARCHITECTURE_DESIGN.md` - Redis ìºì‹± ì œê±° ëª…ì‹œ

### âš ï¸ ì—…ë°ì´íŠ¸ í•„ìš” (Backend ì €ì¥ì†Œ)
ë‹¤ìŒ ë¬¸ì„œë“¤ì€ Backend ì €ì¥ì†Œì—ì„œ ì—…ë°ì´íŠ¸ í•„ìš”:

1. `docs/architecture/image-processing-architecture.md`
   - Redis DB 1 ì°¸ì¡° ì œê±°
   - CDN ê¸°ë°˜ ì•„í‚¤í…ì²˜ë¡œ ë³€ê²½

2. `docs/infrastructure/redis-configuration.md`
   - DB 1: Image Hash Cache ì„¹ì…˜ ì œê±°
   - DB ì‚¬ìš© í˜„í™© ì—…ë°ì´íŠ¸

3. `ansible/roles/redis/tasks/main.yml`
   - DB 1 ê´€ë ¨ ì½”ë©˜íŠ¸ ì œê±°

---

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„ (Backend PR)

### Phase 1: Worker ì½”ë“œ ë³€ê²½
```python
# workers/vision_worker.py

# âŒ ì œê±°: pHash ê³„ì‚° ë° Redis DB 1 ìºì‹±
# âœ… ì¶”ê°€: CDNì—ì„œ ì´ë¯¸ì§€ ë¡œë“œ

def analyze_image(job_id):
    # 1. CDNì—ì„œ ì´ë¯¸ì§€ ë¡œë“œ
    cdn_url = f"{settings.CDN_BASE_URL}/{job_id}.jpg"
    image_data = requests.get(cdn_url).content
    
    # 2. AI ë¶„ì„ (pHash ê³„ì‚° ì œê±°!)
    result = analyze_with_gpt4o_vision(image_data)
    
    return result
```

### Phase 2: API ì‘ë‹µ ë³€ê²½
```python
# api/v1/waste/analyze

@app.post("/api/v1/waste/analyze")
async def create_analysis():
    job_id = str(uuid.uuid4())
    
    # Presigned URL (ì—…ë¡œë“œìš©)
    upload_url = s3.generate_presigned_url(...)
    
    # CDN URL (ë‹¤ìš´ë¡œë“œ/í‘œì‹œìš©) - ì‹ ê·œ!
    cdn_url = f"https://images.growbin.app/{job_id}.jpg"
    
    return {
        "job_id": job_id,
        "upload_url": upload_url,
        "image_url": cdn_url  # â† ì‹ ê·œ!
    }
```

### Phase 3: ì˜ì¡´ì„± ì œê±°
```bash
# requirements.txt
# âŒ ì œê±°
imagehash==4.3.1
```

---

## âœ… ê²°ë¡ 

**Redis DB 1 (Image Hash Cache) ì œê±° ì™„ë£Œ!**

- âœ… CloudFront CDNìœ¼ë¡œ ëŒ€ì²´
- âœ… ì•„í‚¤í…ì²˜ ë‹¨ìˆœí™”
- âœ… pHash ê³„ì‚° ì œê±°
- âœ… Redis ë©”ëª¨ë¦¬ ì ˆì•½
- âœ… ê¸€ë¡œë²Œ í™•ì¥ì„± í™•ë³´

**ë‹¤ìŒ ì‘ì—…**: Backend ì €ì¥ì†Œì—ì„œ Worker ì½”ë“œ ë° ë¬¸ì„œ ì—…ë°ì´íŠ¸

---

**ì‘ì„±ì¼**: 2025-11-06  
**ì‘ì„±ì**: AI Assistant


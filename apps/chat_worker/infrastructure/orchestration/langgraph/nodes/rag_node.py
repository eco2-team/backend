"""RAG Node - LangGraph ì–´ëŒ‘í„°.

ì–‡ì€ ì–´ëŒ‘í„°: state ë³€í™˜ + Command í˜¸ì¶œ + progress notify (UX).
ì •ì±…/íë¦„ì€ SearchRAGCommand(Application)ì—ì„œ ì²˜ë¦¬.

Clean Architecture:
- Node(Adapter): ì´ íŒŒì¼ - LangGraph glue code
- Command(UseCase): SearchRAGCommand - ì •ì±…/íë¦„
- Service: RAGSearcherService - ìˆœìˆ˜ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
"""

from __future__ import annotations

import logging
from typing import TYPE_CHECKING, Any

from chat_worker.application.commands import (
    SearchRAGCommand,
    SearchRAGInput,
)
from chat_worker.infrastructure.orchestration.langgraph.nodes.node_executor import (
    NodeExecutor,
)

if TYPE_CHECKING:
    from chat_worker.application.ports.events import ProgressNotifierPort
    from chat_worker.application.ports.retrieval import RetrieverPort

logger = logging.getLogger(__name__)


def create_rag_node(
    retriever: "RetrieverPort",
    event_publisher: "ProgressNotifierPort",
):
    """RAG ë…¸ë“œ íŒ©í† ë¦¬.

    NodeëŠ” LangGraph ì–´ëŒ‘í„°:
    - state â†’ input DTO ë³€í™˜
    - Command(UseCase) í˜¸ì¶œ
    - output â†’ state ë³€í™˜
    - progress notify (UX)

    Args:
        retriever: ê²€ìƒ‰ Port
        event_publisher: ì§„í–‰ë¥  ì´ë²¤íŠ¸ ë°œí–‰ì (UX)

    Returns:
        rag_node í•¨ìˆ˜
    """
    # Command(UseCase) ì¸ìŠ¤í„´ìŠ¤ ìƒì„± - Port ì¡°ë¦½
    command = SearchRAGCommand(retriever=retriever)

    async def _rag_node_inner(state: dict[str, Any]) -> dict[str, Any]:
        """ì‹¤ì œ ë…¸ë“œ ë¡œì§ (NodeExecutorê°€ ë˜í•‘).

        ì—­í• :
        1. stateì—ì„œ ê°’ ì¶”ì¶œ (LangGraph glue)
        2. Command í˜¸ì¶œ (ì •ì±…/íë¦„ ìœ„ì„)
        3. output â†’ state ë³€í™˜

        Args:
            state: í˜„ì¬ LangGraph ìƒíƒœ

        Returns:
            ì—…ë°ì´íŠ¸ëœ ìƒíƒœ
        """
        job_id = state["job_id"]

        # Progress: ì‹œì‘ (UX)
        await event_publisher.notify_stage(
            task_id=job_id,
            stage="rag",
            status="started",
            progress=40,
            message="ğŸ“š ê·œì • ê²€ìƒ‰ ì¤‘...",
        )

        try:
            # 1. state â†’ input DTO ë³€í™˜
            input_dto = SearchRAGInput(
                job_id=job_id,
                message=state.get("message", ""),
                classification=state.get("classification_result"),
            )

            # 2. Command ì‹¤í–‰ (ì •ì±…/íë¦„ì€ Commandì—ì„œ)
            output = await command.execute(input_dto)

            # 3. output â†’ state ë³€í™˜
            state_update = {
                **state,
                "disposal_rules": output.disposal_rules,
            }

            # Progress: ì™„ë£Œ (UX)
            await event_publisher.notify_stage(
                task_id=job_id,
                stage="rag",
                status="completed",
                progress=60,
                result={
                    "found": output.found,
                    "method": output.search_method,
                },
            )

            return state_update

        except Exception as e:
            logger.error(f"RAG node failed: {e}", extra={"job_id": job_id})
            await event_publisher.notify_stage(
                task_id=job_id,
                stage="rag",
                status="failed",
                result={"error": str(e)},
            )
            return {**state, "disposal_rules": None}

    # NodeExecutorë¡œ ë˜í•‘ (Policy ì ìš©: timeout, retry, circuit breaker)
    executor = NodeExecutor.get_instance()

    async def rag_node(state: dict[str, Any]) -> dict[str, Any]:
        """LangGraph ë…¸ë“œ (Policy ì ìš©ë¨).

        NodeExecutorê°€ ë‹¤ìŒì„ ì²˜ë¦¬:
        - Circuit Breaker í™•ì¸
        - Timeout ì ìš© (1000ms)
        - Retry (1íšŒ)
        - FAIL_FALLBACK ì²˜ë¦¬ (ì‹¤íŒ¨ ì‹œ LLM ì§ì ‘ ì‘ë‹µ)
        """
        return await executor.execute(
            node_name="waste_rag",
            node_func=_rag_node_inner,
            state=state,
        )

    return rag_node

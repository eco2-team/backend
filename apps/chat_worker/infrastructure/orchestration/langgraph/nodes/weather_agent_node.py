"""Weather Agent Node - LLM with Weather/Geocoding Tools.

LLMì´ ë‚ ì”¨ APIì™€ Geocoding APIë¥¼ Toolë¡œ ì‚¬ìš©í•˜ì—¬ ë‚ ì”¨ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ì—ì´ì „íŠ¸ ë…¸ë“œ.

Architecture:
- LLMì´ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ Tool ì„ íƒ
- Tool ì‹¤í–‰ ê²°ê³¼ë¥¼ LLMì´ í•´ì„í•˜ì—¬ ìì—°ì–´ ì‘ë‹µ ìƒì„±
- OpenAI/Gemini ëª¨ë‘ ì§€ì› (Function Calling)

Tools:
- get_weather: ì¢Œí‘œ ê¸°ë°˜ ë‚ ì”¨ ì¡°íšŒ
- geocode: ì¥ì†Œëª…ì„ ì¢Œí‘œë¡œ ë³€í™˜

Flow:
    Router â†’ weather_agent â†’ Answer
             â””â”€ LLM analyzes message
             â””â”€ LLM calls tools (Weather/Kakao API)
             â””â”€ LLM generates weather summary with tips
             â””â”€ Returns weather_context
"""

from __future__ import annotations

import asyncio
import json
import logging
from dataclasses import dataclass
from enum import Enum
from typing import TYPE_CHECKING, Any

from chat_worker.application.services.weather_service import WeatherService
from chat_worker.infrastructure.orchestration.langgraph.context_helper import (
    create_context,
    create_error_context,
)

if TYPE_CHECKING:
    from chat_worker.application.ports.events import ProgressNotifierPort
    from chat_worker.application.ports.kakao_local_client import KakaoLocalClientPort
    from chat_worker.application.ports.weather_client import WeatherClientPort

logger = logging.getLogger(__name__)


# ============================================================
# Tool Definitions
# ============================================================


class ToolName(str, Enum):
    """ì‚¬ìš© ê°€ëŠ¥í•œ Tool ì´ë¦„."""

    GET_WEATHER = "get_weather"
    GEOCODE = "geocode"


# ============================================================
# OpenAI Function Calling Tools (GPT-5.2 Strict Mode)
# ============================================================
# Best Practices Applied (2026):
# 1. Prescriptive descriptions (WHEN to use, not just what)
# 2. Front-load key rules and requirements
# 3. Include usage criteria and edge cases
# 4. Strict mode enabled for schema validation (GPT-5.2 í•„ìˆ˜ ê¶Œì¥)
# Reference: https://cookbook.openai.com/examples/gpt-5/gpt-5-1_prompting_guide

OPENAI_TOOLS = [
    {
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": (
                "ì¢Œí‘œ ê¸°ë°˜ í˜„ì¬ ë‚ ì”¨ ì¡°íšŒ. "
                "ì‚¬ìš© ì‹œì : ì‚¬ìš©ìê°€ ë‚ ì”¨ ì •ë³´ë¥¼ ìš”ì²­í•˜ê³  ì¢Œí‘œê°€ ìˆì„ ë•Œ í˜¸ì¶œ. "
                "ë°˜í™˜ê°’: ê¸°ì˜¨, ìŠµë„, ê°•ìˆ˜í˜•íƒœ, ë‚ ì”¨ íŒ í¬í•¨. "
                "ì£¼ì˜: ì¢Œí‘œ ì—†ì´ í˜¸ì¶œ ë¶ˆê°€. ì‚¬ìš©ìê°€ 'ê°•ë‚¨ì—­ ë‚ ì”¨'ë¼ê³  í•˜ë©´ "
                "ë¨¼ì € geocodeë¡œ 'ê°•ë‚¨ì—­' ì¢Œí‘œë¥¼ ì–»ì€ í›„ ì´ í•¨ìˆ˜ í˜¸ì¶œ. "
                "ì‚¬ìš©ì ìœ„ì¹˜(user_location)ê°€ ì´ë¯¸ ìˆìœ¼ë©´ ë°”ë¡œ í˜¸ì¶œ ê°€ëŠ¥."
            ),
            "parameters": {
                "type": "object",
                "properties": {
                    "latitude": {
                        "type": "number",
                        "description": "ìœ„ë„. í•„ìˆ˜. ë²”ìœ„: 33.0~43.0 (í•œêµ­)",
                    },
                    "longitude": {
                        "type": "number",
                        "description": "ê²½ë„. í•„ìˆ˜. ë²”ìœ„: 124.0~132.0 (í•œêµ­)",
                    },
                    "waste_category": {
                        "type": "string",
                        "description": (
                            "íê¸°ë¬¼ ì¹´í…Œê³ ë¦¬ (ë‚ ì”¨ íŒ ë§ì¶¤ìš©, ì„ íƒ). "
                            "ì˜ˆ: 'paper', 'plastic', 'food', 'general'. "
                            "ë¶„ë¦¬ë°°ì¶œ ê´€ë ¨ ì§ˆë¬¸ì´ë©´ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ ì „ë‹¬."
                        ),
                    },
                },
                "required": ["latitude", "longitude"],
                "additionalProperties": False,
            },
            "strict": True,
        },
    },
    {
        "type": "function",
        "function": {
            "name": "geocode",
            "description": (
                "ì¥ì†Œëª…/ì£¼ì†Œë¥¼ ì¢Œí‘œ(ìœ„ë„, ê²½ë„)ë¡œ ë³€í™˜. "
                "ì‚¬ìš© ì‹œì : ì‚¬ìš©ìê°€ 'ê°•ë‚¨ì—­ ë‚ ì”¨', 'ì„œìš¸ ë‚ ì”¨' ë“± "
                "íŠ¹ì • ì§€ì—­ì„ ì–¸ê¸‰í–ˆìœ¼ë‚˜ ì¢Œí‘œê°€ ì—†ì„ ë•Œ ë¨¼ì € í˜¸ì¶œ. "
                "ì‹¤í–‰ ìˆœì„œ: ì´ í•¨ìˆ˜ë¡œ ì¢Œí‘œë¥¼ ë¨¼ì € ì–»ì€ í›„ get_weather í˜¸ì¶œ. "
                "ì£¼ì˜: ì‚¬ìš©ì ìœ„ì¹˜(user_location)ê°€ ì´ë¯¸ ìˆìœ¼ë©´ í˜¸ì¶œ ë¶ˆí•„ìš”."
            ),
            "parameters": {
                "type": "object",
                "properties": {
                    "place_name": {
                        "type": "string",
                        "description": (
                            "ì¢Œí‘œë¡œ ë³€í™˜í•  ì¥ì†Œëª… ë˜ëŠ” ì£¼ì†Œ. "
                            "ì˜ˆ: 'ê°•ë‚¨ì—­', 'í™ëŒ€ì…êµ¬ì—­', 'ì„œìš¸ì‹œ ê°•ë‚¨êµ¬', 'ë¶€ì‚° í•´ìš´ëŒ€'. "
                            "ê°€ëŠ¥í•œ êµ¬ì²´ì ìœ¼ë¡œ ì…ë ¥."
                        ),
                    },
                },
                "required": ["place_name"],
                "additionalProperties": False,
            },
            "strict": True,
        },
    },
]

# ============================================================
# Gemini Function Calling Tools (Gemini 3)
# ============================================================
# Best Practices Applied (2026):
# 1. Clear, prescriptive descriptions
# 2. Strong-typed parameters
# 3. Parallel & Compositional function calling ì§€ì›
# Reference: https://ai.google.dev/gemini-api/docs/function-calling

GEMINI_TOOLS = [
    {
        "name": "get_weather",
        "description": (
            "ì¢Œí‘œ ê¸°ë°˜ í˜„ì¬ ë‚ ì”¨ ì¡°íšŒ. "
            "ì‚¬ìš© ì‹œì : ì‚¬ìš©ìê°€ ë‚ ì”¨ ì •ë³´ë¥¼ ìš”ì²­í•˜ê³  ì¢Œí‘œê°€ ìˆì„ ë•Œ í˜¸ì¶œ. "
            "ë°˜í™˜ê°’: ê¸°ì˜¨, ìŠµë„, ê°•ìˆ˜í˜•íƒœ, ë‚ ì”¨ íŒ í¬í•¨. "
            "ì£¼ì˜: ì¢Œí‘œ ì—†ì´ í˜¸ì¶œ ë¶ˆê°€. ì‚¬ìš©ìê°€ 'ê°•ë‚¨ì—­ ë‚ ì”¨'ë¼ê³  í•˜ë©´ "
            "ë¨¼ì € geocodeë¡œ 'ê°•ë‚¨ì—­' ì¢Œí‘œë¥¼ ì–»ì€ í›„ ì´ í•¨ìˆ˜ í˜¸ì¶œ."
        ),
        "parameters": {
            "type": "object",
            "properties": {
                "latitude": {
                    "type": "number",
                    "description": "ìœ„ë„. í•„ìˆ˜. ë²”ìœ„: 33.0~43.0 (í•œêµ­)",
                },
                "longitude": {
                    "type": "number",
                    "description": "ê²½ë„. í•„ìˆ˜. ë²”ìœ„: 124.0~132.0 (í•œêµ­)",
                },
                "waste_category": {
                    "type": "string",
                    "description": "íê¸°ë¬¼ ì¹´í…Œê³ ë¦¬ (ë‚ ì”¨ íŒ ë§ì¶¤ìš©, ì„ íƒ). ì˜ˆ: 'paper', 'plastic', 'food'",
                },
            },
            "required": ["latitude", "longitude"],
        },
    },
    {
        "name": "geocode",
        "description": (
            "ì¥ì†Œëª…/ì£¼ì†Œë¥¼ ì¢Œí‘œ(ìœ„ë„, ê²½ë„)ë¡œ ë³€í™˜. "
            "ì‚¬ìš© ì‹œì : ì‚¬ìš©ìê°€ 'ê°•ë‚¨ì—­ ë‚ ì”¨', 'ì„œìš¸ ë‚ ì”¨' ë“± "
            "íŠ¹ì • ì§€ì—­ì„ ì–¸ê¸‰í–ˆìœ¼ë‚˜ ì¢Œí‘œê°€ ì—†ì„ ë•Œ ë¨¼ì € í˜¸ì¶œ. "
            "ì‹¤í–‰ ìˆœì„œ: ì´ í•¨ìˆ˜ë¡œ ì¢Œí‘œë¥¼ ë¨¼ì € ì–»ì€ í›„ get_weather í˜¸ì¶œ."
        ),
        "parameters": {
            "type": "object",
            "properties": {
                "place_name": {
                    "type": "string",
                    "description": (
                        "ì¢Œí‘œë¡œ ë³€í™˜í•  ì¥ì†Œëª… ë˜ëŠ” ì£¼ì†Œ. "
                        "ì˜ˆ: 'ê°•ë‚¨ì—­', 'í™ëŒ€ì…êµ¬ì—­', 'ì„œìš¸ì‹œ ê°•ë‚¨êµ¬', 'ë¶€ì‚° í•´ìš´ëŒ€'."
                    ),
                },
            },
            "required": ["place_name"],
        },
    },
]

# ============================================================
# System Prompt for Weather Agent
# ============================================================
# Best Practices Applied (2026 - GPT-5.2 CTCO Framework):
# 1. Context: ë°°ê²½ ì •ë³´
# 2. Task: ìˆ˜í–‰í•  ì‘ì—…
# 3. Constraints: DO/DON'T ëª…ì‹œ
# 4. Output: ì¶œë ¥ í˜•ì‹
# 5. Preambles: Tool í˜¸ì¶œ ì „ reasoning ì„¤ëª… (GPT-5.2)
# Reference: https://cookbook.openai.com/examples/gpt-5/gpt-5-1_prompting_guide

WEATHER_AGENT_SYSTEM_PROMPT = """# Context
ë‹¹ì‹ ì€ EcoÂ² ì•±ì˜ ë‚ ì”¨ ì •ë³´ ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì—ê²Œ ë‚ ì”¨ ì •ë³´ì™€ ë¶„ë¦¬ë°°ì¶œ ê´€ë ¨ ë‚ ì”¨ íŒì„ ì œê³µí•©ë‹ˆë‹¤.

# Scope Discipline
ì´ ì—ì´ì „íŠ¸ëŠ” get_weather, geocode ë„êµ¬ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
ë‹¤ë¥¸ ì‘ì—…(ì¥ì†Œ ê²€ìƒ‰, ëŒ€í˜•íê¸°ë¬¼ ì •ë³´ ë“±)ì€ ë„êµ¬ ì—†ì´ ì§ì ‘ ì‘ë‹µí•˜ì„¸ìš”.
ì ˆëŒ€ë¡œ ì •ì˜ë˜ì§€ ì•Šì€ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ê±°ë‚˜ ìƒˆë¡œìš´ ì‘ì—…ì„ ë§Œë“¤ì–´ë‚´ì§€ ë§ˆì„¸ìš”.

# Preambles (GPT-5.2)
ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ê¸° ì „ì—, ì™œ ê·¸ ë„êµ¬ë¥¼ í˜¸ì¶œí•˜ëŠ”ì§€ ê°„ë‹¨íˆ ì„¤ëª…í•˜ì„¸ìš”.
ì˜ˆ: "ê°•ë‚¨ì—­ ì¢Œí‘œë¥¼ ì–»ê¸° ìœ„í•´ geocodeë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤."

# Tool ì‚¬ìš© ê·œì¹™

## ì‚¬ìš© ì‹œì  (DO)
- ë‚ ì”¨ ì •ë³´ ìš”ì²­ + ì¢Œí‘œ ìˆìŒ â†’ get_weather
- ë‚ ì”¨ ì •ë³´ ìš”ì²­ + ì§€ì—­ëª… ì–¸ê¸‰ + ì¢Œí‘œ ì—†ìŒ â†’ geocode ë¨¼ì € í˜¸ì¶œ
- ë¶„ë¦¬ë°°ì¶œ ê´€ë ¨ ë‚ ì”¨ íŒ ìš”ì²­ â†’ get_weather (waste_category í¬í•¨)

## ì‚¬ìš© ê¸ˆì§€ (DON'T)
- ë¶„ë¦¬ë°°ì¶œ ë°©ë²• ì§ˆë¬¸ (ë‚ ì”¨ ë¬´ê´€) â†’ ë„êµ¬ ì‚¬ìš© X, ì§ì ‘ ë‹µë³€
- ì¼ë°˜ ëŒ€í™”, ì¸ì‚¬ â†’ ë„êµ¬ ì‚¬ìš© X
- ì´ë¯¸ ì¢Œí‘œê°€ ìˆëŠ”ë° geocode í˜¸ì¶œ X
- ì¥ì†Œ ê²€ìƒ‰, ëŒ€í˜•íê¸°ë¬¼ ì •ë³´ â†’ ë„êµ¬ ì‚¬ìš© X (ë²”ìœ„ ë°–)

# Tool í˜¸ì¶œ ìˆœì„œ (Critical)

"[ì§€ì—­ëª…] ë‚ ì”¨" íŒ¨í„´ (ì¢Œí‘œ ì—†ìŒ):
1. geocode(place_name="ì§€ì—­ëª…") â†’ ì¢Œí‘œ íšë“
2. get_weather(latitude=ê²°ê³¼lat, longitude=ê²°ê³¼lon)

"ë‚ ì”¨ ì•Œë ¤ì¤˜" íŒ¨í„´ (user_location ìˆìŒ):
1. get_weather(latitude=user_lat, longitude=user_lon)

"ë¹„ì˜¤ë©´ ì¢…ì´ ë²„ë ¤ë„ ë¼?" íŒ¨í„´:
1. geocode or use user_location
2. get_weather(latitude=lat, longitude=lon, waste_category="paper")

# íŒŒë¼ë¯¸í„° ê·œì¹™

- latitude/longitude: geocode ê²°ê³¼ ë˜ëŠ” user_location ì‚¬ìš©
- waste_category: ë¶„ë¦¬ë°°ì¶œ ê´€ë ¨ì´ë©´ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ (paper, plastic, food ë“±)

# ì—ëŸ¬ ì²˜ë¦¬

- geocode ì‹¤íŒ¨ â†’ "í•´ë‹¹ ì§€ì—­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§€ì—­ëª…ì„ ì•Œë ¤ì£¼ì„¸ìš”."
- get_weather ì‹¤íŒ¨ â†’ "ë‚ ì”¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
- ì¢Œí‘œ ì—†ì´ get_weather í˜¸ì¶œ ì‹œë„ â†’ í˜¸ì¶œí•˜ì§€ ë§ê³  ìœ„ì¹˜ ìš”ì²­

# ì‘ë‹µ í˜•ì‹

ë‚ ì”¨ ì •ë³´ê°€ ìˆìœ¼ë©´:
1. ê¸°ì˜¨, ìŠµë„, ê°•ìˆ˜í˜•íƒœ ìš”ì•½
2. ë‚ ì”¨ íŒ í¬í•¨ (ë¶„ë¦¬ë°°ì¶œ ê´€ë ¨ì´ë©´ ë§ì¶¤ íŒ)
3. ì´ëª¨ì§€ ì‚¬ìš© ê¶Œì¥ (â˜€ï¸ğŸŒ§ï¸â„ï¸)

ë‚ ì”¨ ì •ë³´ê°€ ì—†ìœ¼ë©´:
- ìœ„ì¹˜ ì •ë³´ ìš”ì²­ ë˜ëŠ” ëŒ€ì•ˆ ì œì‹œ"""


# ============================================================
# Tool Result Dataclass
# ============================================================


@dataclass
class ToolResult:
    """Tool ì‹¤í–‰ ê²°ê³¼."""

    tool_name: str
    success: bool
    data: dict[str, Any] | None = None
    error: str | None = None


# ============================================================
# Tool Executor
# ============================================================


class WeatherToolExecutor:
    """Weather API Tool ì‹¤í–‰ê¸°."""

    def __init__(
        self,
        weather_client: "WeatherClientPort",
        kakao_client: "KakaoLocalClientPort | None" = None,
    ):
        self._weather_client = weather_client
        self._kakao_client = kakao_client

    async def execute(
        self,
        tool_name: str,
        arguments: dict[str, Any],
    ) -> ToolResult:
        """Tool ì‹¤í–‰.

        Args:
            tool_name: Tool ì´ë¦„
            arguments: Tool ì¸ì

        Returns:
            ToolResult
        """
        try:
            if tool_name == ToolName.GET_WEATHER:
                return await self._get_weather(arguments)
            elif tool_name == ToolName.GEOCODE:
                return await self._geocode(arguments)
            else:
                return ToolResult(
                    tool_name=tool_name,
                    success=False,
                    error=f"Unknown tool: {tool_name}",
                )
        except Exception as e:
            logger.exception(f"Tool execution failed: {tool_name}")
            return ToolResult(
                tool_name=tool_name,
                success=False,
                error=str(e),
            )

    async def _get_weather(self, args: dict[str, Any]) -> ToolResult:
        """ë‚ ì”¨ ì¡°íšŒ."""
        lat = args.get("latitude")
        lon = args.get("longitude")
        waste_category = args.get("waste_category")

        if lat is None or lon is None:
            return ToolResult(
                tool_name=ToolName.GET_WEATHER,
                success=False,
                error="ë‚ ì”¨ ì¡°íšŒì—ëŠ” ì¢Œí‘œ(latitude, longitude)ê°€ í•„ìˆ˜ì…ë‹ˆë‹¤.",
            )

        # ìœ„ê²½ë„ â†’ ê²©ìì¢Œí‘œ ë³€í™˜ (WeatherService - ìˆœìˆ˜ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§)
        try:
            nx, ny = WeatherService.convert_to_grid(lat, lon)
        except Exception as e:
            return ToolResult(
                tool_name=ToolName.GET_WEATHER,
                success=False,
                error=f"ì¢Œí‘œ ë³€í™˜ ì‹¤íŒ¨: {e}",
            )

        # ë‚ ì”¨ API í˜¸ì¶œ
        response = await self._weather_client.get_current_weather(nx, ny)

        if not response.success:
            return ToolResult(
                tool_name=ToolName.GET_WEATHER,
                success=False,
                error=response.error_message or "ë‚ ì”¨ ì¡°íšŒ ì‹¤íŒ¨",
            )

        # ë‚ ì”¨ íŒ ìƒì„± (WeatherService - ìˆœìˆ˜ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§)
        tip = WeatherService.generate_weather_tip(response.current, waste_category)
        emoji = WeatherService.get_weather_emoji(response.current)

        return ToolResult(
            tool_name=ToolName.GET_WEATHER,
            success=True,
            data={
                "temperature": response.current.temperature if response.current else None,
                "humidity": response.current.humidity if response.current else None,
                "precipitation_type": (
                    response.current.precipitation_type.name if response.current else None
                ),
                "precipitation": response.current.precipitation if response.current else 0,
                "sky_status": response.current.sky_status.name if response.current else None,
                "tip": tip,
                "emoji": emoji,
                "grid": {"nx": nx, "ny": ny},
            },
        )

    async def _geocode(self, args: dict[str, Any]) -> ToolResult:
        """ì¥ì†Œëª… â†’ ì¢Œí‘œ ë³€í™˜ (Geocoding)."""
        if self._kakao_client is None:
            return ToolResult(
                tool_name=ToolName.GEOCODE,
                success=False,
                error="Geocoding ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            )

        place_name = args.get("place_name", "")

        # Kakao Local APIë¡œ geocoding
        response = await self._kakao_client.search_keyword(
            query=place_name,
            size=1,
        )

        if not response.places:
            return ToolResult(
                tool_name=ToolName.GEOCODE,
                success=False,
                error=f"'{place_name}'ì— ëŒ€í•œ ì¢Œí‘œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            )

        place = response.places[0]
        return ToolResult(
            tool_name=ToolName.GEOCODE,
            success=True,
            data={
                "place_name": place.place_name,
                "address": place.road_address_name or place.address_name,
                "latitude": place.latitude,
                "longitude": place.longitude,
            },
        )


# ============================================================
# OpenAI Function Calling Handler
# ============================================================


async def run_openai_agent(
    openai_client: Any,  # openai.AsyncOpenAI
    model: str,
    message: str,
    user_location: dict[str, float] | None,
    tool_executor: WeatherToolExecutor,
    max_iterations: int = 5,
) -> dict[str, Any]:
    """OpenAI Function Callingìœ¼ë¡œ Weather Agent ì‹¤í–‰.

    Args:
        openai_client: OpenAI AsyncClient
        model: ëª¨ë¸ëª… (gpt-5.2, etc.)
        message: ì‚¬ìš©ì ë©”ì‹œì§€
        user_location: ì‚¬ìš©ì ìœ„ì¹˜ {latitude, longitude}
        tool_executor: Weather Tool ì‹¤í–‰ê¸°
        max_iterations: ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜

    Returns:
        Agent ê²°ê³¼ (weather_data, summary ë“±)
    """
    # ì‚¬ìš©ì ìœ„ì¹˜ ì •ë³´ë¥¼ ë©”ì‹œì§€ì— í¬í•¨
    user_message = message
    if user_location:
        lat = user_location.get("latitude") or user_location.get("lat")
        lon = user_location.get("longitude") or user_location.get("lon")
        if lat and lon:
            user_message = f"{message}\n\n[í˜„ì¬ ìœ„ì¹˜: ìœ„ë„ {lat}, ê²½ë„ {lon}]"

    messages = [
        {"role": "system", "content": WEATHER_AGENT_SYSTEM_PROMPT},
        {"role": "user", "content": user_message},
    ]

    all_tool_results: list[dict[str, Any]] = []

    for iteration in range(max_iterations):
        logger.debug(f"OpenAI weather agent iteration {iteration + 1}")

        response = await openai_client.chat.completions.create(
            model=model,
            messages=messages,
            tools=OPENAI_TOOLS,
            tool_choice="auto",
        )

        assistant_message = response.choices[0].message

        # Tool callì´ ì—†ìœ¼ë©´ ìµœì¢… ì‘ë‹µ
        if not assistant_message.tool_calls:
            return {
                "success": True,
                "summary": assistant_message.content,
                "tool_results": all_tool_results,
            }

        # Tool calls ì²˜ë¦¬
        messages.append(assistant_message.model_dump())

        # ë³‘ë ¬ Tool ì‹¤í–‰ (asyncio.gather) - GPT-5.2 Best Practice
        async def execute_tool(tc: Any) -> tuple[Any, dict, ToolResult]:
            tool_name = tc.function.name
            try:
                arguments = json.loads(tc.function.arguments)
            except json.JSONDecodeError:
                arguments = {}

            logger.info(
                "Executing weather tool",
                extra={"tool": tool_name, "args": arguments},
            )
            result = await tool_executor.execute(tool_name, arguments)
            return tc, arguments, result

        # ëª¨ë“  tool calls ë³‘ë ¬ ì‹¤í–‰
        execution_results = await asyncio.gather(
            *[execute_tool(tc) for tc in assistant_message.tool_calls]
        )

        # ê²°ê³¼ ì²˜ë¦¬ ë° ë©”ì‹œì§€ ì¶”ê°€
        for tc, arguments, result in execution_results:
            all_tool_results.append({
                "tool": tc.function.name,
                "arguments": arguments,
                "result": result.data if result.success else {"error": result.error},
                "success": result.success,
            })

            messages.append({
                "role": "tool",
                "tool_call_id": tc.id,
                "name": tc.function.name,
                "content": json.dumps(
                    result.data if result.success else {"error": result.error},
                    ensure_ascii=False,
                ),
            })

    # Max iterations ë„ë‹¬
    return {
        "success": True,
        "summary": "ë‚ ì”¨ ì •ë³´ë¥¼ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤.",
        "tool_results": all_tool_results,
    }


# ============================================================
# Gemini Function Calling Handler
# ============================================================


async def run_gemini_agent(
    gemini_client: Any,  # google.genai.Client
    model: str,
    message: str,
    user_location: dict[str, float] | None,
    tool_executor: WeatherToolExecutor,
    max_iterations: int = 5,
) -> dict[str, Any]:
    """Gemini Function Callingìœ¼ë¡œ Weather Agent ì‹¤í–‰.

    Args:
        gemini_client: Gemini Client
        model: ëª¨ë¸ëª… (gemini-3-flash, etc.)
        message: ì‚¬ìš©ì ë©”ì‹œì§€
        user_location: ì‚¬ìš©ì ìœ„ì¹˜ {latitude, longitude}
        tool_executor: Weather Tool ì‹¤í–‰ê¸°
        max_iterations: ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜

    Returns:
        Agent ê²°ê³¼ (weather_data, summary ë“±)
    """
    from google.genai import types

    # ì‚¬ìš©ì ìœ„ì¹˜ ì •ë³´ë¥¼ ë©”ì‹œì§€ì— í¬í•¨
    user_message = message
    if user_location:
        lat = user_location.get("latitude") or user_location.get("lat")
        lon = user_location.get("longitude") or user_location.get("lon")
        if lat and lon:
            user_message = f"{message}\n\n[í˜„ì¬ ìœ„ì¹˜: ìœ„ë„ {lat}, ê²½ë„ {lon}]"

    # Gemini 3 Tool ì„¤ì •
    tools = types.Tool(function_declarations=GEMINI_TOOLS)
    config = types.GenerateContentConfig(
        tools=[tools],
        tool_config=types.ToolConfig(
            function_calling_config=types.FunctionCallingConfig(
                mode="AUTO",
            ),
        ),
        system_instruction=WEATHER_AGENT_SYSTEM_PROMPT,
        temperature=0,
    )

    contents = [user_message]
    all_tool_results: list[dict[str, Any]] = []

    for iteration in range(max_iterations):
        logger.debug(f"Gemini weather agent iteration {iteration + 1}")

        response = await gemini_client.aio.models.generate_content(
            model=model,
            contents=contents,
            config=config,
        )

        candidate = response.candidates[0]
        parts = candidate.content.parts

        # Parallel Function Calls ì²˜ë¦¬
        function_calls = [
            p for p in parts
            if hasattr(p, "function_call") and p.function_call is not None
        ]

        if not function_calls:
            # ìµœì¢… í…ìŠ¤íŠ¸ ì‘ë‹µ
            text_parts = [p.text for p in parts if hasattr(p, "text") and p.text]
            return {
                "success": True,
                "summary": " ".join(text_parts) if text_parts else "",
                "tool_results": all_tool_results,
            }

        # ë³‘ë ¬ Tool ì‹¤í–‰
        async def execute_tool(fc_part: Any) -> dict[str, Any]:
            fc = fc_part.function_call
            tool_name = fc.name
            arguments = dict(fc.args) if fc.args else {}
            logger.info(
                "Executing weather tool (Gemini)",
                extra={"tool": tool_name, "args": arguments},
            )
            result = await tool_executor.execute(tool_name, arguments)
            return {
                "tool": tool_name,
                "arguments": arguments,
                "result": result.data if result.success else {"error": result.error},
                "success": result.success,
                "_name": tool_name,
                "_response": result.data if result.success else {"error": result.error},
            }

        results = await asyncio.gather(*[execute_tool(fc) for fc in function_calls])
        all_tool_results.extend(results)

        # ëŒ€í™” ì´ë ¥ì— ì¶”ê°€
        contents.append(candidate.content)

        # ëª¨ë“  Function ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ Contentë¡œ ì¶”ê°€
        function_response_parts = [
            types.Part.from_function_response(
                name=r["_name"],
                response=r["_response"],
            )
            for r in results
        ]
        contents.append(types.Content(role="user", parts=function_response_parts))

    # Max iterations ë„ë‹¬
    return {
        "success": True,
        "summary": "ë‚ ì”¨ ì •ë³´ë¥¼ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤.",
        "tool_results": all_tool_results,
    }


# ============================================================
# Weather Agent Node Factory
# ============================================================


def create_weather_agent_node(
    weather_client: "WeatherClientPort",
    event_publisher: "ProgressNotifierPort",
    kakao_client: "KakaoLocalClientPort | None" = None,
    openai_client: Any | None = None,
    gemini_client: Any | None = None,
    default_model: str = "gpt-5.2",
    default_provider: str = "openai",
):
    """Weather Agent ë…¸ë“œ íŒ©í† ë¦¬.

    LLMì´ Weather/Geocoding APIë¥¼ Toolë¡œ ì‚¬ìš©í•˜ì—¬ ë‚ ì”¨ ì •ë³´ ì œê³µ.
    GPT-5.2 / Gemini 3 ì§€ì›.

    Args:
        weather_client: ë‚ ì”¨ í´ë¼ì´ì–¸íŠ¸
        event_publisher: ì´ë²¤íŠ¸ ë°œí–‰ê¸°
        kakao_client: Kakao Local API í´ë¼ì´ì–¸íŠ¸ (geocodingìš©)
        openai_client: OpenAI AsyncClient (ì„ íƒ)
        gemini_client: Gemini Client (ì„ íƒ)
        default_model: ê¸°ë³¸ ëª¨ë¸ëª… (gpt-5.2, gemini-3-flash ë“±)
        default_provider: ê¸°ë³¸ í”„ë¡œë°”ì´ë” ("openai" | "gemini")

    Returns:
        weather_agent_node í•¨ìˆ˜
    """
    tool_executor = WeatherToolExecutor(
        weather_client=weather_client,
        kakao_client=kakao_client,
    )

    async def weather_agent_node(state: dict[str, Any]) -> dict[str, Any]:
        """LangGraph Weather Agent ë…¸ë“œ.

        Args:
            state: í˜„ì¬ LangGraph ìƒíƒœ

        Returns:
            ì—…ë°ì´íŠ¸ëœ ìƒíƒœ (weather_context)
        """
        job_id = state.get("job_id", "")
        message = state.get("message", "")
        user_location = state.get("user_location")

        # Progress: ì‹œì‘
        await event_publisher.notify_stage(
            task_id=job_id,
            stage="weather",
            status="started",
            progress=40,
            message="ë‚ ì”¨ ì •ë³´ í™•ì¸ ì¤‘...",
        )

        try:
            # Provider ì„ íƒ (stateì—ì„œ override ê°€ëŠ¥)
            provider = state.get("llm_provider", default_provider)
            model = state.get("llm_model", default_model)

            if provider == "gemini" and gemini_client is not None:
                result = await run_gemini_agent(
                    gemini_client=gemini_client,
                    model=model,
                    message=message,
                    user_location=user_location,
                    tool_executor=tool_executor,
                )
            elif openai_client is not None:
                result = await run_openai_agent(
                    openai_client=openai_client,
                    model=model,
                    message=message,
                    user_location=user_location,
                    tool_executor=tool_executor,
                )
            else:
                # Fallback: LLM ì—†ìœ¼ë©´ ì§ì ‘ ë‚ ì”¨ ì¡°íšŒ
                logger.warning("No LLM client available, falling back to direct weather fetch")

                # user_locationì—ì„œ ì¢Œí‘œ ì¶”ì¶œ
                lat = None
                lon = None
                if isinstance(user_location, dict):
                    lat = user_location.get("latitude") or user_location.get("lat")
                    lon = user_location.get("longitude") or user_location.get("lon")

                if lat and lon:
                    weather_result = await tool_executor._get_weather({
                        "latitude": lat,
                        "longitude": lon,
                    })
                    result = {
                        "success": weather_result.success,
                        "summary": None,
                        "tool_results": [{
                            "tool": "get_weather",
                            "result": weather_result.data if weather_result.success else {"error": weather_result.error},
                            "success": weather_result.success,
                        }],
                    }
                else:
                    result = {
                        "success": False,
                        "summary": None,
                        "tool_results": [],
                        "error": "ìœ„ì¹˜ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.",
                    }

            # ê²°ê³¼ì—ì„œ ë‚ ì”¨ ì •ë³´ ì¶”ì¶œ
            weather_data = None
            for tr in result.get("tool_results", []):
                if tr.get("tool") == "get_weather" and tr.get("success"):
                    weather_data = tr.get("result")
                    break

            # Progress: ì™„ë£Œ
            if weather_data:
                temp = weather_data.get("temperature")
                await event_publisher.notify_stage(
                    task_id=job_id,
                    stage="weather",
                    status="completed",
                    progress=45,
                    result={
                        "temperature": temp,
                        "has_tip": bool(weather_data.get("tip")),
                    },
                    message=f"ë‚ ì”¨ í™•ì¸ ì™„ë£Œ: {temp}Â°C" if temp else "ë‚ ì”¨ í™•ì¸ ì™„ë£Œ",
                )

                # weather_context ìƒì„±
                context_data = {
                    "type": "weather",
                    "temperature": weather_data.get("temperature"),
                    "humidity": weather_data.get("humidity"),
                    "precipitation_type": weather_data.get("precipitation_type"),
                    "tip": weather_data.get("tip"),
                    "emoji": weather_data.get("emoji"),
                    "summary": result.get("summary"),
                    "context": result.get("summary"),  # Answer ë…¸ë“œì—ì„œ ì‚¬ìš©
                }

                return {
                    "weather_context": create_context(
                        data=context_data,
                        producer="weather",
                        job_id=job_id,
                    ),
                }
            else:
                # ë‚ ì”¨ ì •ë³´ ì—†ìŒ
                await event_publisher.notify_stage(
                    task_id=job_id,
                    stage="weather",
                    status="skipped",
                    message="ë‚ ì”¨ ì •ë³´ ì—†ìŒ",
                )

                return {
                    "weather_context": create_error_context(
                        producer="weather",
                        job_id=job_id,
                        error=result.get("error", "ë‚ ì”¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."),
                    ),
                }

        except Exception as e:
            logger.exception("Weather agent failed")

            await event_publisher.notify_stage(
                task_id=job_id,
                stage="weather",
                status="failed",
                result={"error": str(e)},
            )

            return {
                "weather_context": create_error_context(
                    producer="weather",
                    job_id=job_id,
                    error=str(e),
                ),
            }

    return weather_agent_node


__all__ = [
    "create_weather_agent_node",
    "OPENAI_TOOLS",
    "GEMINI_TOOLS",
    "WeatherToolExecutor",
]

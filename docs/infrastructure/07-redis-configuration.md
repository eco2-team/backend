# ğŸ’¾ Redis êµ¬ì„± ë° ì‚¬ìš© ì „ëµ

> **Tier 4: Persistence Layer - Cache & State Management**  
> **ë‚ ì§œ**: 2025-10-31  
> **ë°°í¬**: Storage Node (t3.large, 8GB)

## ğŸ“‹ ëª©ì°¨

1. [Redis ì—­í•  (Tier 4)](#redis-ì—­í• -tier-4)
2. [DBë³„ ì‚¬ìš© ì „ëµ](#dbë³„-ì‚¬ìš©-ì „ëµ)
3. [Kubernetes ë°°í¬](#kubernetes-ë°°í¬)
4. [ëª¨ë‹ˆí„°ë§](#ëª¨ë‹ˆí„°ë§)

---

## ğŸ¯ Redis ì—­í•  (Tier 4)

### Tier 4 Persistence Layer

```
Redis ì±…ì„:
âœ… Caching (ì„±ëŠ¥ ìµœì í™”)
âœ… State Storage (ìƒíƒœ ì €ì¥, ë°˜ë³µ ì¡°íšŒ ê°€ëŠ¥)
âœ… Result Backend (Celery)
âœ… Rate Limiting (DDoS ë°©ì§€)

âŒ Session Store (JWT Statelessì´ë¯€ë¡œ ë¶ˆí•„ìš”)
âŒ Message Queue (RabbitMQê°€ ë‹´ë‹¹)

ê´€ì‹¬ì‚¬:
â””â”€ "ë¹ ë¥´ê²Œ ì ‘ê·¼ ê°€ëŠ¥í•œ ë°ì´í„°ë¥¼ ì–´ë–»ê²Œ ì €ì¥í•  ê²ƒì¸ê°€?"
```

---

## ğŸ“Š DBë³„ ì‚¬ìš© ì „ëµ

### DB 0: Celery Result Backend â­â­â­

```python
# Celery ì„¤ì •
result_backend = 'redis://redis.default:6379/0'

# ìë™ ì €ì¥ (Celeryê°€ ê´€ë¦¬)
celery-task-meta-{task_id} = {
    "status": "SUCCESS",
    "result": {...},
    "traceback": null,
    "date_done": "2025-10-31T10:30:00"
}

TTL: 86400ì´ˆ (24ì‹œê°„, task_result_expires)
í¬ê¸°: ~1-5KB/task
ì˜ˆìƒ ë©”ëª¨ë¦¬: ~50MB (10,000 tasks)

ì‚¬ìš©:
â””â”€ Celery Workerê°€ ìë™ ì €ì¥
â””â”€ task.get() ê²°ê³¼ ì¡°íšŒ
```

### DB 1: Image Hash Cache â­â­â­â­â­ (ìµœìš°ì„ !)

```python
# AI ë¹„ìš© 70% ì ˆê°ì˜ í•µì‹¬!

# Perceptual Hash ê¸°ë°˜ ìºì‹±
import imagehash
from PIL import Image

# Hash ê³„ì‚°
img = Image.open("trash.jpg")
phash = str(imagehash.phash(img, hash_size=16))

# ìºì‹œ í‚¤
cache:image:hash:{phash} = {
    "waste_type": "PET í”Œë¼ìŠ¤í‹±",
    "confidence": 0.95,
    "feedback": "ê¹¨ë—ì´ ì„¸ì²™ í›„ ë¼ë²¨ ì œê±°í•˜ê³  ëšœê»‘ ë¶„ë¦¬...",
    "category": "í”Œë¼ìŠ¤í‹±",
    "recyclable": true,
    "analyzed_at": "2025-10-31T10:30:00"
}

TTL: 604800ì´ˆ (7ì¼)
í¬ê¸°: ~10KB/ì´ë¯¸ì§€
ì˜ˆìƒ ë©”ëª¨ë¦¬: ~100MB (10,000 unique ì´ë¯¸ì§€)

íš¨ê³¼:
âœ… ê°™ì€ ì“°ë ˆê¸° ì‚¬ì§„ (ì½œë¼ìº”, ìš°ìœ íŒ© ë“±)
âœ… 10,000 ìš”ì²­ ì¤‘ 7,000 ìºì‹œ íˆíŠ¸ (70%)
âœ… AI API í˜¸ì¶œ: 3,000íšŒë§Œ
âœ… ë¹„ìš© ì ˆê°: $70/ì›”
âœ… ì‘ë‹µ ì†ë„: 5ì´ˆ â†’ 1ì´ˆ

ê°€ì¥ ì¤‘ìš”í•œ ìµœì í™”!
```

### DB 2: Job Progress Tracking â­â­â­â­

```python
# 0.5ì´ˆë§ˆë‹¤ Polling (RabbitMQ ë¶ˆê°€!)

# Worker (ì§„í–‰ë¥  ì—…ë°ì´íŠ¸)
job:{job_id}:progress = {
    "progress": 50,
    "message": "AI ë¶„ì„ ì¤‘...",
    "stage": "ai_vision",
    "updated_at": "2025-10-31T10:30:45"
}

TTL: 3600ì´ˆ (1ì‹œê°„)
í¬ê¸°: ~1KB/job
ì˜ˆìƒ ë©”ëª¨ë¦¬: ~10MB (1,000 active jobs)

ì—…ë°ì´íŠ¸ ë¹ˆë„: 10-15íšŒ/job
ì¡°íšŒ ë¹ˆë„: 20-30íšŒ/job (0.5ì´ˆë§ˆë‹¤)

# API (ë°˜ë³µ ì¡°íšŒ)
@app.get("/status/{job_id}")
async def get_status(job_id: str):
    progress = await redis.get(f"job:{job_id}:progress")
    # âœ… ê°™ì€ Key ë¬´í•œ ë°˜ë³µ ì¡°íšŒ
    # âœ… Overwrite ê°€ëŠ¥
    # âœ… ì—¬ëŸ¬ API ì„œë²„ì—ì„œ ë™ì‹œ ì¡°íšŒ
    return json.loads(progress)
```

### DB 3: Rate Limiting â­â­

```python
# DDoS ë°©ì§€ ë° API ë³´í˜¸

from fastapi import Request
from fastapi_limiter import FastAPILimiter
from fastapi_limiter.depends import RateLimiter

# ì„¤ì •
await FastAPILimiter.init(redis_url="redis://redis.default:6379/3")

# ì‚¬ìš©
@app.post("/api/v1/waste/analyze",
    dependencies=[Depends(RateLimiter(times=60, seconds=60))]
)
async def analyze():
    # 1ë¶„ë‹¹ 60íšŒ ì œí•œ
    pass

# Redis ë°ì´í„° êµ¬ì¡°
ratelimit:ip:{ip}:{endpoint} = 15  # í˜„ì¬ ìš”ì²­ íšŸìˆ˜
TTL: 60ì´ˆ

# ë˜ëŠ” ìˆ˜ë™ êµ¬í˜„
key = f"ratelimit:ip:{client_ip}:/api/v1/waste/analyze"
count = await redis.incr(key)
if count == 1:
    await redis.expire(key, 60)
if count > 60:
    raise HTTPException(429, "Too many requests")

í¬ê¸°: ~100B/IP
ì˜ˆìƒ ë©”ëª¨ë¦¬: ~5MB (10,000 IPs)
```

### DB 4: Token Blacklist â­ (ì„ íƒ)

```python
# ë¡œê·¸ì•„ì›ƒ ë° íƒˆì·¨ í† í° ë¬´íš¨í™”

# ë¡œê·¸ì•„ì›ƒ ì‹œ
@app.post("/api/v1/auth/logout")
async def logout(token: str = Depends(verify_jwt)):
    payload = decode_jwt(token)
    
    # 1. Refresh Token DBì—ì„œ ì‚­ì œ (PostgreSQL)
    await db.execute(
        "DELETE FROM refresh_tokens WHERE user_id = $1",
        payload["user_id"]
    )
    
    # 2. Access Token Blacklist (Redis)
    token_hash = hashlib.sha256(token.encode()).hexdigest()
    expires_in = payload["exp"] - int(time.time())
    
    await redis.setex(
        f"blacklist:token:{token_hash}",
        expires_in,  # Token ë§Œë£Œ ì‹œê°„ê¹Œì§€ë§Œ
        "revoked"
    )

# ëª¨ë“  API ìš”ì²­ ì‹œ í™•ì¸ (Middleware)
@app.middleware("http")
async def check_token_blacklist(request: Request, call_next):
    token = request.headers.get("Authorization", "").replace("Bearer ", "")
    if token:
        token_hash = hashlib.sha256(token.encode()).hexdigest()
        is_blacklisted = await redis.exists(f"blacklist:token:{token_hash}")
        if is_blacklisted:
            return JSONResponse(
                status_code=401,
                content={"detail": "Token has been revoked"}
            )
    return await call_next(request)

í¬ê¸°: ~100B/token
ì˜ˆìƒ ë©”ëª¨ë¦¬: ~1MB (ì„ íƒ ì‚¬ìš©)
```

---

## ğŸš€ Kubernetes ë°°í¬

### Redis Deployment (Tier 4)

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      tier: persistence
  template:
    metadata:
      labels:
        app: redis
        tier: persistence
    spec:
      nodeSelector:
        workload: storage  # Storage ë…¸ë“œ
      containers:
      - name: redis
        image: redis:7-alpine
        command:
        - redis-server
        - --appendonly yes
        - --maxmemory 2gb
        - --maxmemory-policy allkeys-lru
        - --databases 16
        ports:
        - containerPort: 6379
        volumeMounts:
        - name: data
          mountPath: /data
        resources:
          requests:
            cpu: 200m
            memory: 1Gi
          limits:
            cpu: 1000m
            memory: 2Gi
        livenessProbe:
          tcpSocket:
            port: 6379
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          exec:
            command:
            - redis-cli
            - ping
          initialDelaySeconds: 5
          periodSeconds: 5
      volumes:
      - name: data
        emptyDir: {}

---
apiVersion: v1
kind: Service
metadata:
  name: redis
  namespace: default
spec:
  selector:
    app: redis
  ports:
  - port: 6379
    targetPort: 6379
  type: ClusterIP
```

### ConfigMap (DBë³„ ì„¤ì •)

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: redis-config
  namespace: default
data:
  redis.conf: |
    # DB ë¶„ë¦¬
    databases 16
    
    # ë©”ëª¨ë¦¬ ê´€ë¦¬
    maxmemory 2gb
    maxmemory-policy allkeys-lru
    
    # Persistence
    appendonly yes
    appendfsync everysec
    
    # ë„¤íŠ¸ì›Œí¬
    tcp-backlog 511
    timeout 0
    
    # í´ë¼ì´ì–¸íŠ¸ ì—°ê²°
    maxclients 10000
```

---

## ğŸ“Š ëª¨ë‹ˆí„°ë§

### Prometheus Metrics

```yaml
# Redis Exporter
apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-exporter
  namespace: default
spec:
  replicas: 1
  template:
    spec:
      containers:
      - name: exporter
        image: oliver006/redis_exporter:latest
        env:
        - name: REDIS_ADDR
          value: "redis.default:6379"
        ports:
        - containerPort: 9121

---
# ServiceMonitor (Prometheus)
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: redis
  namespace: default
spec:
  selector:
    matchLabels:
      app: redis
  endpoints:
  - port: metrics
    interval: 30s
```

### ì£¼ìš” ë©”íŠ¸ë¦­

```
ë©”ëª¨ë¦¬:
â”œâ”€ redis_memory_used_bytes
â”œâ”€ redis_memory_max_bytes
â””â”€ redis_memory_fragmentation_ratio

ì„±ëŠ¥:
â”œâ”€ redis_commands_processed_total
â”œâ”€ redis_keyspace_hits_total (ìºì‹œ íˆíŠ¸)
â”œâ”€ redis_keyspace_misses_total (ìºì‹œ ë¯¸ìŠ¤)
â””â”€ redis_connected_clients

DBë³„:
â”œâ”€ redis_db_keys{db="1"}  # Image Cache
â”œâ”€ redis_db_keys{db="2"}  # Job Progress
â””â”€ redis_db_keys{db="3"}  # Rate Limit

ì•ŒëŒ:
â”œâ”€ ìºì‹œ íˆíŠ¸ìœ¨ < 60% â†’ Warning
â”œâ”€ ë©”ëª¨ë¦¬ ì‚¬ìš© > 80% â†’ Warning
â””â”€ ì—°ê²° ìˆ˜ > 5000 â†’ Warning
```

---

## ğŸ¯ Best Practices

### 1. ìºì‹œ íˆíŠ¸ìœ¨ ìµœì í™”

```python
# Image Hash Cache íˆíŠ¸ìœ¨ ëª©í‘œ: 70%+

# ëª¨ë‹ˆí„°ë§
hits = redis.info('stats')['keyspace_hits']
misses = redis.info('stats')['keyspace_misses']
hit_rate = hits / (hits + misses) * 100

# íˆíŠ¸ìœ¨ ë‚®ìœ¼ë©´:
# - TTL ëŠ˜ë¦¬ê¸° (7ì¼ â†’ 14ì¼)
# - Hash ì•Œê³ ë¦¬ì¦˜ ì¡°ì • (hash_size ì¦ê°€)
# - ìœ ì‚¬ ì´ë¯¸ì§€ ë²”ìœ„ í™•ëŒ€
```

### 2. ë©”ëª¨ë¦¬ ê´€ë¦¬

```python
# maxmemory-policy ì„¤ì •
maxmemory 2gb
maxmemory-policy allkeys-lru  # LRU eviction

# DBë³„ ìš°ì„ ìˆœìœ„:
# DB 1 (Image Cache) â†’ ê°€ì¥ ì¤‘ìš” (í° ë©”ëª¨ë¦¬)
# DB 2 (Progress) â†’ TTL 1ì‹œê°„ (ìë™ ì •ë¦¬)
# DB 3 (Rate Limit) â†’ TTL 1ë¶„ (ìë™ ì •ë¦¬)
# DB 4 (Blacklist) â†’ TTL ë™ì  (ìë™ ì •ë¦¬)
```

### 3. Persistence ì„¤ì •

```
appendonly yes
appendfsync everysec

# RDB + AOF í˜¼í•©:
# - RDB: ë¹ ë¥¸ ë³µêµ¬
# - AOF: ë°ì´í„° ì•ˆì „ì„±

ë°±ì—…:
- AOF íŒŒì¼: /data/appendonly.aof
- RDB íŒŒì¼: /data/dump.rdb
```

---

## ğŸ“š ê´€ë ¨ ë¬¸ì„œ

- [RabbitMQ HA êµ¬ì„±](rabbitmq-ha-setup.md) - Tier 3
- [Task Queue ì„¤ê³„](../architecture/task-queue-design.md)
- [Image Processing](../architecture/image-processing-architecture.md)

---

**ì‘ì„±ì¼**: 2025-10-31  
**Tier**: 4 (Persistence)  
**ë…¸ë“œ**: Storage (ê³µìœ )  
**ë©”ëª¨ë¦¬**: ~2GB (ì´ 8GB ì¤‘)


# WAL + MQ ì´ì¤‘ ì˜ì†í™” ì•„í‚¤í…ì²˜

## ğŸ“‹ ê°œìš”

Worker-Storageì—ì„œ ì‚¬ìš©í•˜ëŠ” **SQLite WAL(Write-Ahead Logging) + RabbitMQ** ì´ì¤‘ ì˜ì†í™” êµ¬ì¡°ëŠ” ë¹„ë™ê¸° ì‘ì—…ì˜ ì•ˆì •ì„±ê³¼ ì„±ëŠ¥ì„ ë™ì‹œì— ë‹¬ì„±í•˜ê¸° ìœ„í•œ ì„¤ê³„ì…ë‹ˆë‹¤.

---

## ğŸ—ï¸ í˜„ì¬ ì•„í‚¤í…ì²˜

### ì „ì²´ íë¦„

```mermaid
graph TB
    API[API Server] --> MQ[RabbitMQ]
    MQ --> Worker[Celery Worker]
    
    Worker --> WAL[SQLite WAL]
    WAL --> DB[SQLite Main DB]
    
    Worker --> S3[S3 Upload]
    S3 --> PostgreSQL[PostgreSQL ìµœì¢… ì €ì¥]
    
    style WAL fill:#ff6b6b,stroke:#c92a2a,color:#fff
    style MQ fill:#4dabf7,stroke:#1971c2,color:#fff
```

### ë°ì´í„° ê²½ë¡œ

```python
# 1. API ìš”ì²­ â†’ RabbitMQ
@router.post("/upload")
async def upload_image(file: UploadFile):
    task = image_uploader.delay(file.file.read(), user_id)
    return {"task_id": task.id}

# 2. RabbitMQ â†’ Celery Worker
@celery_app.task(bind=True)
def image_uploader(self, image_data: bytes, user_id: str):
    # 3. SQLite WAL ê¸°ë¡
    local_db.insert(
        task_id=self.request.id,
        status='processing',
        data=image_data
    )
    
    # 4. S3 ì—…ë¡œë“œ
    s3_url = upload_to_s3(image_data)
    
    # 5. PostgreSQL ì €ì¥
    postgresql.insert(user_id, s3_url)
    
    # 6. WAL ì •ë¦¬
    local_db.delete(task_id=self.request.id)
```

---

## ğŸ¯ ì´ì¤‘ ì˜ì†í™”ì˜ ëª©ì 

### 1. RabbitMQ ì—­í• 

```yaml
ëª©ì : íƒœìŠ¤í¬ íì‰ ë° ë¶„ì‚°

ì¥ì :
  âœ… íƒœìŠ¤í¬ ë¶„ì‚°: ì—¬ëŸ¬ Workerì— ê· ë“± ë¶„ë°°
  âœ… ìš°ì„ ìˆœìœ„: Priority Queue
  âœ… ì¬ì‹œë„: Automatic Retry
  âœ… ë¹„ë™ê¸°: Non-blocking
  âœ… í™•ì¸ ë©”ì»¤ë‹ˆì¦˜: ACK/NACK

íŠ¹ì§•:
  - Message Persistence (ë””ìŠ¤í¬ ì €ì¥)
  - Durable Queues
  - Delivery Acknowledgement
```

### 2. SQLite WAL ì—­í• 

```yaml
ëª©ì : Worker ë¡œì»¬ ì‘ì—… ì¶”ì  ë° ë³µêµ¬

ì¥ì :
  âœ… ë¹ ë¥¸ ì“°ê¸°: ë©”ëª¨ë¦¬ + ìˆœì°¨ ì“°ê¸°
  âœ… íŠ¸ëœì­ì…˜: ACID ë³´ì¥
  âœ… ì¶©ëŒ ë°©ì§€: ë™ì‹œ ì½ê¸°/ì“°ê¸°
  âœ… ë³µêµ¬ ê°€ëŠ¥: ì¬ì‹œì‘ í›„ ë¯¸ì™„ë£Œ ì‘ì—… ì¬ê°œ
  âœ… ë¡œì»¬ ìºì‹œ: ë„¤íŠ¸ì›Œí¬ ë¶€í•˜ ì—†ìŒ

íŠ¹ì§•:
  - Write-Ahead Log (ì“°ê¸° ì „ ë¡œê·¸ ê¸°ë¡)
  - Checkpoint (ì£¼ê¸°ì  Main DB ë™ê¸°í™”)
  - Rollback Journal
```

---

## ğŸ’¾ SQLite WAL ë™ì‘ ì›ë¦¬

### WAL ëª¨ë“œ vs Rollback Journal

```sql
-- WAL ëª¨ë“œ í™œì„±í™”
PRAGMA journal_mode=WAL;

-- ë™ì‹œì„± í–¥ìƒ
PRAGMA synchronous=NORMAL;

-- ì²´í¬í¬ì¸íŠ¸ ì„¤ì •
PRAGMA wal_autocheckpoint=1000;
```

#### Rollback Journal (ê¸°ë³¸)

```
1. ì“°ê¸° ì‹œì‘
2. ê¸°ì¡´ ë°ì´í„°ë¥¼ Journalì— ë°±ì—…
3. Main DBì— ìƒˆ ë°ì´í„° ì“°ê¸°
4. Journal ì‚­ì œ

ë¬¸ì œì :
- ì“°ê¸° ì¤‘ ì½ê¸° ë¸”ë¡œí‚¹
- ëŠë¦° ì„±ëŠ¥
```

#### WAL (Write-Ahead Logging)

```
1. ì“°ê¸° ì‹œì‘
2. ìƒˆ ë°ì´í„°ë¥¼ WAL íŒŒì¼ì— ì¶”ê°€ (Append-only)
3. ì£¼ê¸°ì ìœ¼ë¡œ Main DBì— ì²´í¬í¬ì¸íŠ¸
4. ì½ê¸°ëŠ” Main DB + WAL ë³‘í•©

ì¥ì :
- ì“°ê¸° ì¤‘ì—ë„ ì½ê¸° ê°€ëŠ¥
- ìˆœì°¨ ì“°ê¸°ë¡œ ë¹ ë¥¸ ì„±ëŠ¥
- ë™ì‹œì„± í–¥ìƒ
```

### íŒŒì¼ êµ¬ì¡°

```bash
/data/worker-storage/
â”œâ”€â”€ tasks.db           # Main Database
â”œâ”€â”€ tasks.db-wal       # Write-Ahead Log (ë³€ê²½ì‚¬í•­)
â””â”€â”€ tasks.db-shm       # Shared Memory (ì¸ë±ìŠ¤)

# WAL íŒŒì¼ í¬ê¸° ëª¨ë‹ˆí„°ë§
ls -lh tasks.db-wal
# â†’ 1000 pagesë§ˆë‹¤ ìë™ ì²´í¬í¬ì¸íŠ¸
```

---

## ğŸ”„ ì´ì¤‘ ì˜ì†í™” ì‹œë‚˜ë¦¬ì˜¤

### ì‹œë‚˜ë¦¬ì˜¤ 1: ì •ìƒ ì²˜ë¦¬

```python
# 1. API â†’ RabbitMQ
API: POST /upload â†’ RabbitMQ Queue
  Status: PENDING

# 2. RabbitMQ â†’ Worker
Worker: Task ìˆ˜ì‹ 
  RabbitMQ: Message ACK ë³´ë¥˜ (ì•„ì§ í™•ì¸ ì•ˆ í•¨)
  
# 3. Worker â†’ SQLite WAL
Worker: ì‘ì—… ì‹œì‘
  SQLite WAL: INSERT task_id, status='processing'
  
# 4. Worker â†’ S3 Upload
Worker: S3ì— ì´ë¯¸ì§€ ì—…ë¡œë“œ
  S3: 201 Created
  
# 5. Worker â†’ PostgreSQL
Worker: PostgreSQLì— ë©”íƒ€ë°ì´í„° ì €ì¥
  PostgreSQL: INSERT user_id, s3_url
  
# 6. Worker â†’ SQLite WAL (ì •ë¦¬)
Worker: ì‘ì—… ì™„ë£Œ
  SQLite WAL: DELETE task_id
  
# 7. Worker â†’ RabbitMQ
Worker: RabbitMQ ACK (í™•ì¸)
  RabbitMQ: Message ì‚­ì œ

ê²°ê³¼: âœ… ì„±ê³µ
```

### ì‹œë‚˜ë¦¬ì˜¤ 2: Worker ì¤‘ë‹¨ (S3 ì—…ë¡œë“œ ì¤‘)

```python
# 1-3: ë™ì¼ (RabbitMQ â†’ Worker â†’ SQLite WAL)

# 4. Worker â†’ S3 Upload
Worker: S3 ì—…ë¡œë“œ ì¤‘...
  âš ï¸ Worker ê°‘ìê¸° ì¢…ë£Œ (OOM, Crash ë“±)

# 5. RabbitMQ ì²˜ë¦¬
RabbitMQ: ACK ë°›ì§€ ëª»í•¨
  â†’ Messageë¥¼ ë‹¤ì‹œ Queueì— ì¶”ê°€ (Requeue)
  â†’ Visibility Timeout í›„ ë‹¤ë¥¸ Workerì— ì „ë‹¬

# 6. Worker ì¬ì‹œì‘
Worker: SQLite WAL ë³µêµ¬
  SQLite: task_id='xxx', status='processing' ë°œê²¬
  
  ì˜µì…˜ 1: WAL ê¸°ë¡ ê¸°ë°˜ ì¬ì‹œë„
    â†’ S3 ì—…ë¡œë“œ ì¬ì‹œë„
    â†’ ì„±ê³µ ì‹œ PostgreSQL ì €ì¥
    â†’ SQLite WAL ì •ë¦¬
    â†’ RabbitMQ ACK
  
  ì˜µì…˜ 2: WAL ë¬´ì‹œ, RabbitMQ ë©”ì‹œì§€ ì¬ì²˜ë¦¬
    â†’ SQLite WAL DELETE (ì¶©ëŒ ë°©ì§€)
    â†’ RabbitMQ ë©”ì‹œì§€ë¡œ ìƒˆë¡œ ì‹œì‘

ê²°ê³¼: âœ… ë³µêµ¬ ê°€ëŠ¥ (ì´ì¤‘ ë³´í˜¸)
```

### ì‹œë‚˜ë¦¬ì˜¤ 3: Network ì¥ì•  (PostgreSQL ì €ì¥ ì‹¤íŒ¨)

```python
# 1-4: ë™ì¼ (S3 ì—…ë¡œë“œ ì™„ë£Œ)

# 5. Worker â†’ PostgreSQL
Worker: PostgreSQL ì—°ê²° ì‹œë„
  âŒ Network Timeout
  
# 6. Worker â†’ Retry
Celery: ìë™ ì¬ì‹œë„ (max_retries=3)
  Retry 1: 5ì´ˆ í›„ ì¬ì‹œë„
  Retry 2: 10ì´ˆ í›„ ì¬ì‹œë„
  Retry 3: 20ì´ˆ í›„ ì¬ì‹œë„
  
# 7. ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨
Celery: Dead Letter Queueë¡œ ì´ë™
  
# 8. SQLite WAL ìœ ì§€
SQLite WAL: task_id ìœ ì§€ (ë¯¸ì™„ë£Œ)
  
# 9. ìˆ˜ë™ ë³µêµ¬ ë˜ëŠ” ì¬ì²˜ë¦¬
ê´€ë¦¬ì: SQLite WAL ì¡°íšŒ
  â†’ ë¯¸ì™„ë£Œ ì‘ì—… í™•ì¸
  â†’ S3 URLì€ ì¡´ì¬ (ì´ë¯¸ ì—…ë¡œë“œë¨)
  â†’ PostgreSQL ì¬ì‹œë„

ê²°ê³¼: âœ… ë°ì´í„° ì†ì‹¤ ì—†ìŒ (S3ì— ì €ì¥ë¨)
```

---

## ğŸ“Š ì¥ì  vs ë‹¨ì 

### ì¥ì 

#### 1. ê³ ê°€ìš©ì„± (High Availability)

```yaml
RabbitMQ ì¥ì• :
  â†’ SQLite WALì— ì‘ì—… ê¸°ë¡ ìœ ì§€
  â†’ RabbitMQ ë³µêµ¬ í›„ ì¬ì²˜ë¦¬

Worker ì¥ì• :
  â†’ RabbitMQê°€ Message Requeue
  â†’ SQLite WALë¡œ ì¤‘ë³µ ì‘ì—… ë°©ì§€

Network ì¥ì• :
  â†’ SQLite WALì— ì¤‘ê°„ ìƒíƒœ ì €ì¥
  â†’ ë³µêµ¬ í›„ ì´ì–´ì„œ ì²˜ë¦¬
```

#### 2. ë¹ ë¥¸ ì‘ë‹µ (Low Latency)

```python
# ë™ê¸°ì‹ (ëŠë¦¼)
API â†’ PostgreSQL ì§ì ‘ ì €ì¥
  ì‘ë‹µ ì‹œê°„: 200-500ms

# ë¹„ë™ê¸°ì‹ (ë¹ ë¦„)
API â†’ RabbitMQ â†’ Worker
  ì‘ë‹µ ì‹œê°„: 5-10ms (íì‰ë§Œ)
  ì‹¤ì œ ì²˜ë¦¬: ë°±ê·¸ë¼ìš´ë“œ
```

#### 3. ìˆœì„œ ë³´ì¥ (Ordering)

```yaml
RabbitMQ:
  - FIFO Queue
  - Priority Queue
  - Message Ordering

SQLite WAL:
  - ìˆœì°¨ ì“°ê¸°
  - íŠ¸ëœì­ì…˜ ìˆœì„œ ë³´ì¥
```

#### 4. ì¤‘ë³µ ë°©ì§€ (Idempotency)

```python
# SQLite WALë¡œ ì¤‘ë³µ í™•ì¸
def image_uploader(task_id, image_data):
    # 1. ì´ë¯¸ ì²˜ë¦¬ ì¤‘ì¸ì§€ í™•ì¸
    if local_db.exists(task_id):
        logger.warning(f"Task {task_id} already processing")
        return  # ì¤‘ë³µ ë°©ì§€
    
    # 2. WALì— ê¸°ë¡
    local_db.insert(task_id, 'processing')
    
    # 3. ì‹¤ì œ ì‘ì—…
    upload_to_s3(image_data)
    
    # 4. ì™„ë£Œ í›„ ì •ë¦¬
    local_db.delete(task_id)
```

### ë‹¨ì 

#### 1. ë³µì¡ë„ ì¦ê°€

```yaml
ê´€ë¦¬ ëŒ€ìƒ:
  - RabbitMQ ì„¤ì • ë° ëª¨ë‹ˆí„°ë§
  - SQLite WAL ì²´í¬í¬ì¸íŠ¸
  - ë™ê¸°í™” ë¡œì§
  - ë³µêµ¬ ë¡œì§

ë””ë²„ê¹…:
  - Messageê°€ RabbitMQì— ìˆë‚˜?
  - WALì— ê¸°ë¡ë˜ì–´ ìˆë‚˜?
  - ì–´ë””ì„œ ì‹¤íŒ¨í–ˆë‚˜?
```

#### 2. ë™ê¸°í™” ì˜¤ë²„í—¤ë“œ

```python
# ì“°ê¸° ê²½ë¡œ
1. RabbitMQì— Message ì¶”ê°€
2. SQLite WALì— ê¸°ë¡
3. ì‹¤ì œ ì‘ì—… ìˆ˜í–‰
4. PostgreSQLì— ì €ì¥
5. SQLite WAL ì •ë¦¬
6. RabbitMQ ACK

ì´ 6ë‹¨ê³„ â†’ ê° ë‹¨ê³„ë§ˆë‹¤ I/O
```

#### 3. ì¤‘ë³µ ì²˜ë¦¬ ê°€ëŠ¥ì„±

```yaml
ì‹œë‚˜ë¦¬ì˜¤:
  1. Workerê°€ ì‘ì—… ì™„ë£Œ
  2. SQLite WAL ì •ë¦¬ ì™„ë£Œ
  3. RabbitMQ ACK ì „ì— Worker ì¢…ë£Œ
  â†’ RabbitMQê°€ Message Requeue
  â†’ ë‹¤ë¥¸ Workerê°€ ì¤‘ë³µ ì²˜ë¦¬

í•´ê²°ì±…:
  - ë©±ë“±ì„±(Idempotency) ë³´ì¥
  - PostgreSQLì— unique constraint
  - S3 ë™ì¼ íŒŒì¼ ë®ì–´ì“°ê¸°
```

#### 4. ë””ìŠ¤í¬ ê³µê°„ ì‚¬ìš©

```bash
# WAL íŒŒì¼ í¬ê¸°
tasks.db: 10MB
tasks.db-wal: 5MB (ë³€ê²½ì‚¬í•­)

# í”¼í¬ ì‹œê°„ëŒ€
tasks.db-wal: 50MB (ì²´í¬í¬ì¸íŠ¸ ì „)

# ë””ìŠ¤í¬ ëª¨ë‹ˆí„°ë§ í•„ìš”
```

---

## ğŸ”€ ëŒ€ì•ˆ ì•„í‚¤í…ì²˜

### ëŒ€ì•ˆ 1: RabbitMQë§Œ ì‚¬ìš© (ë‹¨ìˆœí™”)

```yaml
êµ¬ì¡°:
  API â†’ RabbitMQ (Persistent) â†’ Worker â†’ PostgreSQL

ì¥ì :
  âœ… ë‹¨ìˆœí•¨
  âœ… RabbitMQ Persistenceë¡œ ì¶©ë¶„
  âœ… ê´€ë¦¬ ë¶€ë‹´ ê°ì†Œ

ë‹¨ì :
  âŒ Worker ë¡œì»¬ ìƒíƒœ ì¶”ì  ë¶ˆê°€
  âŒ ë³µêµ¬ ì‹œ RabbitMQ ì˜ì¡´
  âŒ ì¤‘ë³µ ë°©ì§€ ì–´ë ¤ì›€

ì í•©í•œ ê²½ìš°:
  - ì‘ì—…ì´ ë‹¨ìˆœ
  - ì¤‘ë³µ ì²˜ë¦¬ í—ˆìš© ê°€ëŠ¥
  - RabbitMQ ì•ˆì •ì„± ë†’ìŒ
```

### ëŒ€ì•ˆ 2: PostgreSQLë§Œ ì‚¬ìš© (ì „í†µì )

```yaml
êµ¬ì¡°:
  API â†’ PostgreSQL (task table) â†’ Worker Polling

ì¥ì :
  âœ… ë‹¨ìˆœí•¨
  âœ… ì¤‘ì•™ ì§‘ì¤‘ ê´€ë¦¬
  âœ… SQL ì¿¼ë¦¬ í™œìš©

ë‹¨ì :
  âŒ Polling ì˜¤ë²„í—¤ë“œ
  âŒ ë™ì‹œì„± ì œí•œ
  âŒ PostgreSQL ë¶€í•˜ ì¦ê°€

ì í•©í•œ ê²½ìš°:
  - íŠ¸ë˜í”½ ë‚®ìŒ
  - ê¸°ì¡´ PostgreSQL í™œìš©
  - ë‹¨ìˆœí•œ êµ¬ì¡° ì„ í˜¸
```

### ëŒ€ì•ˆ 3: Kafka (Event Sourcing)

```yaml
êµ¬ì¡°:
  API â†’ Kafka â†’ Consumer â†’ PostgreSQL

ì¥ì :
  âœ… ì´ë²¤íŠ¸ ì†Œì‹±
  âœ… ì¬ìƒ ê°€ëŠ¥ (Replay)
  âœ… ë†’ì€ ì²˜ë¦¬ëŸ‰
  âœ… ë¶„ì‚° ì²˜ë¦¬

ë‹¨ì :
  âŒ Kafka ìš´ì˜ ë³µì¡ë„
  âŒ ë¦¬ì†ŒìŠ¤ ìš”êµ¬ ë†’ìŒ
  âŒ Overkillì¼ ìˆ˜ ìˆìŒ

ì í•©í•œ ê²½ìš°:
  - ëŒ€ê·œëª¨ íŠ¸ë˜í”½
  - ì´ë²¤íŠ¸ ê¸°ë°˜ ì•„í‚¤í…ì²˜
  - ê°ì‚¬(Audit) í•„ìš”
```

### ëŒ€ì•ˆ 4: Redis Streams (ê°€ë²¼ìš´ MQ)

```yaml
êµ¬ì¡°:
  API â†’ Redis Streams â†’ Consumer Group â†’ PostgreSQL

ì¥ì :
  âœ… Redis ì¬ì‚¬ìš©
  âœ… ë¹ ë¥¸ ì„±ëŠ¥
  âœ… Consumer Group
  âœ… ë©”ëª¨ë¦¬ ê¸°ë°˜

ë‹¨ì :
  âŒ Persistence ì•½í•¨
  âŒ ë©”ëª¨ë¦¬ ì œí•œ
  âŒ ë³µì¡í•œ ë¼ìš°íŒ… ì–´ë ¤ì›€

ì í•©í•œ ê²½ìš°:
  - ì´ë¯¸ Redis ì‚¬ìš© ì¤‘
  - ë‹¨ìˆœí•œ í í•„ìš”
  - ë©”ëª¨ë¦¬ ì¶©ë¶„
```

---

## ğŸ¯ ê¶Œì¥ ì‚¬í•­

### í˜„ì¬ êµ¬ì¡° ìœ ì§€ (WAL + MQ) ì í•©í•œ ê²½ìš°

```yaml
âœ… ë‹¤ìŒ ì¡°ê±´ì„ ë§Œì¡±í•˜ë©´ í˜„ì¬ êµ¬ì¡° ê¶Œì¥:

1. ë†’ì€ ì•ˆì •ì„± ìš”êµ¬
   - ë°ì´í„° ì†ì‹¤ ìµœì†Œí™”
   - ì‘ì—… ì¶”ì  í•„ìš”

2. ì¤‘ê°„ ê·œëª¨ íŠ¸ë˜í”½
   - ì´ˆë‹¹ 100-1000 ìš”ì²­
   - Worker 2-10ê°œ

3. ë³µì¡í•œ ì‘ì—…
   - S3 ì—…ë¡œë“œ + PostgreSQL
   - ì—¬ëŸ¬ ë‹¨ê³„ ì‘ì—…
   - ì¬ì‹œë„ í•„ìš”

4. ìš´ì˜ ì—­ëŸ‰
   - RabbitMQ ìš´ì˜ ê°€ëŠ¥
   - SQLite ê´€ë¦¬ ê°€ëŠ¥
```

### ë‹¨ìˆœí™” ê³ ë ¤ (RabbitMQë§Œ) ì í•©í•œ ê²½ìš°

```yaml
âœ… ë‹¤ìŒ ì¡°ê±´ì´ë©´ ë‹¨ìˆœí™” ê³ ë ¤:

1. ë‚®ì€ íŠ¸ë˜í”½
   - ì´ˆë‹¹ 10-100 ìš”ì²­
   - Worker 1-2ê°œ

2. ë‹¨ìˆœí•œ ì‘ì—…
   - ë‹¨ì¼ ë‹¨ê³„
   - ë¹ ë¥¸ ì²˜ë¦¬ (< 1ì´ˆ)

3. ë©±ë“±ì„± ë³´ì¥ ê°€ëŠ¥
   - ì¤‘ë³µ ì²˜ë¦¬ í—ˆìš©
   - ë˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ ë ˆë²¨ ì¤‘ë³µ ë°©ì§€

4. ìš´ì˜ ë¶€ë‹´ ìµœì†Œí™”
   - ìµœì†Œ ì¸í”„ë¼
   - ë‹¨ìˆœí•œ êµ¬ì¡° ì„ í˜¸
```

---

## ğŸ“ˆ ì„±ëŠ¥ ë¹„êµ

| í•­ëª© | PostgreSQLë§Œ | RabbitMQë§Œ | WAL + MQ (í˜„ì¬) | Kafka |
|-----|-------------|-----------|----------------|-------|
| ì‘ë‹µ ì‹œê°„ | 200ms | 10ms | 10ms | 5ms |
| ì²˜ë¦¬ëŸ‰ | 100 TPS | 1,000 TPS | 1,000 TPS | 10,000 TPS |
| ë³µêµ¬ ê°€ëŠ¥ | âœ… | âœ… | âœ…âœ… | âœ…âœ…âœ… |
| ë³µì¡ë„ | ë‚®ìŒ | ì¤‘ê°„ | ë†’ìŒ | ë§¤ìš° ë†’ìŒ |
| ë¦¬ì†ŒìŠ¤ | ë‚®ìŒ | ì¤‘ê°„ | ì¤‘ê°„ | ë†’ìŒ |
| ìš´ì˜ ë‚œì´ë„ | ì‰¬ì›€ | ë³´í†µ | ì–´ë ¤ì›€ | ë§¤ìš° ì–´ë ¤ì›€ |

---

## ğŸ”§ êµ¬í˜„ ì˜ˆì‹œ

### Worker-Storage SQLite ì´ˆê¸°í™”

```python
# worker_storage/db.py
import sqlite3
from contextlib import contextmanager

class LocalTaskDB:
    def __init__(self, db_path="/data/tasks.db"):
        self.db_path = db_path
        self._init_db()
    
    def _init_db(self):
        conn = sqlite3.connect(self.db_path)
        
        # WAL ëª¨ë“œ í™œì„±í™”
        conn.execute("PRAGMA journal_mode=WAL")
        conn.execute("PRAGMA synchronous=NORMAL")
        conn.execute("PRAGMA wal_autocheckpoint=1000")
        
        # í…Œì´ë¸” ìƒì„±
        conn.execute("""
            CREATE TABLE IF NOT EXISTS tasks (
                task_id TEXT PRIMARY KEY,
                status TEXT NOT NULL,
                data BLOB,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)
        
        # ì¸ë±ìŠ¤
        conn.execute("CREATE INDEX IF NOT EXISTS idx_status ON tasks(status)")
        conn.execute("CREATE INDEX IF NOT EXISTS idx_created_at ON tasks(created_at)")
        
        conn.commit()
        conn.close()
    
    @contextmanager
    def get_conn(self):
        conn = sqlite3.connect(self.db_path)
        try:
            yield conn
            conn.commit()
        except Exception as e:
            conn.rollback()
            raise e
        finally:
            conn.close()
    
    def insert_task(self, task_id: str, status: str, data: bytes = None):
        with self.get_conn() as conn:
            conn.execute(
                "INSERT OR REPLACE INTO tasks (task_id, status, data, updated_at) VALUES (?, ?, ?, CURRENT_TIMESTAMP)",
                (task_id, status, data)
            )
    
    def update_status(self, task_id: str, status: str):
        with self.get_conn() as conn:
            conn.execute(
                "UPDATE tasks SET status = ?, updated_at = CURRENT_TIMESTAMP WHERE task_id = ?",
                (status, task_id)
            )
    
    def delete_task(self, task_id: str):
        with self.get_conn() as conn:
            conn.execute("DELETE FROM tasks WHERE task_id = ?", (task_id,))
    
    def get_pending_tasks(self):
        with self.get_conn() as conn:
            cursor = conn.execute(
                "SELECT task_id, data FROM tasks WHERE status = 'processing' ORDER BY created_at"
            )
            return cursor.fetchall()
    
    def checkpoint(self):
        """ìˆ˜ë™ ì²´í¬í¬ì¸íŠ¸"""
        with self.get_conn() as conn:
            conn.execute("PRAGMA wal_checkpoint(TRUNCATE)")

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
local_db = LocalTaskDB()
```

### Celery Worker í†µí•©

```python
# worker_storage/tasks.py
from celery import Celery
from .db import local_db
import boto3

celery_app = Celery('worker_storage', broker='amqp://k8s-rabbitmq')

s3_client = boto3.client('s3')

@celery_app.task(bind=True, max_retries=3)
def image_uploader(self, image_data: bytes, user_id: str, filename: str):
    task_id = self.request.id
    
    try:
        # 1. WALì— ê¸°ë¡
        local_db.insert_task(task_id, 'processing', image_data)
        
        # 2. S3 ì—…ë¡œë“œ
        s3_key = f"users/{user_id}/{filename}"
        s3_client.put_object(
            Bucket='sesacthon-images',
            Key=s3_key,
            Body=image_data
        )
        
        s3_url = f"https://sesacthon-images.s3.amazonaws.com/{s3_key}"
        
        # 3. PostgreSQL ì €ì¥
        # (ì—¬ê¸°ì„œëŠ” ìƒëµ)
        
        # 4. WAL ì •ë¦¬
        local_db.delete_task(task_id)
        
        return {"status": "success", "s3_url": s3_url}
        
    except Exception as e:
        # ì¬ì‹œë„
        local_db.update_status(task_id, 'failed')
        raise self.retry(exc=e, countdown=5)


@celery_app.task
def recover_pending_tasks():
    """
    Worker ì‹œì‘ ì‹œ ë¯¸ì™„ë£Œ ì‘ì—… ë³µêµ¬
    """
    pending = local_db.get_pending_tasks()
    
    for task_id, data in pending:
        # ì¬ì²˜ë¦¬
        image_uploader.apply_async(
            args=(data, "unknown", "recovered"),
            task_id=task_id
        )
```

---

## ğŸ“ ê²°ë¡ 

### í˜„ì¬ WAL + MQ êµ¬ì¡°

```yaml
í‰ê°€: âœ… ì í•©

ì´ìœ :
  1. ë†’ì€ ì•ˆì •ì„± (ì´ì¤‘ ì˜ì†í™”)
  2. ë¹ ë¥¸ ì‘ë‹µ (ë¹„ë™ê¸°)
  3. ë³µêµ¬ ê°€ëŠ¥ (WAL + MQ)
  4. ì¤‘ë³µ ë°©ì§€ (ë¡œì»¬ ì¶”ì )

íŠ¸ë ˆì´ë“œì˜¤í”„:
  - ë³µì¡ë„ ì¦ê°€ (ê´€ë¦¬ ê°€ëŠ¥í•œ ìˆ˜ì¤€)
  - ë¦¬ì†ŒìŠ¤ ì‚¬ìš© (Workerë‹¹ 40GB â†’ ì¶©ë¶„)

ê¶Œì¥ ì‚¬í•­:
  - í˜„ì¬ êµ¬ì¡° ìœ ì§€
  - ëª¨ë‹ˆí„°ë§ ê°•í™” (WAL íŒŒì¼ í¬ê¸°, MQ ê¹Šì´)
  - ì •ê¸°ì  ì²´í¬í¬ì¸íŠ¸
```

---

**ìµœì¢… ì—…ë°ì´íŠ¸**: 2025-11-08  
**ì•„í‚¤í…ì²˜ ë²„ì „**: v0.6.0 (14-Node)


# ğŸ“Š Prometheus/Grafana ëª¨ë‹ˆí„°ë§ ê°€ì´ë“œ

> **7-Node ì•„í‚¤í…ì²˜ì—ì„œ API ë° Worker ì„œë¹„ìŠ¤ ëª¨ë‹ˆí„°ë§**  
> **1 Master + 2 Workers + 4 Infrastructure**

## ğŸ“‹ ëª©ì°¨

1. [ì•„í‚¤í…ì²˜ ê°œìš”](#ì•„í‚¤í…ì²˜-ê°œìš”)
2. [ServiceMonitor ì„¤ì •](#servicemonitor-ì„¤ì •)
3. [PrometheusRule ì•Œë¦¼](#prometheusrule-ì•Œë¦¼)
4. [Grafana Dashboard](#grafana-dashboard)
5. [FastAPI ë©”íŠ¸ë¦­ êµ¬í˜„](#fastapi-ë©”íŠ¸ë¦­-êµ¬í˜„)
6. [ë°°í¬ ë° í™•ì¸](#ë°°í¬-ë°-í™•ì¸)

---

## ğŸ—ï¸ ì•„í‚¤í…ì²˜ ê°œìš”

### ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ

```mermaid
graph TB
    subgraph "Worker-1 (Application)"
        A1[API Services<br/>waste, auth, userinfo<br/>location, recycle-info<br/>chat-llm<br/>:8000/metrics]
    end
    
    subgraph "Worker-2 (Async Workers)"
        W1[storage-worker<br/>:8000/metrics]
        W2[ai-worker<br/>:8000/metrics]
    end
    
    subgraph "Monitoring Node"
        SM1[ServiceMonitor<br/>API]
        SM2[ServiceMonitor<br/>Worker]
        P[Prometheus<br/>k8s-monitoring]
        G[Grafana<br/>k8s-monitoring]
    end
    
    A1 --> SM1
    W1 & W2 --> SM2
    SM1 & SM2 --> P
    P --> G
    
    style P fill:#ff9999
    style G fill:#99ccff
    style A1 fill:#ffeb99
    style W1 fill:#99ff99
    style W2 fill:#99ff99
```

### ë…¸ë“œ ë°°ì¹˜

```
7-Node ì•„í‚¤í…ì²˜:
â”œâ”€ k8s-master (t3.large, 8GB)
â”‚  â””â”€ Control Plane
â”‚
â”œâ”€ k8s-worker-1 (t3.medium, 4GB) - Application
â”‚  â””â”€ API Services (ëª¨ë“  ë„ë©”ì¸ í†µí•©)
â”‚     â””â”€ /metrics ì—”ë“œí¬ì¸íŠ¸
â”‚
â”œâ”€ k8s-worker-2 (t3.medium, 4GB) - Async Workers
â”‚  â”œâ”€ storage-worker
â”‚  â””â”€ ai-worker
â”‚     â””â”€ /metrics ì—”ë“œí¬ì¸íŠ¸
â”‚
â””â”€ k8s-monitoring (t3.medium, 4GB)
   â”œâ”€ Prometheus
   â”‚  â”œâ”€ ServiceMonitor: API (Worker-1)
   â”‚  â”œâ”€ ServiceMonitor: Workers (Worker-2)
   â”‚  â”œâ”€ PrometheusRule (ì•Œë¦¼ ê·œì¹™)
   â”‚  â””â”€ TSDB (7ì¼ retention)
   â”‚
   â””â”€ Grafana
      â”œâ”€ API Dashboard
      â”œâ”€ Worker Dashboard
      â””â”€ Alerting
```

---

## ğŸ” ServiceMonitor ì„¤ì •

### API ServiceMonitor

**íŒŒì¼**: `k8s/monitoring/servicemonitor-api.yaml`

```yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: api-services
  namespace: monitoring
spec:
  selector:
    matchLabels:
      component: api  # API Serviceì— ì´ ë¼ë²¨ í•„ìˆ˜
  
  endpoints:
    - port: metrics
      path: /metrics
      interval: 30s
```

**ì¶”ì í•˜ëŠ” ë©”íŠ¸ë¦­**:
- `http_requests_total`: ì „ì²´ ìš”ì²­ ìˆ˜
- `http_request_duration_seconds`: ì‘ë‹µ ì‹œê°„
- `http_requests_in_progress`: ì§„í–‰ ì¤‘ì¸ ìš”ì²­
- `process_*`: í”„ë¡œì„¸ìŠ¤ ë©”íŠ¸ë¦­ (CPU, ë©”ëª¨ë¦¬)
- `python_*`: Python ëŸ°íƒ€ì„ ë©”íŠ¸ë¦­

### Worker ServiceMonitor

**íŒŒì¼**: `k8s/monitoring/servicemonitor-worker.yaml`

```yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: worker-services
  namespace: monitoring
spec:
  selector:
    matchLabels:
      component: worker  # Worker Serviceì— ì´ ë¼ë²¨ í•„ìˆ˜
  
  endpoints:
    - port: metrics
      path: /metrics
      interval: 30s
```

**ì¶”ì í•˜ëŠ” ë©”íŠ¸ë¦­**:
- `celery_task_*`: Celery íƒœìŠ¤í¬ ë©”íŠ¸ë¦­
- `rabbitmq_queue_*`: RabbitMQ í ë©”íŠ¸ë¦­
- `gpt_api_*`: GPT API í˜¸ì¶œ ë©”íŠ¸ë¦­
- `s3_upload_*`: S3 ì—…ë¡œë“œ ë©”íŠ¸ë¦­

---

## ğŸš¨ PrometheusRule ì•Œë¦¼

**íŒŒì¼**: `k8s/monitoring/prometheusrule-alerts.yaml`

### API ì•Œë¦¼ ê·œì¹™

| Alert | Condition | Severity | Description |
|-------|-----------|----------|-------------|
| **APIHighErrorRate** | ì—ëŸ¬ìœ¨ > 5% (5ë¶„) | critical | 5xx ì—ëŸ¬ ê¸‰ì¦ |
| **APIHighLatency** | P95 > 2s (5ë¶„) | warning | ì‘ë‹µ ì†ë„ ì €í•˜ |
| **APIPodDown** | Available < 1 (1ë¶„) | critical | Pod ë‹¤ìš´ |
| **APIHighCPU** | CPU > 80% (10ë¶„) | warning | CPU ê³¼ë¶€í•˜ |
| **APIHighMemory** | Memory > 80% (10ë¶„) | warning | ë©”ëª¨ë¦¬ ë¶€ì¡± |

### Worker ì•Œë¦¼ ê·œì¹™

| Alert | Condition | Severity | Description |
|-------|-----------|----------|-------------|
| **CeleryQueueHigh** | Queue > 1000 (5ë¶„) | warning | í ì ì²´ |
| **CeleryDLQNotEmpty** | DLQ > 0 (1ë¶„) | critical | ì‹¤íŒ¨ ë©”ì‹œì§€ ë°œìƒ |
| **WorkerPodDown** | Available < 1 (1ë¶„) | critical | Worker Pod ë‹¤ìš´ |
| **GPTAPIHighLatency** | P95 > 30s (10ë¶„) | warning | GPT API ëŠë¦¼ |
| **GPTAPIErrorRate** | ì—ëŸ¬ìœ¨ > 10% (5ë¶„) | critical | GPT API ì—ëŸ¬ |
| **S3UploadFailure** | Failures > 0 (1ë¶„) | critical | S3 ì—…ë¡œë“œ ì‹¤íŒ¨ |

### Infrastructure ì•Œë¦¼ ê·œì¹™

| Alert | Condition | Severity | Description |
|-------|-----------|----------|-------------|
| **RabbitMQDown** | up == 0 (1ë¶„) | critical | RabbitMQ ë‹¤ìš´ |
| **PostgreSQLDown** | up == 0 (1ë¶„) | critical | PostgreSQL ë‹¤ìš´ |
| **RedisDown** | up == 0 (1ë¶„) | critical | Redis ë‹¤ìš´ |
| **PostgreSQLDiskFull** | Disk < 10% (5ë¶„) | critical | ë””ìŠ¤í¬ ë¶€ì¡± |

---

## ğŸ“ˆ Grafana Dashboard

**íŒŒì¼**: `k8s/monitoring/grafana-dashboard-api.json`

### Dashboard íŒ¨ë„

```mermaid
graph TD
    D[Ecoeco API Dashboard]
    
    D --> P1[API Request Rate<br/>req/s per service]
    D --> P2[API Error Rate %<br/>5xx errors]
    D --> P3[API Latency P95<br/>seconds]
    D --> P4[API Pod Status<br/>available replicas]
    D --> P5[API CPU Usage %<br/>per pod]
    D --> P6[API Memory Usage MB<br/>per pod]
    D --> P7[Worker Queue Size<br/>messages]
    D --> P8[GPT API Latency<br/>seconds]
    
    style D fill:#6699ff
    style P1 fill:#ffeb99
    style P2 fill:#ff9999
    style P3 fill:#ffeb99
    style P4 fill:#99ff99
    style P5 fill:#ffcccc
    style P6 fill:#ffcccc
    style P7 fill:#ccffcc
    style P8 fill:#ffeb99
```

### ì£¼ìš” ì¿¼ë¦¬

**API Request Rate**:
```promql
sum(rate(http_requests_total{component="api"}[5m])) by (service)
```

**API Error Rate**:
```promql
sum(rate(http_requests_total{component="api",status=~"5.."}[5m])) by (service) /
sum(rate(http_requests_total{component="api"}[5m])) by (service) * 100
```

**API Latency P95**:
```promql
histogram_quantile(0.95, 
  sum(rate(http_request_duration_seconds_bucket{component="api"}[5m])) by (service, le)
)
```

---

## ğŸ’» FastAPI ë©”íŠ¸ë¦­ êµ¬í˜„

### 1. ì˜ì¡´ì„± ì„¤ì¹˜

```bash
# requirements.txtì— ì¶”ê°€
prometheus-client==0.19.0
```

### 2. ëª¨ë‹ˆí„°ë§ ëª¨ë“ˆ ì‚¬ìš©

**íŒŒì¼**: `app/monitoring.py` (ì´ë¯¸ ìƒì„±ë¨)

**API ì„œë¹„ìŠ¤ì— ì ìš©**:

```python
# app/main.py
from fastapi import FastAPI
from app.monitoring import setup_monitoring

app = FastAPI(title="Waste API")

# Prometheus ëª¨ë‹ˆí„°ë§ ì„¤ì •
setup_monitoring(app, service_name="waste-api")

@app.get("/api/v1/waste/classify")
async def classify_waste(image_url: str):
    # ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
    return {"result": "plastic"}
```

**ìë™ìœ¼ë¡œ ì¶”ê°€ë˜ëŠ” ì—”ë“œí¬ì¸íŠ¸**:
- `GET /metrics` - Prometheus ë©”íŠ¸ë¦­
- `GET /health` - Liveness probe
- `GET /ready` - Readiness probe

### 3. Celery Task ë©”íŠ¸ë¦­

```python
# workers/storage/tasks.py
from app.monitoring import track_celery_task
from celery import shared_task

@shared_task
@track_celery_task("image_upload")
def image_upload_task(image_path: str):
    # S3 ì—…ë¡œë“œ ë¡œì§
    return {"status": "uploaded"}
```

### 4. GPT API ë©”íŠ¸ë¦­

```python
# workers/ai/gpt_client.py
from app.monitoring import track_gpt_api_call
import openai

@track_gpt_api_call("gpt-4o-mini")
async def call_gpt(prompt: str):
    response = await openai.ChatCompletion.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}]
    )
    return response
```

### 5. S3 ì—…ë¡œë“œ ë©”íŠ¸ë¦­

```python
# app/storage/s3.py
from app.monitoring import track_s3_upload
import boto3

@track_s3_upload()
async def upload_to_s3(file_path: str, bucket: str, key: str):
    s3 = boto3.client('s3')
    s3.upload_file(file_path, bucket, key)
    return f"s3://{bucket}/{key}"
```

---

## ğŸš€ ë°°í¬ ë° í™•ì¸

### 1. ServiceMonitor ë°°í¬

```bash
# ServiceMonitor ì ìš©
kubectl apply -f k8s/monitoring/servicemonitor-api.yaml
kubectl apply -f k8s/monitoring/servicemonitor-worker.yaml

# í™•ì¸
kubectl get servicemonitor -n monitoring
```

### 2. PrometheusRule ë°°í¬

```bash
# PrometheusRule ì ìš©
kubectl apply -f k8s/monitoring/prometheusrule-alerts.yaml

# í™•ì¸
kubectl get prometheusrule -n monitoring
```

### 3. Grafana Dashboard ì„í¬íŠ¸

```bash
# Grafana UIì—ì„œ Import
# k8s/monitoring/grafana-dashboard-api.json ì—…ë¡œë“œ
```

ë˜ëŠ” ConfigMapìœ¼ë¡œ ìë™ ë°°í¬:

```bash
kubectl create configmap grafana-dashboard-api \
  --from-file=k8s/monitoring/grafana-dashboard-api.json \
  -n monitoring
```

### 4. API Service ë¼ë²¨ ì¶”ê°€

**Kubernetes Serviceì— `component: api` ë¼ë²¨ í•„ìˆ˜**:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: waste-api
  labels:
    component: api  # â­ í•„ìˆ˜
spec:
  selector:
    app: waste-api
  ports:
    - name: http
      port: 8000
    - name: metrics  # â­ í•„ìˆ˜
      port: 8000
      targetPort: 8000
```

### 5. Prometheus í™•ì¸

```bash
# Prometheus UI ì ‘ì†
kubectl port-forward svc/prometheus-operated -n monitoring 9090:9090

# ë¸Œë¼ìš°ì €: http://localhost:9090
# Targets í™•ì¸: Status -> Targets
```

**í™•ì¸ ì‚¬í•­**:
- `api-services` ServiceMonitor: 6ê°œ API íƒ€ê²Ÿ UP
- `worker-services` ServiceMonitor: 2ê°œ Worker íƒ€ê²Ÿ UP

### 6. Grafana í™•ì¸

```bash
# Grafana UI ì ‘ì†
kubectl port-forward svc/grafana -n monitoring 3000:3000

# ë¸Œë¼ìš°ì €: http://localhost:3000
# Dashboard -> Import -> grafana-dashboard-api.json
```

**í™•ì¸ ì‚¬í•­**:
- API Request Rate ê·¸ë˜í”„ì— ë°ì´í„° í‘œì‹œ
- API Error Rate < 5%
- API Latency < 2s
- Pod Status = Available

---

## ğŸ”§ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ServiceMonitorê°€ íƒ€ê²Ÿì„ ì°¾ì§€ ëª»í•˜ëŠ” ê²½ìš°

```bash
# Service ë¼ë²¨ í™•ì¸
kubectl get svc -n default -L component

# ë¼ë²¨ì´ ì—†ë‹¤ë©´ ì¶”ê°€
kubectl label svc waste-api component=api -n default
```

### ë©”íŠ¸ë¦­ì´ ìˆ˜ì§‘ë˜ì§€ ì•ŠëŠ” ê²½ìš°

```bash
# Podì˜ /metrics ì—”ë“œí¬ì¸íŠ¸ í™•ì¸
kubectl exec -it <pod-name> -- curl localhost:8000/metrics

# Prometheusê°€ ìŠ¤í¬ë˜í•‘í•˜ëŠ”ì§€ í™•ì¸
# Prometheus UI -> Status -> Targets
```

### Grafana Dashboardê°€ ë¹ˆ ê²½ìš°

```bash
# Prometheus ë°ì´í„° ì†ŒìŠ¤ í™•ì¸
# Grafana -> Configuration -> Data Sources -> Prometheus

# Query í…ŒìŠ¤íŠ¸
http_requests_total
```

---

## ğŸ“Š ê¸°ëŒ€ ê²°ê³¼

### Prometheus Targets

```
api-services (6/6 up)
â”œâ”€ waste-api (UP)
â”œâ”€ auth-api (UP)
â”œâ”€ userinfo-api (UP)
â”œâ”€ location-api (UP)
â”œâ”€ recycle-info-api (UP)
â””â”€ chat-llm-api (UP)

worker-services (2/2 up)
â”œâ”€ storage-worker (UP)
â””â”€ ai-worker (UP)
```

### Grafana Dashboard

- **API Request Rate**: 10-100 req/s
- **API Error Rate**: < 1%
- **API Latency P95**: < 1s
- **Worker Queue Size**: < 100 messages
- **GPT API Latency**: < 20s

---

## ğŸ”— ê´€ë ¨ ë¬¸ì„œ

- [Prometheus Operator](https://github.com/prometheus-operator/prometheus-operator)
- [FastAPI Monitoring](../guides/FASTAPI_MONITORING.md)
- [Grafana Dashboards](../guides/GRAFANA_DASHBOARDS.md)

---

**ì‘ì„±ì¼**: 2025-11-06  
**ë²„ì „**: 1.0 (7-Node Architecture)  
**ìƒíƒœ**: âœ… Production Ready


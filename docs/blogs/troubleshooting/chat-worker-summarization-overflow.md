# Chat Worker Summarization Overflow í•´ê²° ë¦¬í¬íŠ¸

## 1. ë¬¸ì œ ë°œê²¬

### ì—ëŸ¬ ë¡œê·¸

```
openai.BadRequestError: Error code: 400
Input tokens exceed the configured limit of 272000 tokens.
Your messages resulted in 915611 tokens.
```

`SummarizationNode`ê°€ ì••ì¶•ì„ ì‹œë„í•  ë•Œ, `summarize_messages()`ì— ì „ë‹¬ëœ `older_messages`ê°€
ëª¨ë¸ ì…ë ¥ í•œë„(272K tokens)ë¥¼ ì´ˆê³¼í•˜ì—¬ í¬ë˜ì‹œ ë°œìƒ.

### ê¸°ì¡´ êµ¬ì¡°

```
User Message (Turn N)
       â”‚
       â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  intent  â”‚
  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  router  â”‚ â† Send API (ë³‘ë ¬ ì‹¤í–‰)
  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â–¼              â–¼              â–¼            â–¼
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚waste_rag â”‚  â”‚ web_search â”‚  â”‚locationâ”‚  â”‚ others â”‚
 â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
      â”‚               â”‚              â”‚            â”‚
      â”‚          ê²°ê³¼ ë¬´ì œí•œ           â”‚            â”‚
      â”‚          (ìˆ˜ë°±KB ê°€ëŠ¥)         â”‚            â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  aggregator   â”‚
              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚     summarize         â”‚
         â”‚                       â”‚
         â”‚  í˜„ì¬ tokens > 272K?  â”‚
         â”‚  â†’ YES: ì••ì¶• ì‹œë„     â”‚
         â”‚                       â”‚
         â”‚  older = msgs[:-80]   â”‚
         â”‚  (~900K tokens)       â”‚
         â”‚        â†“              â”‚
         â”‚  summarize_messages() â”‚
         â”‚  messages_text =      â”‚
         â”‚  ì „ì²´ concat           â”‚
         â”‚        â†“              â”‚
         â”‚  llm.generate(prompt) â”‚ â† ğŸ’¥ 915K > 272K limit
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  âŒ í¬ë˜ì‹œ
```

### ë©”ì‹œì§€ ëˆ„ì  ë©”ì»¤ë‹ˆì¦˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ChatState ì •ì˜:                                                         â”‚
â”‚    messages: Annotated[list[AnyMessage], add_messages]                   â”‚
â”‚                                                                         â”‚
â”‚  ì»¤ìŠ¤í…€ add_messages reducer:                                             â”‚
â”‚    def add_messages(existing, new):                                      â”‚
â”‚        return existing + new    â† í•­ìƒ appendë§Œ, ì‚­ì œ ë¶ˆê°€                 â”‚
â”‚                                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  Turn 1:  messages = [H1, A1]                              ~2K tokens  â”‚
â”‚  Turn 2:  messages = [H1, A1, H2, A2]                     ~4K tokens  â”‚
â”‚  Turn 3:  messages = [..., H3, A3(ì›¹ê²€ìƒ‰ ë‹µë³€)]            ~60K tokens  â”‚
â”‚  Turn 4:  messages = [..., H4, A4(ì›¹ê²€ìƒ‰ ë‹µë³€)]           ~150K tokens  â”‚
â”‚  ...                                                                    â”‚
â”‚  Turn N:  messages = [H1, A1, ..., HN-1, AN-1, HN]      ~915K tokens  â”‚
â”‚                                                                         â”‚
â”‚  â†’ messagesëŠ” ì ˆëŒ€ ì¤„ì–´ë“¤ì§€ ì•ŠìŒ                                           â”‚
â”‚  â†’ ë§¤ í„´ë§ˆë‹¤ checkpointì— ì „ì²´ íˆìŠ¤í† ë¦¬ ì €ì¥                                â”‚
â”‚  â†’ Redis ë©”ëª¨ë¦¬ + ì§ë ¬í™” ë¹„ìš©ë„ ë¬´í•œ ì¦ê°€                                   â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### SummarizationNodeì˜ í•œê³„

ë¸”ë¡œê·¸ ê¸€([rooftopsnow.tistory.com/200](https://rooftopsnow.tistory.com/200))ì˜
OpenCode ê¸°ë°˜ ë™ì  ì„¤ì •ì€ ì ìš©ë˜ì–´ ìˆìœ¼ë‚˜, **ìš”ì•½ ê²°ê³¼ê°€ messagesë¥¼ êµì²´í•˜ì§€ ì•ŠìŒ**:

```python
# í˜„ì¬ SummarizationNode ì¶œë ¥:
return {
    "llm_input_messages": [SystemMessage(ìš”ì•½), ...recent],  # â† answer ë…¸ë“œìš© "ë·°"
    "summary": new_summary,                                   # â† stateì— ì €ì¥
}
# "messages" í•„ë“œ ë¯¸ìˆ˜ì • â†’ checkpointì— ì „ì²´ íˆìŠ¤í† ë¦¬ ê·¸ëŒ€ë¡œ ìœ ì§€
```

| ì ìš©ë¨ (ë¸”ë¡œê·¸ ê¸€)               | ëˆ„ë½ë¨                               |
|-------------------------------|--------------------------------------|
| ë™ì  íŠ¸ë¦¬ê±° (272K for GPT-5.2) | ìš”ì•½ ì…ë ¥ í¬ê¸° ì œí•œ                     |
| ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬                  | messages ë¦¬ìŠ¤íŠ¸ ì‹¤ì œ ì‚­ì œ (trim)        |
| PRUNE_PROTECT (40K tokens)    | RemoveMessage íŒ¨í„´                    |
| êµ¬ì¡°í™” 5ì„¹ì…˜ ìš”ì•½                | checkpoint í¬ê¸° bounded ë³´ì¥           |
| ìš”ì•½ í† í° 15% (60K)            |                                      |

---

## 2. í•´ê²° ë°©ì•ˆ ëª¨ìƒ‰

### ë°©ì•ˆ A: ì…ë ¥ Truncation (band-aid)

`summarize_messages()`ì˜ ì…ë ¥ì„ ëª¨ë¸ í•œë„ ë‚´ë¡œ ì˜ë¼ì„œ crashë§Œ ë°©ì§€.

```python
# web_search ê²°ê³¼ ì œí•œ
if len(result) > 50_000:
    result = result[:50_000]

# summarize_messages ì…ë ¥ ì œí•œ
if len(messages_text) > 800_000:
    messages_text = messages_text[-800_000:]  # tail ë³´ì¡´
```

- ì¥ì : ë³€ê²½ ìµœì†Œ, crash ì¦‰ì‹œ í•´ê²°
- ë‹¨ì : messages ë¬´í•œ ëˆ„ì ì€ ê·¸ëŒ€ë¡œ. checkpoint/Redis í¬ê¸° ì¦ê°€ ì§€ì†

### ë°©ì•ˆ B: trimMessages (ë·° ë ˆë²¨)

LLM í˜¸ì¶œ ì „ì— ìµœê·¼ Nê°œë§Œ ì˜ë¼ì„œ ì „ë‹¬ (LangGraph docsì˜ "Trimming" íŒ¨í„´):

```python
from langchain_core.messages import trim_messages

trimmed = trim_messages(state["messages"], max_tokens=200_000, strategy="last")
response = await model.invoke(trimmed)
```

- ì¥ì : answer ë…¸ë“œë§Œ ìˆ˜ì •
- ë‹¨ì : checkpointì—ëŠ” ì „ì²´ íˆìŠ¤í† ë¦¬ ìœ ì§€. Redis ë©”ëª¨ë¦¬ ê³„ì† ì¦ê°€

### ë°©ì•ˆ C: RemoveMessage (ê·¼ë³¸ í•´ê²°)

LangGraph ê³µì‹ íŒ¨í„´ìœ¼ë¡œ ì‹¤ì œ messagesë¥¼ ì‚­ì œ:

```python
from langchain_core.messages import RemoveMessage

return {
    "messages": [RemoveMessage(id=m.id) for m in older] + [SystemMessage(ìš”ì•½)],
    "summary": new_summary,
}
```

- ì¥ì : checkpoint ìì²´ê°€ bounded. Redis ë©”ëª¨ë¦¬ ì•ˆì •
- ë‹¨ì : reducer êµì²´ í•„ìš” (ì»¤ìŠ¤í…€ â†’ LangGraph ë‚´ì¥)

---

## 3. ì±„íƒì•ˆ: RemoveMessage íŒ¨í„´

### LangGraph ê³µì‹ ë ˆí¼ëŸ°ìŠ¤

[LangGraph - Add Memory (Summarization)](https://docs.langchain.com/oss/javascript/langgraph/add-memory)

```typescript
// ê³µì‹ íŒ¨í„´: ìš”ì•½ í›„ older messagesë¥¼ RemoveMessageë¡œ ì‚­ì œ
const summarizeConversation = async (state) => {
  const summary = state.summary || "";
  const summaryMsg = summary
    ? `Extend this summary: ${summary}`
    : "Create a summary:";

  const messages = [...state.messages, new HumanMessage(summaryMsg)];
  const response = await model.invoke(messages);

  return {
    summary: response.content,
    messages: state.messages.slice(0, -2)
      .map(m => new RemoveMessage({ id: m.id }))  // â† ì‹¤ì œ ì‚­ì œ
  };
};
```

í•µì‹¬: ë…¸ë“œê°€ `RemoveMessage`ë¥¼ ë°˜í™˜í•˜ë©´, `add_messages` reducerê°€ í•´ë‹¹ IDì˜ ë©”ì‹œì§€ë¥¼
ê¸°ì¡´ ë¦¬ìŠ¤íŠ¸ì—ì„œ **ì œê±°**. checkpointì—ë„ ì œê±°ëœ ìƒíƒœë¡œ ì €ì¥ë¨.

---

## 4. ì±„íƒì•ˆ ì´ìœ : Reducer êµ¬ì¡°ì™€ RemoveMessageì˜ í•„ìš”ì„±

### LangGraph State = Reducer ê¸°ë°˜

LangGraphì˜ state í•„ë“œëŠ” **reducer í•¨ìˆ˜**ë¥¼ í†µí•´ì„œë§Œ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤.
ë…¸ë“œê°€ ê°’ì„ ë°˜í™˜í•˜ë©´ reducerê°€ `ê¸°ì¡´ê°’`ê³¼ `ìƒˆê°’`ì„ ë³‘í•©í•©ë‹ˆë‹¤:

```
ë…¸ë“œ ë°˜í™˜: {"messages": [new_msg]}
                   â”‚
                   â–¼
         reducer(existing, new)
         = existing + new        â† ê²°ê³¼ê°€ checkpointì— ì €ì¥
```

ì´ êµ¬ì¡°ì—ì„œëŠ” ë…¸ë“œê°€ **ì§ì ‘ messagesë¥¼ êµì²´í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤**.
í•­ìƒ appendë§Œ ê°€ëŠ¥í•˜ë¯€ë¡œ, messagesëŠ” ë‹¨ì¡°ì¦ê°€í•©ë‹ˆë‹¤:

```
Turn 1 â†’ reducer([], [H1, A1])           = [H1, A1]
Turn 2 â†’ reducer([H1,A1], [H2, A2])      = [H1, A1, H2, A2]
Turn 3 â†’ reducer([...], [H3, A3])        = [H1, A1, ..., H3, A3]
  ...
Turn N â†’ reducer([...], [HN, AN])        = [ì „ì²´ ëˆ„ì ]  â† unbounded!
```

### RemoveMessage = Reducerì—ê²Œ ë³´ë‚´ëŠ” "ì‚­ì œ ì‹œê·¸ë„"

`RemoveMessage`ëŠ” ì¼ë°˜ ë©”ì‹œì§€ê°€ ì•„ë‹Œ **ì œì–´ ë©”ì‹œì§€**ì…ë‹ˆë‹¤.
LangGraph ë‚´ì¥ `add_messages` reducerëŠ” ì´ë¥¼ ê°ì§€í•˜ì—¬ ì‚­ì œë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤:

```
ë…¸ë“œ ë°˜í™˜: {"messages": [RemoveMessage(id="H1"), SystemMessage("ìš”ì•½")]}
                   â”‚
                   â–¼
         add_messages(existing, new):
           for msg in new:
             if isinstance(msg, RemoveMessage):
               existing.remove(id=msg.id)   â† ì‚­ì œ!
             else:
               existing.append(msg)          â† ì¶”ê°€
```

ì´ ë©”ì»¤ë‹ˆì¦˜ì´ ì—†ìœ¼ë©´ reducer ê¸°ë°˜ stateì—ì„œ **ê°’ì„ ì¤„ì´ëŠ” ê²ƒì´ êµ¬ì¡°ì ìœ¼ë¡œ ë¶ˆê°€ëŠ¥**í•©ë‹ˆë‹¤.

### ì™œ ì§ì ‘ êµì²´í•˜ë©´ ì•ˆ ë˜ëŠ”ê°€?

```python
# âŒ ì´ë ‡ê²Œ í•˜ë©´?
return {"messages": [SystemMessage("ìš”ì•½"), H_recent, A_recent]}

# reducer ë™ì‘:
# existing = [H1, A1, H2, A2, ..., HN]  (915K tokens)
# new = [SystemMessage, H_recent, A_recent]
# result = existing + new = [H1, ..., HN, SystemMessage, ...]  â† ë” ì»¤ì§!
```

Reducerë¥¼ ìš°íšŒí•˜ë ¤ë©´ LangGraphì˜ state ê´€ë¦¬ ì²´ê³„ë¥¼ ë²—ì–´ë‚˜ì•¼ í•˜ë©°,
checkpoint ì¼ê´€ì„±ì´ ê¹¨ì§‘ë‹ˆë‹¤. `RemoveMessage`ëŠ” ì´ ì œì•½ ë‚´ì—ì„œ
ìœ ì¼í•˜ê²Œ messagesë¥¼ ì¤„ì´ëŠ” ê³µì‹ ë©”ì»¤ë‹ˆì¦˜ì…ë‹ˆë‹¤.

---

## 5. êµ¬í˜„ ë°©ì•ˆ

### ìˆ˜ì • ëŒ€ìƒ íŒŒì¼

| # | íŒŒì¼ | ë³€ê²½ ë‚´ìš© |
|---|------|-----------|
| 1 | `state.py` | ì»¤ìŠ¤í…€ `add_messages` â†’ LangGraph ë‚´ì¥ìœ¼ë¡œ êµì²´ |
| 2 | `summarization.py` | `RemoveMessage` ë°˜í™˜í•˜ë„ë¡ ìˆ˜ì • |
| 3 | `web_search_node.py` | ê²°ê³¼ í¬ê¸° ì œí•œ ìœ ì§€ (ë°©ì–´ì ) |
| 4 | `summarization.py` | ì…ë ¥ truncation ìœ ì§€ (ë°©ì–´ì ) |

### Step 1: Reducer êµì²´ (state.py)

```python
# Before (ì»¤ìŠ¤í…€ â€” RemoveMessage ë¯¸ì§€ì›):
def add_messages(
    existing: list[AnyMessage] | None,
    new: list[AnyMessage] | AnyMessage,
) -> list[AnyMessage]:
    if existing is None:
        existing = []
    if isinstance(new, list):
        return existing + new
    return existing + [new]

# After (LangGraph ë‚´ì¥ â€” RemoveMessage ì§€ì›):
from langgraph.graph.message import add_messages
```

LangGraph ë‚´ì¥ `add_messages`ëŠ”:
- `RemoveMessage` ê°ì§€í•˜ì—¬ ID ê¸°ë°˜ ì‚­ì œ
- ë™ì¼ ID ë©”ì‹œì§€ ì—…ë°ì´íŠ¸ (upsert)
- ê¸°ë³¸ append ë™ì‘ ìœ ì§€

### Step 2: SummarizationNode ì¶œë ¥ ë³€ê²½ (summarization.py)

```python
# Before:
return {
    "llm_input_messages": summarized_messages,  # â† ì„ì‹œ ë·° (stateì— ë¬´ì˜ë¯¸)
    "summary": new_summary,
}

# After:
from langchain_core.messages import RemoveMessage

# older_messagesë¥¼ ì‚­ì œí•˜ê³  ìš”ì•½ SystemMessageë¡œ ëŒ€ì²´
delete_msgs = [RemoveMessage(id=m.id) for m in older_messages if hasattr(m, 'id')]
summary_msg = SystemMessage(content=f"[ì´ì „ ëŒ€í™” ìš”ì•½]\n{new_summary}")

return {
    "messages": delete_msgs + [summary_msg],  # â† reducerê°€ ì‹¤ì œ ì‚­ì œ+ì¶”ê°€ ìˆ˜í–‰
    "summary": new_summary,
}
```

### Step 3: Answer ë…¸ë“œ ìˆ˜ì • (answer_node.py)

`llm_input_messages` ì˜ì¡´ ì œê±°. `messages`ë¥¼ ì§ì ‘ ì‚¬ìš©:

```python
# Before:
messages = state.get("llm_input_messages", state.get("messages", []))

# After:
messages = state.get("messages", [])
# â†’ summarize ë…¸ë“œì—ì„œ ì´ë¯¸ messagesê°€ trimë˜ì–´ ìˆìŒ
```

### ìˆ˜ì • í›„ êµ¬ì¡°

```
Turn N: messages = [H1, A1, ..., HN-1, AN-1, HN]   ~300K tokens
         â”‚
         â–¼
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  SummarizationNode                                      â”‚
   â”‚                                                         â”‚
   â”‚  current_tokens = 300K > 272K â†’ íŠ¸ë¦¬ê±°!                  â”‚
   â”‚                                                         â”‚
   â”‚  recent  = messages[-80:]           ~40K tokens         â”‚
   â”‚  older   = messages[:-80]           ~260K tokens        â”‚
   â”‚                                                         â”‚
   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
   â”‚  â”‚ summarize_messages(older)                    â”‚        â”‚
   â”‚  â”‚   messages_text = concat (max 800K chars)   â”‚        â”‚
   â”‚  â”‚   â†’ llm.generate(prompt)                    â”‚        â”‚
   â”‚  â”‚   â†’ "êµ¬ì¡°í™”ëœ 5ì„¹ì…˜ ìš”ì•½" (â‰¤ 60K tokens)      â”‚        â”‚
   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
   â”‚                                                         â”‚
   â”‚  Return: {                                              â”‚
   â”‚    "messages": [                                        â”‚
   â”‚       RemoveMessage(H1.id),  â† older ì‚­ì œ               â”‚
   â”‚       RemoveMessage(A1.id),                             â”‚
   â”‚       ...                                               â”‚
   â”‚       SystemMessage("ìš”ì•½"),  â† ìš”ì•½ìœ¼ë¡œ ëŒ€ì²´             â”‚
   â”‚    ],                                                   â”‚
   â”‚    "summary": new_summary,                              â”‚
   â”‚  }                                                      â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼ add_messages reducer ì²˜ë¦¬
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  messages = [SystemMessage("ìš”ì•½"), ...recent_80ê°œ]       â”‚
   â”‚             ~100K tokens (bounded!)                      â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚    answer     â”‚ â† messagesì—ì„œ ì§ì ‘ ì½ìŒ
                â”‚              â”‚
                â”‚  messages += â”‚
                â”‚  [AIMessage] â”‚
                â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
                checkpoint ì €ì¥: messages â‰ˆ ~100K tokens (bounded!)
```

### í¬ê¸° ë¹„êµ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Before vs After                                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    â”‚ Before              â”‚ After                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ messages í¬ê¸°       â”‚ ë¬´í•œ ëˆ„ì             â”‚ ~100K tokens (bounded)        â”‚
â”‚ checkpoint í¬ê¸°     â”‚ ë¬´í•œ ì¦ê°€            â”‚ ì•ˆì •ì                          â”‚
â”‚ Redis ë©”ëª¨ë¦¬        â”‚ ì„¸ì…˜ë‹¹ ìˆ˜MB ê°€ëŠ¥      â”‚ ì„¸ì…˜ë‹¹ ~400KB ì´í•˜             â”‚
â”‚ ìš”ì•½ trigger í›„     â”‚ messages ê·¸ëŒ€ë¡œ      â”‚ older ì‚­ì œ + ìš”ì•½ êµì²´         â”‚
â”‚ ë‹¤ìŒ Turn           â”‚ ì´ì „ ì „ì²´ + ìƒˆ ë©”ì‹œì§€ â”‚ ìš”ì•½ + recent + ìƒˆ ë©”ì‹œì§€      â”‚
â”‚ ì¥ê¸° ëŒ€í™” ì•ˆì •ì„±     â”‚ âŒ ì–¸ì  ê°„ crash       â”‚ âœ… í•­ìƒ bounded                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ë°©ì–´ì  truncation ìœ ì§€

`RemoveMessage` ì ìš© í›„ì—ë„, ì²« trigger ì „ messagesê°€ 272Kë¥¼ ë„˜ëŠ” edge case
(ì˜ˆ: ë‹¨ì¼ í„´ì—ì„œ ê±°ëŒ€í•œ ì›¹ê²€ìƒ‰ ê²°ê³¼)ë¥¼ ëŒ€ë¹„í•˜ì—¬ ê¸°ì¡´ truncation fixë„ ìœ ì§€:

```python
# web_search_node.py â€” ê²°ê³¼ 50K chars ì œí•œ
if len(result) > max_result_chars:
    result = result[:max_result_chars]

# summarization.py â€” ìš”ì•½ ì…ë ¥ 800K chars ì œí•œ
if len(messages_text) > max_input_chars:
    messages_text = messages_text[-max_input_chars:]
```

ì´ ë‘ ë‹¨ê³„ ë°©ì–´ë¡œ crashëŠ” ë°©ì§€í•˜ë˜, `RemoveMessage`ë¡œ ê·¼ë³¸ì  í¬ê¸° ì œì–´ë¥¼ ë‹¬ì„±í•©ë‹ˆë‹¤.

---

## ì°¸ì¡°

- [LangGraph - Add Memory (Summarization, Trimming, Deletion)](https://docs.langchain.com/oss/javascript/langgraph/add-memory)
- [OpenCode ë™ì  ì»¨í…ìŠ¤íŠ¸ ì••ì¶• ì „ëµ](https://rooftopsnow.tistory.com/200)
- [LangGraph How-to: Manage Message History](https://langchain-ai.github.io/langgraph/how-tos/manage-conversation-history/)
- Error: `openai.BadRequestError: 915611 tokens > 272000 limit`
- Branch: `fix/web-search-result-truncation`
- PR: TBD (ë°©ì–´ì  truncationì€ ì»¤ë°‹ ì™„ë£Œ, RemoveMessageëŠ” ë³„ë„ ì‘ì—…)

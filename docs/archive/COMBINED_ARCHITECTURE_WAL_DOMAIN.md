# WAL + ë„ë©”ì¸ ë¶„ë¦¬ í†µí•© ì•„í‚¤í…ì²˜

ë¶„ì„ ì¼ì‹œ: 2025-11-06
ì‹œìŠ¤í…œ: Ecoeco Backend (13-Node Cluster)
ì°¸ê³ : Robin Storage, OStore, PostgreSQL WAL

---

## ğŸ¯ í•µì‹¬ ì§ˆë¬¸

**"WALê³¼ ë„ë©”ì¸ ë¶„ë¦¬ë¥¼ ê²°í•©í•˜ë©´ ì–´ë–¤ êµ¬ì¡°ê°€ ë‚˜ì˜¬ì§€, ì¥ì• ì§€ì ì€ ì–´ë–»ê²Œ íŒŒì•…í• ì§€?"**

---

## ğŸ“Š 1. í†µí•© ì•„í‚¤í…ì²˜ ì „ì²´ êµ¬ì¡°

```mermaid
graph TB
    subgraph CP["Control Plane (ì „ì—­ ì¡°ìœ¨)"]
        PG_Auth["ecoeco_auth<br/>(2GB, HA)<br/>ì¸ì¦/ì¸ê°€"]
        PG_Waste["ecoeco_waste<br/>(5GB, HA)<br/>íê¸°ë¬¼ ë¶„ì„"]
        PG_Chat["ecoeco_chat<br/>(3GB, HA)<br/>LLM ì±„íŒ…"]
        PG_Location["ecoeco_location<br/>(1GB, HA)<br/>ìœ„ì¹˜ ì •ë³´"]
        PG_Analytics["ecoeco_analytics<br/>(10GB, Read Replica)<br/>ë¶„ì„/í†µê³„"]
    end
    
    subgraph MQ["Message Queue Layer (ë„ë©”ì¸ë³„ í ë¶„ë¦¬)"]
        RMQ["RabbitMQ Cluster<br/>(Durable Queues, Mnesia WAL)<br/>â”œâ”€ user_input_queue<br/>â”œâ”€ vision_analysis_queue<br/>â”œâ”€ rule_retrieval_queue<br/>â”œâ”€ response_generation_queue<br/>â”œâ”€ auth_queue<br/>â”œâ”€ location_query_queue<br/>â””â”€ analytics_queue"]
    end
    
    subgraph API["API Layer (ë„ë©”ì¸ë³„ ì„œë¹„ìŠ¤)"]
        Waste["waste-api<br/>(t3.small, 2GB)"]
        Auth["auth-api<br/>(t3.micro, 1GB)"]
        Userinfo["userinfo-api<br/>(t3.micro, 1GB)"]
        Location["location-api<br/>(t3.micro, 1GB)"]
        Recycle["recycle-api<br/>(t3.micro, 1GB)"]
        ChatLLM["chat-llm-api<br/>(t3.small, 2GB)"]
    end
    
    subgraph Worker["Worker Layer (ë¡œì»¬ WAL ì ìš©)"]
        WS["Worker-Storage<br/>(t3.medium, 4GB)<br/>â”œâ”€ image-uploader<br/>â”œâ”€ rule-retriever<br/>â””â”€ â­ WAL: task_queue.db"]
        WAI["Worker-AI<br/>(t3.medium, 4GB)<br/>â”œâ”€ gpt5-analyzer<br/>â”œâ”€ response-generator<br/>â””â”€ â­ WAL: task_queue.db<br/>    â”œâ”€ gpt_cache<br/>    â””â”€ retry_queue"]
    end
    
    PG_Waste -.->|ë¹„ë™ê¸° ë™ê¸°í™”| WS
    PG_Waste -.->|ë¹„ë™ê¸° ë™ê¸°í™”| WAI
    
    Waste -->|Publish| RMQ
    Auth -->|Publish| RMQ
    ChatLLM -->|Publish| RMQ
    
    RMQ -->|Consume| WS
    RMQ -->|Consume| WAI
    
    Waste --> PG_Waste
    Auth --> PG_Auth
    Userinfo --> PG_Auth
    Location --> PG_Location
    Recycle --> PG_Waste
    ChatLLM --> PG_Chat
    
    style PG_Auth fill:#3498DB,stroke:#2874A6,stroke-width:2px,color:#fff
    style PG_Waste fill:#3498DB,stroke:#2874A6,stroke-width:2px,color:#fff
    style PG_Chat fill:#3498DB,stroke:#2874A6,stroke-width:2px,color:#fff
    style PG_Location fill:#3498DB,stroke:#2874A6,stroke-width:2px,color:#fff
    style PG_Analytics fill:#3498DB,stroke:#2874A6,stroke-width:2px,color:#fff
    style RMQ fill:#F39C12,stroke:#C87F0A,stroke-width:3px,color:#000
    style Waste fill:#cce5ff,stroke:#007bff,stroke-width:2px,color:#000
    style Auth fill:#FFE066,stroke:#F59F00,stroke-width:2px,color:#000
    style Userinfo fill:#FFE066,stroke:#F59F00,stroke-width:2px,color:#000
    style Location fill:#cce5ff,stroke:#007bff,stroke-width:2px,color:#000
    style Recycle fill:#cce5ff,stroke:#007bff,stroke-width:2px,color:#000
    style ChatLLM fill:#cce5ff,stroke:#007bff,stroke-width:2px,color:#000
    style WS fill:#9370DB,stroke:#5A478A,stroke-width:3px,color:#fff
    style WAI fill:#7B68EE,stroke:#4B3C8C,stroke-width:3px,color:#fff
```

---

## ğŸ”„ 2. ë°ì´í„° íë¦„ (ì „ì²´ ì‹œí€€ìŠ¤)

### 2.1 Waste Analysis ìš”ì²­ íë¦„

```mermaid
sequenceDiagram
    participant User as ì‚¬ìš©ì
    participant API as waste-api
    participant AuthDB as ecoeco_auth DB
    participant WasteDB as ecoeco_waste DB
    participant RMQ as RabbitMQ
    participant WS as Worker-Storage
    participant WAI as Worker-AI
    participant S3 as S3
    participant GPT5 as GPT-5 Vision
    participant GPT4 as GPT-4o mini
    participant WAL as ë¡œì»¬ WAL
    
    User->>API: ì´ë¯¸ì§€ ì—…ë¡œë“œ ìš”ì²­
    API->>AuthDB: ì¸ì¦ í™•ì¸
    AuthDB-->>API: ì¸ì¦ ì„±ê³µ
    API->>WasteDB: ë©”íƒ€ ì €ì¥
    API->>RMQ: Publish (user_input_queue)<br/>delivery_mode=2
    API-->>User: ì¦‰ì‹œ ì‘ë‹µ (task_id)
    
    Note over RMQ: Mnesia WALì—<br/>ë©”ì‹œì§€ ê¸°ë¡
    
    RMQ->>WS: Consume (image-uploader)
    WS->>WAL: INSERT task_wal<br/>status='pending'
    WS->>S3: ì´ë¯¸ì§€ ì—…ë¡œë“œ
    S3-->>WS: ì—…ë¡œë“œ ì™„ë£Œ
    WS->>WAL: UPDATE status='completed'
    WS->>RMQ: ACK + Publish<br/>(vision_analysis_queue)
    WS->>WasteDB: ë¹„ë™ê¸° ë™ê¸°í™”
    
    RMQ->>WAI: Consume (gpt5-analyzer)
    WAI->>WAL: INSERT task_wal
    WAI->>GPT5: GPT-5 Vision API í˜¸ì¶œ (30ì´ˆ)
    GPT5-->>WAI: ë¶„ì„ ê²°ê³¼
    WAI->>WAL: UPDATE + gpt_cache ì €ì¥
    WAI->>RMQ: ACK + Publish<br/>(rule_retrieval_queue)
    
    RMQ->>WS: Consume (rule-retriever)
    WS->>WS: JSON ê·œì¹™ ì¡°íšŒ (ë¡œì»¬)
    WS->>RMQ: ACK + Publish<br/>(response_generation_queue)
    
    RMQ->>WAI: Consume (response-generator)
    WAI->>WAL: INSERT task_wal
    WAI->>GPT4: GPT-4o mini API í˜¸ì¶œ (10ì´ˆ)
    GPT4-->>WAI: ìµœì¢… ì‘ë‹µ
    WAI->>WAL: UPDATE status='completed'
    WAI->>WasteDB: ìµœì¢… ê²°ê³¼ ì €ì¥
    WAI-->>User: ì‘ë‹µ ì „ì†¡
```

---

## ğŸš¨ 3. ì¥ì•  ì§€ì  ë¶„ì„ ë° ëŒ€ì‘

### 3.1 ì¥ì•  ì§€ì  ë§µ

```mermaid
graph TB
    subgraph L1["[L1] API Layer"]
        F1["F1: waste-api ë‹¤ìš´"]
        F2["F2: auth-api ë‹¤ìš´"]
        F3["F3: chat-llm-api ë‹¤ìš´"]
    end
    
    subgraph L2["[L2] Message Queue Layer"]
        F4["F4: RabbitMQ í´ëŸ¬ìŠ¤í„° ì¥ì• "]
        F5["F5: íŠ¹ì • í ë§‰í˜ (dead letter)"]
        F6["F6: ë©”ì‹œì§€ ì†ì‹¤ (non-persistent)"]
    end
    
    subgraph L3["[L3] Worker Layer"]
        F7["F7: Worker-Storage ë‹¤ìš´"]
        F8["F8: Worker-AI ë‹¤ìš´"]
        F9["F9: ë¡œì»¬ WAL íŒŒì¼ ì†ìƒ"]
        F10["F10: PostgreSQL ë™ê¸°í™” ì‹¤íŒ¨"]
    end
    
    subgraph L4["[L4] Database Layer"]
        F11["F11: ecoeco_waste DB ë‹¤ìš´"]
        F12["F12: ecoeco_auth DB ë‹¤ìš´"]
        F13["F13: DB ì»¤ë„¥ì…˜ í’€ ê³ ê°ˆ"]
        F14["F14: ë””ìŠ¤í¬ ìš©ëŸ‰ ë¶€ì¡±"]
    end
    
    subgraph L5["[L5] External Services"]
        F15["F15: GPT-5 Vision API ì¥ì• "]
        F16["F16: GPT-4o mini API ì¥ì• "]
        F17["F17: S3 ì¥ì• "]
    end
    
    style F1 fill:#FFE066,stroke:#F59F00,stroke-width:2px,color:#000
    style F2 fill:#FFE066,stroke:#F59F00,stroke-width:2px,color:#000
    style F3 fill:#FFE066,stroke:#F59F00,stroke-width:2px,color:#000
    style F4 fill:#F39C12,stroke:#C87F0A,stroke-width:3px,color:#000
    style F5 fill:#F39C12,stroke:#C87F0A,stroke-width:2px,color:#000
    style F6 fill:#F39C12,stroke:#C87F0A,stroke-width:2px,color:#000
    style F7 fill:#9370DB,stroke:#5A478A,stroke-width:3px,color:#fff
    style F8 fill:#7B68EE,stroke:#4B3C8C,stroke-width:3px,color:#fff
    style F9 fill:#E74C3C,stroke:#C0392B,stroke-width:3px,color:#fff
    style F10 fill:#E74C3C,stroke:#C0392B,stroke-width:2px,color:#fff
    style F11 fill:#3498DB,stroke:#2874A6,stroke-width:3px,color:#fff
    style F12 fill:#3498DB,stroke:#2874A6,stroke-width:3px,color:#fff
    style F13 fill:#3498DB,stroke:#2874A6,stroke-width:2px,color:#fff
    style F14 fill:#3498DB,stroke:#2874A6,stroke-width:2px,color:#fff
    style F15 fill:#FF6B6B,stroke:#C92A2A,stroke-width:3px,color:#fff
    style F16 fill:#FF6B6B,stroke:#C92A2A,stroke-width:3px,color:#fff
    style F17 fill:#51CF66,stroke:#2F9E44,stroke-width:2px,color:#fff
```

---

### 3.2 ì¥ì• ë³„ ì˜í–¥ ë²”ìœ„ ë° ë³µêµ¬ ì „ëµ

#### F1: waste-api ë‹¤ìš´ (ë„ë©”ì¸ë³„ ê²©ë¦¬ íš¨ê³¼ âœ…)

**ì˜í–¥ ë²”ìœ„**:
- âŒ íê¸°ë¬¼ ë¶„ì„ API ì¤‘ë‹¨
- âœ… auth-api, chat-llm-api, location-api ì •ìƒ ìš´ì˜ (ê²©ë¦¬ë¨!)

**ê°ì§€**:
```python
# Prometheus Alert
- alert: WasteAPIDown
  expr: up{job="waste-api"} == 0
  for: 1m
  annotations:
    summary: "waste-api ë‹¤ìš´"
```

**ë³µêµ¬ ì „ëµ**:
1. Kubernetes ReplicaSet ìë™ ì¬ì‹œì‘
2. ë‹¤ë¥¸ Podê°€ íŠ¸ë˜í”½ ì¸ìˆ˜
3. RabbitMQ íì— ìŒ“ì¸ ë©”ì‹œì§€ ë³´ì¡´ â†’ ë³µêµ¬ í›„ ì²˜ë¦¬

---

#### F4: RabbitMQ í´ëŸ¬ìŠ¤í„° ì¥ì•  (WAL íš¨ê³¼ âœ…)

**ì˜í–¥ ë²”ìœ„**:
- âŒ ìƒˆ ë©”ì‹œì§€ ë°œí–‰ ë¶ˆê°€
- âœ… Worker ë¡œì»¬ WALì— ë¯¸ì™„ë£Œ Task ë³´ì¡´
- âœ… ë³µêµ¬ í›„ ìë™ ì¬ì‹œì‘

**ê°ì§€**:
```python
- alert: RabbitMQDown
  expr: rabbitmq_up == 0
  for: 2m
  annotations:
    summary: "RabbitMQ í´ëŸ¬ìŠ¤í„° ë‹¤ìš´"
```

**ë³µêµ¬ ì „ëµ**:
```python
# Worker ì‹œì‘ ì‹œ WAL ë³µêµ¬
class WALRecovery:
    def recover_on_startup(self):
        # 1. RabbitMQ ì¬ì—°ê²° ëŒ€ê¸°
        while not rabbitmq_available():
            time.sleep(5)
        
        # 2. ë¡œì»¬ WALì—ì„œ ë¯¸ì™„ë£Œ Task ì¡°íšŒ
        pending = self.conn.execute("""
            SELECT task_id, task_name, payload
            FROM task_wal
            WHERE status IN ('pending', 'running')
            AND created_at > ?
        """, (time.time() - 3600,)).fetchall()  # 1ì‹œê°„ ì´ë‚´
        
        # 3. RabbitMQë¡œ ì¬ë°œí–‰
        for task_id, task_name, payload in pending:
            rabbitmq_publish(task_name, payload, task_id=task_id)
            
            # WALì— ì¬ë°œí–‰ í‘œì‹œ
            self.conn.execute("""
                UPDATE task_wal
                SET status = 'republished',
                    error = 'Recovered from RabbitMQ outage'
                WHERE task_id = ?
            """, (task_id,))
```

---

#### F7: Worker-Storage ë‹¤ìš´ (WAL ë³µêµ¬ âœ…)

**ì˜í–¥ ë²”ìœ„**:
- âŒ S3 ì—…ë¡œë“œ ì¤‘ë‹¨
- âœ… RabbitMQ íì— ë©”ì‹œì§€ ë³´ì¡´
- âœ… ë¡œì»¬ WALì— ì§„í–‰ ì¤‘ Task ë³´ì¡´

**ê°ì§€**:
```python
- alert: WorkerStorageDown
  expr: up{job="worker-storage"} == 0
  for: 2m
  annotations:
    summary: "Worker-Storage ë‹¤ìš´"
```

**ë³µêµ¬ ì „ëµ**:
```bash
# 1. Kubernetes Pod ì¬ì‹œì‘
kubectl rollout restart deployment/worker-storage

# 2. Worker ì‹œì‘ ì‹œ ìë™ ì‹¤í–‰
# workers/storage/celery_app.py
if __name__ == "__main__":
    # WAL ë³µêµ¬
    recovery = WALRecovery("/var/lib/ecoeco/task_queue.db")
    recovery.recover_on_startup()
    
    # Celery Worker ì‹œì‘
    app.worker_main()
```

**WAL ë³µêµ¬ ë¡œì§**:
```python
def recover_on_startup(self):
    # 1. WAL ì²´í¬í¬ì¸íŠ¸ (WAL â†’ DB ë™ê¸°í™”)
    self.conn.execute("PRAGMA wal_checkpoint(FULL)")
    
    # 2. ë¯¸ì™„ë£Œ Task ì¡°íšŒ
    pending = self.conn.execute("""
        SELECT task_id, task_name, payload, created_at
        FROM task_wal
        WHERE status IN ('pending', 'running')
    """).fetchall()
    
    for task_id, task_name, payload, created_at in pending:
        # íƒ€ì„ì•„ì›ƒ ì²´í¬ (1ì‹œê°„ ì´ˆê³¼ ì‹œ ì‹¤íŒ¨ ì²˜ë¦¬)
        if time.time() - created_at > 3600:
            self.conn.execute("""
                UPDATE task_wal
                SET status = 'timeout',
                    error = 'Task timeout during worker restart',
                    completed_at = ?
                WHERE task_id = ?
            """, (int(time.time()), task_id))
            logger.warning(f"Task {task_id} timed out")
        else:
            # RabbitMQë¡œ ì¬ë°œí–‰
            logger.info(f"Republishing task {task_id}")
            # ... (ì¬ë°œí–‰ ë¡œì§)
```

---

#### F11: ecoeco_waste DB ë‹¤ìš´ (ë„ë©”ì¸ë³„ ê²©ë¦¬ âœ…)

**ì˜í–¥ ë²”ìœ„**:
- âŒ íê¸°ë¬¼ ë¶„ì„ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨
- âœ… ecoeco_auth, ecoeco_chat DB ì •ìƒ (ê²©ë¦¬ë¨!)
- âœ… Worker WALì— ì„ì‹œ ì €ì¥

**ê°ì§€**:
```python
- alert: WasteDBDown
  expr: pg_up{database="ecoeco_waste"} == 0
  for: 1m
  annotations:
    summary: "ecoeco_waste DB ë‹¤ìš´"
```

**ë³µêµ¬ ì „ëµ**:
```python
# Workerì—ì„œ PostgreSQL ì—°ê²° ì‹¤íŒ¨ ì‹œ
@app.task(bind=True, max_retries=5)
def sync_to_postgres(self, task_id):
    try:
        # PostgreSQL ì €ì¥ ì‹œë„
        with postgres_session('ecoeco_waste') as db:
            task_data = get_from_wal(task_id)
            db.add(TaskLog(**task_data))
            db.commit()
    
    except OperationalError as e:
        # DB ì—°ê²° ì‹¤íŒ¨
        logger.error(f"PostgreSQL down: {e}")
        
        # WALì— ë™ê¸°í™” ì‹¤íŒ¨ í‘œì‹œ
        local_wal.conn.execute("""
            UPDATE task_wal
            SET sync_status = 'pending',
                sync_retry_count = sync_retry_count + 1,
                last_sync_attempt = ?
            WHERE task_id = ?
        """, (int(time.time()), task_id))
        
        # ì¬ì‹œë„ (Exponential Backoff)
        raise self.retry(exc=e, countdown=60 * (2 ** self.request.retries))
```

**ë°±ê·¸ë¼ìš´ë“œ ì¬ë™ê¸°í™”**:
```python
@app.task
def background_sync_wal_to_postgres():
    """ì£¼ê¸°ì ìœ¼ë¡œ WALì—ì„œ ë¯¸ë™ê¸°í™” Taskë¥¼ PostgreSQLì— ì €ì¥"""
    pending_syncs = local_wal.conn.execute("""
        SELECT task_id, task_name, payload, completed_at
        FROM task_wal
        WHERE status = 'completed'
        AND sync_status = 'pending'
        AND sync_retry_count < 10
        ORDER BY completed_at ASC
        LIMIT 100
    """).fetchall()
    
    for task_id, task_name, payload, completed_at in pending_syncs:
        sync_to_postgres.delay(task_id)

# Celery Beat ìŠ¤ì¼€ì¤„
app.conf.beat_schedule = {
    'background-sync': {
        'task': 'background_sync_wal_to_postgres',
        'schedule': 300.0,  # 5ë¶„ë§ˆë‹¤
    },
}
```

---

#### F15: GPT-5 Vision API ì¥ì•  (ì™¸ë¶€ ì„œë¹„ìŠ¤)

**ì˜í–¥ ë²”ìœ„**:
- âŒ ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ë‹¨
- âœ… ë‹¤ë¥¸ ë„ë©”ì¸ ì •ìƒ ìš´ì˜
- âœ… WALì— ì¬ì‹œë„ í ë³´ì¡´

**ê°ì§€**:
```python
- alert: GPT5APIDown
  expr: rate(gpt5_api_errors_total[5m]) > 0.5
  for: 5m
  annotations:
    summary: "GPT-5 Vision API ì¥ì• ìœ¨ ë†’ìŒ"
```

**ë³µêµ¬ ì „ëµ**:
```python
# Worker-AIì—ì„œ GPT-5 í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
@app.task(bind=True, max_retries=10)
def gpt5_analysis_task(self, image_path):
    try:
        # GPT-5 API í˜¸ì¶œ
        result = call_gpt5_vision_api(image_path)
        
        # WAL ìºì‹œì— ì €ì¥
        local_wal.conn.execute("""
            INSERT INTO gpt_cache (image_path, response, model, created_at)
            VALUES (?, ?, 'gpt-5', ?)
        """, (image_path, json.dumps(result), int(time.time())))
        
        return result
    
    except GPT5APIError as e:
        logger.error(f"GPT-5 API failed: {e}")
        
        # WAL ì¬ì‹œë„ íì— ì €ì¥
        local_wal.conn.execute("""
            INSERT INTO retry_queue (task_id, retry_count, error, next_retry_at)
            VALUES (?, ?, ?, ?)
        """, (
            self.request.id,
            self.request.retries,
            str(e),
            int(time.time()) + 60 * (2 ** self.request.retries)
        ))
        
        # Exponential Backoff ì¬ì‹œë„
        raise self.retry(
            exc=e,
            countdown=60 * (2 ** self.request.retries),  # 1ë¶„, 2ë¶„, 4ë¶„, 8ë¶„, ...
            max_retries=10
        )
```

---

## ğŸ” 4. ì¥ì•  ê°ì§€ ì‹œìŠ¤í…œ (í†µí•© ëª¨ë‹ˆí„°ë§)

### 4.1 Prometheus ë©”íŠ¸ë¦­

```yaml
# prometheus.yml
scrape_configs:
  # API Layer
  - job_name: 'api-services'
    kubernetes_sd_configs:
      - role: pod
        namespaces:
          names: ['api']
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_label_app]
        regex: '(waste|auth|chat)-api'
        action: keep
    metrics_path: /metrics
  
  # Worker Layer
  - job_name: 'celery-workers'
    static_configs:
      - targets:
        - 'worker-storage:9090'
        - 'worker-ai:9090'
  
  # PostgreSQL
  - job_name: 'postgresql'
    static_configs:
      - targets:
        - 'postgresql-exporter:9187'
    relabel_configs:
      - source_labels: [database]
        target_label: domain
  
  # RabbitMQ
  - job_name: 'rabbitmq'
    static_configs:
      - targets: ['rabbitmq:15692']
```

### 4.2 ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ (Worker WAL ìƒíƒœ)

```python
# workers/storage/metrics.py
from prometheus_client import Counter, Gauge, Histogram

# WAL ë©”íŠ¸ë¦­
wal_tasks_total = Counter(
    'wal_tasks_total',
    'Total tasks recorded in WAL',
    ['status', 'task_name']
)

wal_pending_tasks = Gauge(
    'wal_pending_tasks',
    'Current number of pending tasks in WAL'
)

wal_sync_delay = Histogram(
    'wal_sync_delay_seconds',
    'Time delay between task completion and PostgreSQL sync'
)

wal_file_size = Gauge(
    'wal_file_size_bytes',
    'Current size of WAL file'
)

# Task Hookì—ì„œ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
@task_prerun.connect
def update_wal_metrics_prerun(task_id, task_name, **kwargs):
    wal_tasks_total.labels(status='started', task_name=task_name).inc()
    
    # í˜„ì¬ pending ìˆ˜ ì—…ë°ì´íŠ¸
    pending_count = local_wal.conn.execute(
        "SELECT COUNT(*) FROM task_wal WHERE status IN ('pending', 'running')"
    ).fetchone()[0]
    wal_pending_tasks.set(pending_count)

@task_postrun.connect
def update_wal_metrics_postrun(task_id, task_name, **kwargs):
    wal_tasks_total.labels(status='completed', task_name=task_name).inc()
    
    # ë™ê¸°í™” ì§€ì—° ì¸¡ì •
    completed_at = local_wal.conn.execute(
        "SELECT completed_at FROM task_wal WHERE task_id = ?",
        (task_id,)
    ).fetchone()[0]
    
    sync_delay = time.time() - completed_at
    wal_sync_delay.observe(sync_delay)
    
    # WAL íŒŒì¼ í¬ê¸°
    wal_size = os.path.getsize("/var/lib/ecoeco/task_queue.db-wal")
    wal_file_size.set(wal_size)
```

### 4.3 Grafana ëŒ€ì‹œë³´ë“œ

```json
{
  "dashboard": {
    "title": "Ecoeco WAL + Domain Architecture",
    "panels": [
      {
        "title": "ë„ë©”ì¸ë³„ DB ìƒíƒœ",
        "targets": [{
          "expr": "pg_up{database=~\"ecoeco_(auth|waste|chat|location|analytics)\"}"
        }]
      },
      {
        "title": "Worker WAL ìƒíƒœ",
        "targets": [
          {
            "expr": "wal_pending_tasks",
            "legendFormat": "Pending Tasks"
          },
          {
            "expr": "rate(wal_tasks_total[5m])",
            "legendFormat": "Tasks/sec - {{status}}"
          }
        ]
      },
      {
        "title": "WAL ë™ê¸°í™” ì§€ì—°",
        "targets": [{
          "expr": "histogram_quantile(0.95, wal_sync_delay_seconds_bucket)",
          "legendFormat": "P95 Sync Delay"
        }]
      },
      {
        "title": "RabbitMQ í ê¹Šì´ (ë„ë©”ì¸ë³„)",
        "targets": [{
          "expr": "rabbitmq_queue_messages{queue=~\".*_queue\"}"
        }]
      },
      {
        "title": "ì¥ì•  ì˜í–¥ ë²”ìœ„",
        "targets": [
          {
            "expr": "up{job=\"api-services\"} == 0",
            "legendFormat": "API Down: {{instance}}"
          },
          {
            "expr": "up{job=\"celery-workers\"} == 0",
            "legendFormat": "Worker Down: {{instance}}"
          }
        ]
      }
    ]
  }
}
```

---

## ğŸ¯ 5. ì¥ì•  ì‹œë‚˜ë¦¬ì˜¤ë³„ ë³µêµ¬ ì‹œê°„ (RTO/RPO)

| ì¥ì•  ìœ í˜• | ì˜í–¥ ë²”ìœ„ | RTO (ë³µêµ¬ ì‹œê°„) | RPO (ë°ì´í„° ì†ì‹¤) | ë³µêµ¬ ì „ëµ |
|-----------|-----------|-----------------|-------------------|-----------|
| **F1: waste-api ë‹¤ìš´** | íê¸°ë¬¼ ë¶„ì„ë§Œ | 30ì´ˆ | 0 (WAL ë³´ì¡´) | K8s ìë™ ì¬ì‹œì‘ |
| **F2: auth-api ë‹¤ìš´** | ì¸ì¦ë§Œ | 30ì´ˆ | 0 (WAL ë³´ì¡´) | K8s ìë™ ì¬ì‹œì‘ |
| **F4: RabbitMQ ë‹¤ìš´** | ìƒˆ ë©”ì‹œì§€ ë°œí–‰ ë¶ˆê°€ | 2ë¶„ | 0 (Durable Queue) | í´ëŸ¬ìŠ¤í„° ì¬ì‹œì‘ |
| **F7: Worker-Storage ë‹¤ìš´** | S3 ì—…ë¡œë“œ ì¤‘ë‹¨ | 1ë¶„ | 0 (ë¡œì»¬ WAL) | WAL ë³µêµ¬ â†’ ì¬ë°œí–‰ |
| **F8: Worker-AI ë‹¤ìš´** | AI ë¶„ì„ ì¤‘ë‹¨ | 1ë¶„ | 0 (ë¡œì»¬ WAL + ìºì‹œ) | WAL ë³µêµ¬ â†’ ì¬ë°œí–‰ |
| **F11: ecoeco_waste DB ë‹¤ìš´** | ë¶„ì„ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨ | 5ë¶„ | 0 (Worker WAL) | DB ë³µêµ¬ â†’ WAL ì¬ë™ê¸°í™” |
| **F12: ecoeco_auth DB ë‹¤ìš´** | ì¸ì¦ ì‹¤íŒ¨ | 5ë¶„ | 0 | DB ë³µêµ¬ |
| **F15: GPT-5 API ì¥ì• ** | ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ë‹¨ | API ë³µêµ¬ê¹Œì§€ | 0 (ì¬ì‹œë„ í) | Exponential Backoff ì¬ì‹œë„ |

**í•µì‹¬ í¬ì¸íŠ¸**:
- âœ… **RTO < 5ë¶„**: ëª¨ë“  ì¥ì•  ìœ í˜•
- âœ… **RPO = 0**: WAL ë•ë¶„ì— ë°ì´í„° ì†ì‹¤ ì—†ìŒ
- âœ… **ë„ë©”ì¸ ê²©ë¦¬**: í•œ ë„ë©”ì¸ ì¥ì•  â†’ ë‹¤ë¥¸ ë„ë©”ì¸ ì •ìƒ

---

## ğŸ› ï¸ 6. ì¥ì•  ë³µêµ¬ ìë™í™” ìŠ¤í¬ë¦½íŠ¸

### 6.1 ì „ì²´ ì‹œìŠ¤í…œ í—¬ìŠ¤ì²´í¬

```bash
#!/bin/bash
# scripts/monitoring/health-check.sh

echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "ğŸ” Ecoeco ì‹œìŠ¤í…œ í—¬ìŠ¤ì²´í¬ (WAL + ë„ë©”ì¸ ë¶„ë¦¬)"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

# 1. PostgreSQL ë„ë©”ì¸ë³„ DB ì²´í¬
echo ""
echo "1ï¸âƒ£  PostgreSQL ë„ë©”ì¸ë³„ DB ìƒíƒœ"
for db in auth waste chat location analytics; do
    if psql -h postgresql -U postgres -d "ecoeco_${db}" -c "SELECT 1" >/dev/null 2>&1; then
        echo "  âœ… ecoeco_${db}: OK"
    else
        echo "  âŒ ecoeco_${db}: DOWN"
    fi
done

# 2. RabbitMQ í ì²´í¬
echo ""
echo "2ï¸âƒ£  RabbitMQ í ìƒíƒœ"
rabbitmqctl list_queues name messages consumers | while read queue msgs consumers; do
    if [ "$msgs" -gt 1000 ]; then
        echo "  âš ï¸  ${queue}: ${msgs} messages (í ë§‰í˜ ì˜ì‹¬)"
    else
        echo "  âœ… ${queue}: ${msgs} messages"
    fi
done

# 3. Worker WAL ìƒíƒœ ì²´í¬
echo ""
echo "3ï¸âƒ£  Worker WAL ìƒíƒœ"
for worker in storage ai; do
    wal_db="/var/lib/ecoeco/worker-${worker}/task_queue.db"
    if [ -f "$wal_db" ]; then
        pending=$(sqlite3 "$wal_db" "SELECT COUNT(*) FROM task_wal WHERE status IN ('pending', 'running')")
        echo "  âœ… Worker-${worker}: ${pending} pending tasks"
        
        if [ "$pending" -gt 100 ]; then
            echo "     âš ï¸  ê²½ê³ : pending tasks ê³¼ë‹¤"
        fi
    else
        echo "  âŒ Worker-${worker}: WAL DB ì—†ìŒ"
    fi
done

# 4. API ì—”ë“œí¬ì¸íŠ¸ ì²´í¬
echo ""
echo "4ï¸âƒ£  API ì„œë¹„ìŠ¤ ìƒíƒœ"
for api in waste auth userinfo location recycle-info chat-llm; do
    if curl -sf "http://${api}-api:8000/health" >/dev/null; then
        echo "  âœ… ${api}-api: OK"
    else
        echo "  âŒ ${api}-api: DOWN"
    fi
done

echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
```

### 6.2 WAL ìë™ ë³µêµ¬ ìŠ¤í¬ë¦½íŠ¸

```bash
#!/bin/bash
# scripts/maintenance/wal-recovery.sh

WORKER_TYPE=$1  # storage or ai
WAL_DB="/var/lib/ecoeco/worker-${WORKER_TYPE}/task_queue.db"

echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "ğŸ”„ Worker-${WORKER_TYPE} WAL ë³µêµ¬ ì‹œì‘"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"

# 1. WAL ì²´í¬í¬ì¸íŠ¸ (WAL â†’ DB ë™ê¸°í™”)
echo ""
echo "1ï¸âƒ£  WAL ì²´í¬í¬ì¸íŠ¸ ì‹¤í–‰..."
sqlite3 "$WAL_DB" "PRAGMA wal_checkpoint(FULL);"
echo "  âœ… ì²´í¬í¬ì¸íŠ¸ ì™„ë£Œ"

# 2. ë¯¸ì™„ë£Œ Task ì¡°íšŒ
echo ""
echo "2ï¸âƒ£  ë¯¸ì™„ë£Œ Task ì¡°íšŒ..."
pending_count=$(sqlite3 "$WAL_DB" "SELECT COUNT(*) FROM task_wal WHERE status IN ('pending', 'running')")
echo "  ğŸ“‹ ë¯¸ì™„ë£Œ Task: ${pending_count}ê°œ"

if [ "$pending_count" -gt 0 ]; then
    # 3. Task íƒ€ì„ì•„ì›ƒ ì²´í¬ (1ì‹œê°„ ì´ˆê³¼)
    echo ""
    echo "3ï¸âƒ£  íƒ€ì„ì•„ì›ƒ Task ì²˜ë¦¬..."
    timeout_count=$(sqlite3 "$WAL_DB" "
        UPDATE task_wal
        SET status = 'timeout',
            error = 'Task timeout during recovery',
            completed_at = strftime('%s', 'now')
        WHERE status IN ('pending', 'running')
        AND created_at < strftime('%s', 'now') - 3600;
        
        SELECT changes();
    ")
    echo "  â° íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬: ${timeout_count}ê°œ"
    
    # 4. ìœ íš¨í•œ Task RabbitMQ ì¬ë°œí–‰
    echo ""
    echo "4ï¸âƒ£  ìœ íš¨í•œ Task ì¬ë°œí–‰..."
    sqlite3 "$WAL_DB" "
        SELECT task_id, task_name, payload
        FROM task_wal
        WHERE status IN ('pending', 'running')
        AND created_at >= strftime('%s', 'now') - 3600
    " | while IFS='|' read task_id task_name payload; do
        echo "  ğŸ“¤ ì¬ë°œí–‰: ${task_name} (${task_id})"
        # Python ìŠ¤í¬ë¦½íŠ¸ë¡œ RabbitMQ ì¬ë°œí–‰
        python3 /app/scripts/republish_task.py "$task_id" "$task_name" "$payload"
    done
fi

echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "âœ… WAL ë³µêµ¬ ì™„ë£Œ!"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
```

---

## ğŸ“Š 7. ìµœì¢… ì•„í‚¤í…ì²˜ ìš”ì•½

### í•µì‹¬ ì„¤ê³„ ì›ì¹™

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. ë„ë©”ì¸ë³„ DB ë¶„ë¦¬ (OStore êµí›ˆ)                               â”‚
â”‚    â†’ ì¥ì•  ê²©ë¦¬: waste DB ë‹¤ìš´ â†’ auth/chat ì •ìƒ                 â”‚
â”‚    â†’ ìŠ¤ì¼€ì¼ ë…ë¦½: íŠ¸ë˜í”½ ë§ì€ ë„ë©”ì¸ë§Œ ì¦ì„¤                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2. RabbitMQ Durable Queue (Mnesia WAL)                          â”‚
â”‚    â†’ ë©”ì‹œì§€ ì˜ì†í™”: ì¬ì‹œì‘ í›„ ë³µêµ¬                              â”‚
â”‚    â†’ ì´ì¤‘ ë³´ì¥: RabbitMQ + Worker WAL                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 3. Worker ë¡œì»¬ SQLite WAL (Robin ë°©ì‹)                          â”‚
â”‚    â†’ ë¹ ë¥¸ ê¸°ë¡: ìˆœì°¨ ì“°ê¸° (8ë°° ë¹ ë¦„)                            â”‚
â”‚    â†’ ì¥ì•  ë³µêµ¬: Worker ì¬ì‹œì‘ ì‹œ WALì—ì„œ ìë™ ë³µêµ¬              â”‚
â”‚    â†’ PostgreSQL ë…ë¦½: DB ì¥ì•  ì‹œì—ë„ Worker ì‘ë™                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 4. ë¹„ë™ê¸° PostgreSQL ë™ê¸°í™”                                     â”‚
â”‚    â†’ ë°±ê·¸ë¼ìš´ë“œ ë™ê¸°í™”: Worker â†’ PostgreSQL                     â”‚
â”‚    â†’ ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜: Exponential Backoff                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ì¥ì•  ê²©ë¦¬ íš¨ê³¼

```
ë‹¨ì¼ DB êµ¬ì¡° (ê¸°ì¡´):
  DB ë‹¤ìš´ â†’ ì „ì²´ ì„œë¹„ìŠ¤ ë‹¤ìš´ âŒ

ë„ë©”ì¸ë³„ DB + WAL êµ¬ì¡° (ê°œì„ ):
  ecoeco_waste DB ë‹¤ìš´
    â†’ waste API ì“°ê¸° ì‹¤íŒ¨
    â†’ Worker WALì— ì„ì‹œ ì €ì¥ âœ…
    â†’ auth/chat/location API ì •ìƒ ìš´ì˜ âœ…
    â†’ DB ë³µêµ¬ í›„ WAL ìë™ ì¬ë™ê¸°í™” âœ…
```

### RTO/RPO ë³´ì¥

```
RTO (Recovery Time Objective)
  - API ì¥ì• : 30ì´ˆ (K8s ìë™ ì¬ì‹œì‘)
  - Worker ì¥ì• : 1ë¶„ (WAL ë³µêµ¬)
  - DB ì¥ì• : 5ë¶„ (DB ë³µêµ¬ + WAL ì¬ë™ê¸°í™”)

RPO (Recovery Point Objective)
  - ëª¨ë“  ì¥ì•  ìœ í˜•: 0 (ë°ì´í„° ì†ì‹¤ ì—†ìŒ)
  - WAL ë•ë¶„ì— ì™„ë²½í•œ ë°ì´í„° ë³´ì¡´
```

---

**ê²°ë¡ **: WALê³¼ ë„ë©”ì¸ ë¶„ë¦¬ë¥¼ ê²°í•©í•˜ë©´ **ì¥ì•  ê²©ë¦¬ + ë°ì´í„° ë³´ì¡´ + ë¹ ë¥¸ ë³µêµ¬**ë¥¼ ëª¨ë‘ ë‹¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! ğŸ¯


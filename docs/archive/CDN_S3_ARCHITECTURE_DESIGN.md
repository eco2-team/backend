# ğŸ—ï¸ CDN + S3 ê¸°ë°˜ ì´ë¯¸ì§€ ì²˜ë¦¬ ì•„í‚¤í…ì²˜

> **ì°¸ê³ **: [ìš°ì•„í•œí˜•ì œë“¤ - Spring Bootì—ì„œ S3ì— íŒŒì¼ì„ ì—…ë¡œë“œí•˜ëŠ” ì„¸ ê°€ì§€ ë°©ë²•](https://techblog.woowahan.com/11392/)  
> **ì ìš© ë°©ì‹**: Presigned URL (í”„ë¡ íŠ¸ì—”ë“œ ì§ì ‘ ì—…ë¡œë“œ)  
> **ë¸Œëœì¹˜**: feature/cdn-image-caching  
> **ë‚ ì§œ**: 2025-11-06

---

## ğŸ“‹ ëª©ì°¨

1. [ì„¸ ê°€ì§€ ì—…ë¡œë“œ ë°©ì‹ ë¹„êµ](#ì„¸-ê°€ì§€-ì—…ë¡œë“œ-ë°©ì‹-ë¹„êµ)
2. [ì„ íƒí•œ ë°©ì‹: Presigned URL](#ì„ íƒí•œ-ë°©ì‹-presigned-url)
3. [ìƒˆë¡œìš´ ì•„í‚¤í…ì²˜](#ìƒˆë¡œìš´-ì•„í‚¤í…ì²˜)
4. [êµ¬í˜„ ìƒì„¸](#êµ¬í˜„-ìƒì„¸)
5. [Redis ìºì‹± ì œê±°](#redis-ìºì‹±-ì œê±°)

---

## ğŸ” ì„¸ ê°€ì§€ ì—…ë¡œë“œ ë°©ì‹ ë¹„êµ

### 1ï¸âƒ£ Stream ì—…ë¡œë“œ

**ë°©ì‹**: Backendê°€ MultipartFileì„ InputStreamìœ¼ë¡œ ë°›ì•„ S3ì— ì§ì ‘ ì—…ë¡œë“œ

```kotlin
@PostMapping("/upload/stream")
fun streamUpload(file: MultipartFile) {
    val metadata = ObjectMetadata()
    metadata.contentType = file.contentType
    metadata.contentLength = file.size
    
    amazonS3.putObject("bucket", "key", file.inputStream, metadata)
}
```

**ì¥ì **:
- âœ… ë©”ëª¨ë¦¬ íš¨ìœ¨ì  (ë””ìŠ¤í¬ ì €ì¥ ì—†ìŒ)
- âœ… ê°„ë‹¨í•œ êµ¬í˜„
- âœ… ë‹¨ì¼ íŒŒì¼ ì—…ë¡œë“œì— ì í•©

**ë‹¨ì **:
- âŒ Backend ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­í­ ì†Œëª¨
- âŒ Backend ë¶€í•˜ ì¦ê°€
- âŒ ì—…ë¡œë“œ ì‹¤íŒ¨ ì‹œ ì „ì²´ ì¬ì—…ë¡œë“œ
- âŒ í™•ì¥ì„± ì œí•œ (Backend ë³‘ëª©)

**ì í•©í•œ ê²½ìš°**:
- ì†Œê·œëª¨ ì„œë¹„ìŠ¤
- Backendê°€ íŒŒì¼ ê²€ì¦/ì „ì²˜ë¦¬ í•„ìš”
- ì‚¬ìš©ìê°€ ì§ì ‘ S3 ì ‘ê·¼ ë¶ˆê°€ëŠ¥í•œ ê²½ìš°

---

### 2ï¸âƒ£ Presigned URL

**ë°©ì‹**: Backendê°€ ì„ì‹œ ì—…ë¡œë“œ URL ë°œê¸‰ â†’ Frontendê°€ S3ì— ì§ì ‘ ì—…ë¡œë“œ

```kotlin
@GetMapping("/upload/presigned-url")
fun getPresignedUrl(@RequestParam filename: String): String {
    val putObjectRequest = PutObjectRequest("bucket", filename, file)
    
    return amazonS3.generatePresignedUrl(
        "bucket",
        filename,
        Date(System.currentTimeMillis() + 5 * 60 * 1000), // 5ë¶„ ìœ íš¨
        HttpMethod.PUT
    ).toString()
}
```

**ì¥ì **:
- âœ… **Backend ë¶€í•˜ ì œë¡œ** (ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­í­ ì ˆì•½)
- âœ… **í™•ì¥ì„± ìš°ìˆ˜** (S3ê°€ íŠ¸ë˜í”½ ì²˜ë¦¬)
- âœ… **ë¹ ë¥¸ ì—…ë¡œë“œ** (Frontend â†’ S3 ì§ì ‘)
- âœ… ë³´ì•ˆ (ì‹œê°„ ì œí•œ URL)

**ë‹¨ì **:
- âŒ Backendì—ì„œ íŒŒì¼ ê²€ì¦ ì–´ë ¤ì›€ (ì—…ë¡œë“œ í›„ ê²€ì¦)
- âŒ ì¶”ê°€ API í˜¸ì¶œ í•„ìš” (URL ë°œê¸‰)

**ì í•©í•œ ê²½ìš°**:
- ëŒ€ê·œëª¨ ì„œë¹„ìŠ¤ â­
- Backend ë¶€í•˜ ìµœì†Œí™” í•„ìš”
- Frontendê°€ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê²½ìš°
- **ìš°ë¦¬ ì‹œìŠ¤í…œ (ëª¨ë°”ì¼ ì•± â†’ S3)** â­â­â­

---

### 3ï¸âƒ£ Multipart Upload

**ë°©ì‹**: ëŒ€ìš©ëŸ‰ íŒŒì¼ì„ ì—¬ëŸ¬ Partë¡œ ë‚˜ëˆ„ì–´ ë³‘ë ¬ ì—…ë¡œë“œ

```kotlin
fun multipartUpload(file: MultipartFile) {
    // 1. Multipart Upload ì´ˆê¸°í™”
    val initRequest = InitiateMultipartUploadRequest("bucket", "key")
    val uploadId = amazonS3.initiateMultipartUpload(initRequest).uploadId
    
    // 2. Part ì—…ë¡œë“œ (ë³‘ë ¬)
    val partETags = mutableListOf<PartETag>()
    val partSize = 5 * 1024 * 1024 // 5MB
    
    file.inputStream.use { input ->
        var partNumber = 1
        var buffer = ByteArray(partSize)
        
        while (input.read(buffer) > 0) {
            val uploadRequest = UploadPartRequest()
                .withBucketName("bucket")
                .withKey("key")
                .withUploadId(uploadId)
                .withPartNumber(partNumber++)
                .withInputStream(ByteArrayInputStream(buffer))
                .withPartSize(buffer.size.toLong())
            
            val result = amazonS3.uploadPart(uploadRequest)
            partETags.add(result.partETag)
        }
    }
    
    // 3. ì™„ë£Œ
    val completeRequest = CompleteMultipartUploadRequest(
        "bucket", "key", uploadId, partETags
    )
    amazonS3.completeMultipartUpload(completeRequest)
}
```

**ì¥ì **:
- âœ… ëŒ€ìš©ëŸ‰ íŒŒì¼ ì—…ë¡œë“œ (100MB+)
- âœ… ë³‘ë ¬ ì—…ë¡œë“œ (ì†ë„ í–¥ìƒ)
- âœ… ì—…ë¡œë“œ ì¬ê°œ ê°€ëŠ¥ (ì‹¤íŒ¨í•œ Partë§Œ ì¬ì—…ë¡œë“œ)

**ë‹¨ì **:
- âŒ ë³µì¡í•œ êµ¬í˜„
- âŒ ì‘ì€ íŒŒì¼ì—ëŠ” ì˜¤ë²„í—¤ë“œ
- âŒ Backend ë¡œì§ ë³µì¡

**ì í•©í•œ ê²½ìš°**:
- ëŒ€ìš©ëŸ‰ íŒŒì¼ (ë™ì˜ìƒ, ê³ í•´ìƒë„ ì´ë¯¸ì§€)
- ë„¤íŠ¸ì›Œí¬ ë¶ˆì•ˆì •í•œ í™˜ê²½
- **ìš°ë¦¬ ì‹œìŠ¤í…œì—ëŠ” ê³¼ë„í•¨** (ì´ë¯¸ì§€ 2-5MB)

---

## âœ… ì„ íƒí•œ ë°©ì‹: Presigned URL

### ì„ íƒ ì´ìœ 

| ìš”êµ¬ì‚¬í•­ | Presigned URL | í‰ê°€ |
|---------|---------------|------|
| ëª¨ë°”ì¼ ì•±ì—ì„œ ì´¬ì˜í•œ ì´ë¯¸ì§€ | âœ… Frontend â†’ S3 ì§ì ‘ | ìµœì  |
| ë‹¨ì¼ ì´ë¯¸ì§€ (2-5MB) | âœ… ë‹¨ì¼ ì—…ë¡œë“œ ì í•© | ìµœì  |
| Backend ë¶€í•˜ ìµœì†Œí™” | âœ… ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­í­ ì œë¡œ | ìµœì  |
| í™•ì¥ì„± (ë™ì‹œ ì‚¬ìš©ì 100-500ëª…) | âœ… S3ê°€ íŠ¸ë˜í”½ ì²˜ë¦¬ | ìµœì  |
| ë¹ ë¥¸ ì—…ë¡œë“œ | âœ… ì§ì ‘ ì—°ê²° | ìµœì  |
| AI ë¶„ì„ ëŒ€ê¸° ì‹œê°„ ìµœì†Œí™” | âœ… Workerê°€ CDNì—ì„œ ë¡œë“œ | ìµœì  |

### í˜„ì¬ ì‹œìŠ¤í…œê³¼ì˜ í˜¸í™˜ì„±

**í˜„ì¬ ì´ë¯¸ Presigned URL ì‚¬ìš© ì¤‘!** (í™•ì¸ í•„ìš”)

```python
# í˜„ì¬ êµ¬ì¡° (docs/architecture/image-processing-architecture.md:488-506)
@app.post("/api/v1/waste/analyze")
async def create_analysis():
    job_id = str(uuid.uuid4())
    
    # S3 Pre-signed URL (ì´ë¯¸ ì‚¬ìš© ì¤‘!)
    upload_url = s3.generate_presigned_url(
        'put_object',
        Params={'Bucket': 'images', 'Key': f'{job_id}.jpg'},
        ExpiresIn=300
    )
    
    return {
        "job_id": job_id,
        "upload_url": upload_url
    }
```

**ë³€ê²½ì‚¬í•­**:
- âœ… Presigned URL ë°©ì‹ì€ ê·¸ëŒ€ë¡œ ìœ ì§€
- âœ… CloudFront CDN ì¶”ê°€ (Worker ì´ë¯¸ì§€ ë¡œë“œ ìµœì í™”)
- âŒ Redis ì´ë¯¸ì§€ í•´ì‹œ ìºì‹± ì œê±° (CDNìœ¼ë¡œ ëŒ€ì²´)

---

## ğŸ—ï¸ ìƒˆë¡œìš´ ì•„í‚¤í…ì²˜

### ë³€ê²½ ì „ (Redis ìºì‹±)

```mermaid
sequenceDiagram
    participant App as Mobile App
    participant API as Backend API
    participant Worker as AI Worker
    participant S3 as AWS S3
    participant Redis as Redis DB 1
    participant AI as GPT-4o Vision

    App->>API: 1. POST /analyze
    API->>App: 2. Presigned URL
    App->>S3: 3. ì´ë¯¸ì§€ ì—…ë¡œë“œ
    
    App->>API: 4. POST /upload-complete
    API->>Worker: 5. Task ë°œí–‰
    
    Worker->>S3: 6. ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (ë§¤ë²ˆ!)
    Worker->>Worker: 7. pHash ê³„ì‚°
    Worker->>Redis: 8. ìºì‹œ í™•ì¸
    
    alt Cache Hit (70%)
        Redis-->>Worker: AI ê²°ê³¼ ë°˜í™˜
        Worker-->>App: ì¦‰ì‹œ ì‘ë‹µ (1ì´ˆ)
    else Cache Miss (30%)
        Worker->>AI: GPT-4o Vision API
        AI-->>Worker: ë¶„ë¥˜ ê²°ê³¼
        Worker->>Redis: ìºì‹± (7ì¼)
        Worker-->>App: ë¶„ì„ ê²°ê³¼ (3-5ì´ˆ)
    end
```

**ë¬¸ì œì **:
- âŒ Workerê°€ ë§¤ë²ˆ S3ì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
- âŒ pHash ê³„ì‚°ì„ ìœ„í•´ ì „ì²´ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ í•„ìš”
- âŒ Redisì— AI ê²°ê³¼ë§Œ ìºì‹± (ì´ë¯¸ì§€ ìì²´ëŠ” ìºì‹± ì•ˆ ë¨)
- âŒ 70% ìºì‹œ íˆíŠ¸ìœ¨ë„ 30%ëŠ” ì—¬ì „íˆ ë‹¤ìš´ë¡œë“œ

---

### ë³€ê²½ í›„ (CDN ìºì‹±)

```mermaid
sequenceDiagram
    participant App as Mobile App
    participant API as Backend API
    participant Worker as AI Worker
    participant CDN as CloudFront CDN
    participant S3 as AWS S3
    participant AI as GPT-4o Vision

    App->>API: 1. POST /analyze
    API->>App: 2. Presigned URL + CDN URL
    App->>S3: 3. ì´ë¯¸ì§€ ì§ì ‘ ì—…ë¡œë“œ
    
    Note over S3,CDN: S3 = Origin<br/>CDN = Edge Cache
    
    App->>API: 4. POST /upload-complete
    API->>Worker: 5. Task ë°œí–‰
    
    Worker->>CDN: 6. ì´ë¯¸ì§€ ìš”ì²­ (CDN URL)
    
    alt CDN Cache Hit (50-70%)
        CDN-->>Worker: Edgeì—ì„œ ì¦‰ì‹œ ë°˜í™˜
        Note over CDN: ì²« ìš”ì²­ í›„<br/>24ì‹œê°„ ìºì‹±
    else CDN Cache Miss
        CDN->>S3: Originì—ì„œ ê°€ì ¸ì˜¤ê¸°
        S3-->>CDN: ì´ë¯¸ì§€ ë°˜í™˜
        CDN-->>Worker: ì´ë¯¸ì§€ ì „ë‹¬ + ìºì‹±
    end
    
    Worker->>Worker: 7. ì´ë¯¸ì§€ ë¶„ì„ ì¤€ë¹„
    Worker->>AI: 8. GPT-4o Vision API
    AI-->>Worker: ë¶„ë¥˜ ê²°ê³¼
    Worker-->>App: 9. ë¶„ì„ ê²°ê³¼ (2-4ì´ˆ)
    
    Note over App,CDN: í”„ë¡ íŠ¸ì—”ë“œ ì´ë¯¸ì§€ í‘œì‹œ
    App->>CDN: 10. ì´ë¯¸ì§€ ë¡œë“œ (ë¹ ë¦„!)
    CDN-->>App: ìºì‹±ëœ ì´ë¯¸ì§€ ë°˜í™˜
```

**ê°œì„ ì‚¬í•­**:
- âœ… Workerê°€ CDNì—ì„œ ì´ë¯¸ì§€ ë¡œë“œ (50-70% Edge Hit)
- âœ… í”„ë¡ íŠ¸ì—”ë“œë„ CDNì—ì„œ ë¹ ë¥¸ ì´ë¯¸ì§€ ë¡œë“œ
- âœ… Redis ìºì‹± ì œê±° (ë‹¨ìˆœí™”)
- âœ… pHash ê³„ì‚° ì œê±° (ë¶ˆí•„ìš”)
- âœ… ê¸€ë¡œë²Œ í™•ì¥ì„± (Edge Location)

---

## ğŸ”§ êµ¬í˜„ ìƒì„¸

### Phase 1: CloudFront ì¸í”„ë¼

**íŒŒì¼**: `terraform/cloudfront.tf` (ì‹ ê·œ)

```hcl
# CloudFront Distribution
resource "aws_cloudfront_distribution" "images" {
  enabled             = true
  is_ipv6_enabled     = true
  comment             = "CDN for waste analysis images"
  price_class         = "PriceClass_200"  # ì•„ì‹œì•„ + ë¶ë¯¸ + ìœ ëŸ½
  
  # Origin: S3 Bucket
  origin {
    domain_name = aws_s3_bucket.images.bucket_regional_domain_name
    origin_id   = "S3-${aws_s3_bucket.images.id}"
    
    # OAI (Origin Access Identity) - S3 ë³´ì•ˆ ì—°ê²°
    s3_origin_config {
      origin_access_identity = aws_cloudfront_origin_access_identity.images.cloudfront_access_identity_path
    }
  }
  
  # Cache Behavior
  default_cache_behavior {
    target_origin_id       = "S3-${aws_s3_bucket.images.id}"
    viewer_protocol_policy = "redirect-to-https"
    allowed_methods        = ["GET", "HEAD", "OPTIONS"]
    cached_methods         = ["GET", "HEAD", "OPTIONS"]
    compress               = true
    
    # Cache Policy: Optimized
    forwarded_values {
      query_string = false
      cookies {
        forward = "none"
      }
    }
    
    # TTL ì„¤ì •
    min_ttl     = 0
    default_ttl = 86400   # 24ì‹œê°„
    max_ttl     = 604800  # 7ì¼
  }
  
  # SSL Certificate
  viewer_certificate {
    cloudfront_default_certificate = false
    acm_certificate_arn           = aws_acm_certificate.cdn.arn
    ssl_support_method            = "sni-only"
    minimum_protocol_version      = "TLSv1.2_2021"
  }
  
  # Custom Domain
  aliases = ["images.${var.domain_name}"]
  
  restrictions {
    geo_restriction {
      restriction_type = "none"
    }
  }
  
  tags = {
    Name        = "${var.environment}-images-cdn"
    Environment = var.environment
  }
}

# Origin Access Identity
resource "aws_cloudfront_origin_access_identity" "images" {
  comment = "OAI for S3 images bucket"
}

# S3 Bucket Policy (CloudFrontë§Œ ì•¡ì„¸ìŠ¤)
resource "aws_s3_bucket_policy" "images_cdn" {
  bucket = aws_s3_bucket.images.id
  
  policy = jsonencode({
    Version = "2012-10-17"
    Statement = [
      {
        Sid    = "AllowCloudFrontOAI"
        Effect = "Allow"
        Principal = {
          AWS = aws_cloudfront_origin_access_identity.images.iam_arn
        }
        Action   = "s3:GetObject"
        Resource = "${aws_s3_bucket.images.arn}/*"
      }
    ]
  })
}

# ACM Certificate (us-east-1 í•„ìˆ˜!)
resource "aws_acm_certificate" "cdn" {
  provider          = aws.us_east_1
  domain_name       = "images.${var.domain_name}"
  validation_method = "DNS"
  
  lifecycle {
    create_before_destroy = true
  }
}

# Route53 Record
resource "aws_route53_record" "cdn" {
  zone_id = data.aws_route53_zone.main.zone_id
  name    = "images.${var.domain_name}"
  type    = "A"
  
  alias {
    name                   = aws_cloudfront_distribution.images.domain_name
    zone_id                = aws_cloudfront_distribution.images.hosted_zone_id
    evaluate_target_health = false
  }
}
```

---

### Phase 2: Backend API ë³€ê²½

**ë³€ê²½ ìœ„ì¹˜**: Backend ì €ì¥ì†Œ - `waste-service` API

#### 2.1 í™˜ê²½ ë³€ìˆ˜

```bash
# .env ë˜ëŠ” ConfigMap
CDN_ENABLED=true
CDN_BASE_URL=https://images.ecoeco.app
CDN_CACHE_TTL=86400
```

#### 2.2 API ì‘ë‹µ ë³€ê²½

```python
# í˜„ì¬
@app.post("/api/v1/waste/analyze")
async def create_analysis():
    job_id = str(uuid.uuid4())
    
    # S3 Pre-signed URL (ì—…ë¡œë“œìš©)
    upload_url = s3.generate_presigned_url(
        'put_object',
        Params={
            'Bucket': settings.S3_BUCKET_NAME,
            'Key': f'{job_id}.jpg'
        },
        ExpiresIn=300  # 5ë¶„
    )
    
    return {
        "job_id": job_id,
        "upload_url": upload_url
    }


# ë³€ê²½ í›„
@app.post("/api/v1/waste/analyze")
async def create_analysis():
    job_id = str(uuid.uuid4())
    
    # S3 Pre-signed URL (ì—…ë¡œë“œìš© - ë³€ê²½ ì—†ìŒ)
    upload_url = s3.generate_presigned_url(
        'put_object',
        Params={
            'Bucket': settings.S3_BUCKET_NAME,
            'Key': f'{job_id}.jpg',
            'ContentType': 'image/jpeg'
        },
        ExpiresIn=300
    )
    
    # CDN URL (ë‹¤ìš´ë¡œë“œ/í‘œì‹œìš© - ì‹ ê·œ)
    cdn_url = f"{settings.CDN_BASE_URL}/{job_id}.jpg"
    
    # Redis ì´ˆê¸° ì§„í–‰ë¥  (DB 2 - ë³€ê²½ ì—†ìŒ)
    await redis_progress.setex(
        f"job:{job_id}:progress",
        3600,
        json.dumps({
            "progress": 0,
            "status": "pending",
            "message": "ì—…ë¡œë“œ ëŒ€ê¸° ì¤‘"
        })
    )
    
    return {
        "job_id": job_id,
        "upload_url": upload_url,  # S3 ì—…ë¡œë“œìš©
        "image_url": cdn_url       # CDN í‘œì‹œìš© (ì‹ ê·œ!)
    }
```

---

### Phase 3: Worker ë³€ê²½ (í•µì‹¬!)

**ë³€ê²½ ìœ„ì¹˜**: Backend ì €ì¥ì†Œ - `workers/vision_worker.py`

#### 3.1 Redis ì´ë¯¸ì§€ í•´ì‹œ ìºì‹± ì œê±°

```python
# âŒ ì´ì „: Redis DB 1ì— pHash ê¸°ë°˜ ìºì‹±
def analyze_image(job_id):
    # S3ì—ì„œ ë‹¤ìš´ë¡œë“œ
    image_path = download_from_s3(f"{job_id}.jpg")
    
    # pHash ê³„ì‚°
    img = Image.open(image_path)
    phash = str(imagehash.phash(img, hash_size=16))
    
    # Redis ìºì‹œ í™•ì¸
    cache_key = f"cache:image:hash:{phash}"
    cached = redis_cache.get(cache_key)  # Redis DB 1
    
    if cached:
        return json.loads(cached)
    
    # AI ë¶„ì„
    result = analyze_with_gpt4o_vision(image_path)
    
    # Redis ìºì‹± (7ì¼)
    redis_cache.setex(cache_key, 86400 * 7, json.dumps(result))
    
    return result
```

#### 3.2 CDN ê¸°ë°˜ ì´ë¯¸ì§€ ë¡œë“œ

```python
# âœ… ë³€ê²½ í›„: CDNì—ì„œ ì´ë¯¸ì§€ ë¡œë“œ (Redis ìºì‹± ì œê±°)
import requests
from io import BytesIO
from PIL import Image

def analyze_image(job_id):
    """
    CDN + S3 ê¸°ë°˜ ì´ë¯¸ì§€ ë¶„ì„
    - Redis ì´ë¯¸ì§€ í•´ì‹œ ìºì‹± ì œê±°
    - CDNì—ì„œ ì´ë¯¸ì§€ ë¡œë“œ (Edge Cache í™œìš©)
    """
    # 1. CDNì—ì„œ ì´ë¯¸ì§€ ë¡œë“œ
    update_progress(job_id, 10, "ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘...")
    image_data = download_from_cdn(job_id)
    
    # 2. ì´ë¯¸ì§€ ë¡œë“œ
    update_progress(job_id, 30, "ì´ë¯¸ì§€ ë¶„ì„ ì¤€ë¹„ ì¤‘...")
    img = Image.open(BytesIO(image_data))
    
    # 3. AI ë¶„ì„ (pHash ê³„ì‚° ì œê±°!)
    update_progress(job_id, 50, "AI ë¶„ì„ ì¤‘...")
    result = analyze_with_gpt4o_vision(image_data)
    
    # 4. í”¼ë“œë°± ìƒì„±
    update_progress(job_id, 70, "í”¼ë“œë°± ìƒì„± ì¤‘...")
    feedback = generate_feedback(result)
    
    # 5. DB ì €ì¥
    update_progress(job_id, 90, "ì €ì¥ ì¤‘...")
    save_to_db(job_id, result, feedback)
    
    # 6. ì™„ë£Œ
    update_progress(job_id, 100, "ì™„ë£Œ!")
    
    return {
        "waste_type": result['waste_type'],
        "confidence": result['confidence'],
        "feedback": feedback,
        "analyzed_at": datetime.now().isoformat()
    }


def download_from_cdn(job_id):
    """
    CDNì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
    - CloudFront Edge Locationì—ì„œ ìºì‹œ íˆíŠ¸ ì‹œ ë¹ ë¦„
    - Cache Miss ì‹œ S3 Originì—ì„œ ê°€ì ¸ì˜´
    """
    cdn_url = f"{settings.CDN_BASE_URL}/{job_id}.jpg"
    
    try:
        response = requests.get(cdn_url, timeout=10)
        response.raise_for_status()
        
        # CloudFront ìºì‹œ íˆíŠ¸ í™•ì¸ (ë””ë²„ê¹…ìš©)
        cache_status = response.headers.get('X-Cache', 'Unknown')
        logger.info(f"CDN Cache Status: {cache_status}")
        
        return response.content
        
    except requests.RequestException as e:
        logger.error(f"CDN ë¡œë“œ ì‹¤íŒ¨: {e}")
        # Fallback: S3 ì§ì ‘ ë‹¤ìš´ë¡œë“œ
        return download_from_s3_fallback(job_id)


def download_from_s3_fallback(job_id):
    """
    S3 Fallback (CDN ì¥ì•  ì‹œ)
    - CDNì´ ì‘ë‹µí•˜ì§€ ì•Šì„ ë•Œë§Œ ì‚¬ìš©
    """
    logger.warning(f"S3 Fallback for job {job_id}")
    
    s3 = boto3.client('s3')
    obj = s3.get_object(
        Bucket=settings.S3_BUCKET_NAME,
        Key=f"{job_id}.jpg"
    )
    return obj['Body'].read()


def analyze_with_gpt4o_vision(image_data):
    """
    GPT-4o Vision API í˜¸ì¶œ
    - ë°”ì´ë„ˆë¦¬ ë°ì´í„°ë¥¼ base64ë¡œ ì¸ì½”ë”©
    """
    import base64
    
    # Base64 ì¸ì½”ë”©
    image_base64 = base64.b64encode(image_data).decode('utf-8')
    
    # OpenAI API í˜¸ì¶œ
    response = openai.ChatCompletion.create(
        model="gpt-4o",
        messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": "ì´ ì“°ë ˆê¸°ì˜ ì¬ì§ˆê³¼ ë¶„ë¥˜ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”."
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{image_base64}"
                        }
                    }
                ]
            }
        ]
    )
    
    return {
        "waste_type": response.choices[0].message.content,
        "confidence": 0.95
    }


def update_progress(job_id, progress, message):
    """
    Redis DB 2: ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (ë³€ê²½ ì—†ìŒ)
    """
    redis_progress.setex(
        f"job:{job_id}:progress",
        3600,
        json.dumps({
            "progress": progress,
            "message": message,
            "updated_at": datetime.now().isoformat()
        })
    )
```

---

### Phase 4: í”„ë¡ íŠ¸ì—”ë“œ ë³€ê²½

**ë³€ê²½ ìœ„ì¹˜**: Frontend ì €ì¥ì†Œ

```typescript
// API ì‘ë‹µ íƒ€ì…
interface AnalysisResponse {
  job_id: string;
  upload_url: string;  // S3 ì—…ë¡œë“œìš©
  image_url: string;   // CDN í‘œì‹œìš© (ì‹ ê·œ!)
}

// ì´ë¯¸ì§€ ì—…ë¡œë“œ ë° ë¶„ì„
async function analyzeWaste(imageFile: File) {
  // 1. ë¶„ì„ ìš”ì²­ (Job ID + URL ë°œê¸‰)
  const response = await fetch('/api/v1/waste/analyze', {
    method: 'POST'
  });
  const { job_id, upload_url, image_url } = await response.json();
  
  // 2. S3ì— ì§ì ‘ ì—…ë¡œë“œ (Presigned URL)
  await fetch(upload_url, {
    method: 'PUT',
    body: imageFile,
    headers: {
      'Content-Type': 'image/jpeg'
    }
  });
  
  // 3. ì—…ë¡œë“œ ì™„ë£Œ ì•Œë¦¼
  await fetch(`/api/v1/upload-complete/${job_id}`, {
    method: 'POST'
  });
  
  // 4. ë¶„ì„ ê²°ê³¼ í´ë§
  const result = await pollAnalysisResult(job_id);
  
  // 5. ê²°ê³¼ í‘œì‹œ (CDN ì´ë¯¸ì§€ ì‚¬ìš©)
  displayResult(result, image_url);  // CDN URL!
  
  return result;
}

// ê²°ê³¼ í‘œì‹œ
function displayResult(result: AnalysisResult, imageUrl: string) {
  return (
    <div className="result-card">
      {/* CDNì—ì„œ ë¹ ë¥´ê²Œ ë¡œë“œ! */}
      <img src={imageUrl} alt="ë¶„ì„ ì´ë¯¸ì§€" />
      
      <div className="result-info">
        <h3>{result.waste_type}</h3>
        <p>{result.feedback}</p>
        <span>ì‹ ë¢°ë„: {result.confidence}%</span>
      </div>
    </div>
  );
}
```

---

## âŒ Redis ìºì‹± ì œê±°

### ì œê±° í•­ëª©

#### 1. Redis DB 1: Image Hash Cache (ì œê±°)

```python
# âŒ ì œê±°í•  ì½”ë“œ
cache_key = f"cache:image:hash:{phash}"
cached = redis_cache.get(cache_key)

if cached:
    return json.loads(cached)

redis_cache.setex(cache_key, 86400 * 7, json.dumps(result))
```

**ì œê±° ì´ìœ **:
- âŒ pHash ê³„ì‚°ì„ ìœ„í•´ ì „ì²´ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ í•„ìš”
- âŒ 70% ìºì‹œ íˆíŠ¸ìœ¨ë„ 30%ëŠ” ë‹¤ìš´ë¡œë“œ
- âŒ Redis ë©”ëª¨ë¦¬ ì‚¬ìš©
- âœ… CDNì´ ì´ë¯¸ì§€ ìì²´ë¥¼ ìºì‹± (ë” íš¨ìœ¨ì )

#### 2. imagehash ë¼ì´ë¸ŒëŸ¬ë¦¬ ì˜ì¡´ì„± ì œê±°

```bash
# requirements.txt
# âŒ ì œê±°
imagehash==4.3.1
```

#### 3. Redis DB 1 ì‚¬ìš© ì¤‘ë‹¨

```python
# Redis ì—°ê²° (ê¸°ì¡´)
redis_cache = redis.Redis(host='redis.default', port=6379, db=1)      # âŒ ì‚¬ìš© ì¤‘ë‹¨
redis_progress = redis.Redis(host='redis.default', port=6379, db=2)   # âœ… ê³„ì† ì‚¬ìš©
redis_celery = redis.Redis(host='redis.default', port=6379, db=0)     # âœ… ê³„ì† ì‚¬ìš©
```

**Redis ì‚¬ìš© í˜„í™©**:
- DB 0: Celery Result Backend âœ… (ìœ ì§€)
- DB 1: Image Hash Cache âŒ (ì œê±°)
- DB 2: Job Progress Tracking âœ… (ìœ ì§€)
- DB 3: Session Store âœ… (ìœ ì§€)

---

## ğŸ“Š ì„±ëŠ¥ ë¹„êµ

### ì´ì „: Redis ìºì‹±

```
ì‹œë‚˜ë¦¬ì˜¤: ì›” 10,000 ì´ë¯¸ì§€ ë¶„ì„ ìš”ì²­

ìºì‹œ íˆíŠ¸ (70%):
- Worker â†’ S3 ë‹¤ìš´ë¡œë“œ: 0íšŒ (ìºì‹œë¨)
- Worker â†’ Redis ì¡°íšŒ: 7,000íšŒ
- AI API í˜¸ì¶œ: 0íšŒ
- ì‘ë‹µ ì‹œê°„: 1ì´ˆ

ìºì‹œ ë¯¸ìŠ¤ (30%):
- Worker â†’ S3 ë‹¤ìš´ë¡œë“œ: 3,000íšŒ âŒ
- Worker â†’ pHash ê³„ì‚°: 3,000íšŒ âŒ
- Worker â†’ Redis ì €ì¥: 3,000íšŒ
- AI API í˜¸ì¶œ: 3,000íšŒ
- ì‘ë‹µ ì‹œê°„: 3-5ì´ˆ

ë¹„ìš©:
- S3 ë°ì´í„° ì „ì†¡: 3,000 Ã— 2MB Ã— $0.126/GB = $0.76
- AI API: 3,000 Ã— $0.01 = $30
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ì´ ë¹„ìš©: $30.76/ì›”
```

### ë³€ê²½ í›„: CDN ìºì‹±

```
ì‹œë‚˜ë¦¬ì˜¤: ì›” 10,000 ì´ë¯¸ì§€ ë¶„ì„ ìš”ì²­

CDN ìºì‹œ íˆíŠ¸ (50-70%):
- Worker â†’ CDN ë‹¤ìš´ë¡œë“œ: 10,000íšŒ (Edgeì—ì„œ ë¹ ë¦„!)
- CDN â†’ S3 ìš”ì²­: 3,000-5,000íšŒë§Œ
- AI API í˜¸ì¶œ: 10,000íšŒ (ìºì‹± ì—†ìŒ)
- ì‘ë‹µ ì‹œê°„: 2-4ì´ˆ (ì¼ê´€ë¨)

ë¹„ìš©:
- S3 GET ìš”ì²­: 3,000 Ã— $0.0004/1000 = $0.0012
- S3 ë°ì´í„° ì „ì†¡ (S3 â†’ CDN): 3,000 Ã— 2MB Ã— $0.02/GB = $0.12
- CloudFront ë°ì´í„° ì „ì†¡: 10,000 Ã— 2MB Ã— $0.085/GB = $1.70
- CloudFront ìš”ì²­: 10,000 Ã— $0.0075/10,000 = $0.0075
- AI API: 10,000 Ã— $0.01 = $100
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ì´ ë¹„ìš©: $101.83/ì›”

ë¹„ìš© ì¦ê°€: +$71/ì›” (AI APIê°€ ì£¼ì›ì¸)
```

### ğŸ¤” ë¹„ìš© ì¦ê°€ ë¬¸ì œ í•´ê²°

**ë¬¸ì œ**: Redis ìºì‹± ì œê±°ë¡œ AI API í˜¸ì¶œ 3ë°° ì¦ê°€ (30% â†’ 100%)

**í•´ê²° ë°©ì•ˆ 1: Aggressive CDN Caching + ê²°ê³¼ ìºì‹±**

```python
# AI ë¶„ì„ ê²°ê³¼ë¥¼ job_id ê¸°ë°˜ìœ¼ë¡œ ìºì‹±
def analyze_image(job_id):
    # 1. CDNì—ì„œ ì´ë¯¸ì§€ ë¡œë“œ
    image_data = download_from_cdn(job_id)
    
    # 2. job_id ê¸°ë°˜ ê²°ê³¼ ìºì‹± í™•ì¸
    cache_key = f"result:{job_id}"
    cached = redis_result.get(cache_key)
    
    if cached:
        return json.loads(cached)
    
    # 3. AI ë¶„ì„
    result = analyze_with_gpt4o_vision(image_data)
    
    # 4. ê²°ê³¼ ìºì‹± (7ì¼)
    redis_result.setex(cache_key, 86400 * 7, json.dumps(result))
    
    return result
```

**íš¨ê³¼**:
- âœ… ê°™ì€ job_id ì¬ì¡°íšŒ ì‹œ ìºì‹œ íˆíŠ¸ (70%)
- âœ… AI API í˜¸ì¶œ: 3,000íšŒë¡œ ê°ì†Œ
- âœ… ë¹„ìš©: $30.76/ì›”ë¡œ ë³µê·€

**í•´ê²° ë°©ì•ˆ 2: ì´ë¯¸ì§€ ì¤‘ë³µ ì œê±° (DynamoDB Hash Table)**

```python
# ì´ë¯¸ì§€ Content Hash ê¸°ë°˜ ì¤‘ë³µ ì œê±°
import hashlib

def analyze_image(job_id):
    # 1. CDNì—ì„œ ì´ë¯¸ì§€ ë¡œë“œ
    image_data = download_from_cdn(job_id)
    
    # 2. Content Hash ê³„ì‚° (SHA256)
    content_hash = hashlib.sha256(image_data).hexdigest()
    
    # 3. DynamoDBì—ì„œ ì¤‘ë³µ í™•ì¸
    cached = dynamodb.get_item(
        TableName='waste-analysis-cache',
        Key={'content_hash': content_hash}
    )
    
    if cached:
        return cached['result']
    
    # 4. AI ë¶„ì„
    result = analyze_with_gpt4o_vision(image_data)
    
    # 5. DynamoDB ì €ì¥
    dynamodb.put_item(
        TableName='waste-analysis-cache',
        Item={
            'content_hash': content_hash,
            'result': result,
            'ttl': int(time.time()) + 86400 * 7
        }
    )
    
    return result
```

---

## âœ… ìµœì¢… ì•„í‚¤í…ì²˜ (ê¶Œì¥)

### í•˜ì´ë¸Œë¦¬ë“œ: CDN + job_id ê¸°ë°˜ ìºì‹±

```mermaid
sequenceDiagram
    participant App as Mobile App
    participant API as Backend API
    participant Worker as AI Worker
    participant CDN as CloudFront CDN
    participant S3 as AWS S3
    participant Redis as Redis DB 2
    participant AI as GPT-4o Vision

    App->>API: 1. POST /analyze
    API->>App: 2. job_id + Presigned URL + CDN URL
    App->>S3: 3. ì´ë¯¸ì§€ ì§ì ‘ ì—…ë¡œë“œ
    
    App->>API: 4. POST /upload-complete/{job_id}
    API->>Worker: 5. Task ë°œí–‰
    
    Worker->>CDN: 6. ì´ë¯¸ì§€ ìš”ì²­ (CDN URL)
    CDN-->>Worker: ì´ë¯¸ì§€ ë°˜í™˜ (Edge Cache)
    
    Worker->>Redis: 7. ê²°ê³¼ ìºì‹œ í™•ì¸ (job_id ê¸°ë°˜)
    
    alt Cache Hit (70%)
        Redis-->>Worker: AI ê²°ê³¼ ë°˜í™˜
        Worker-->>App: ì¦‰ì‹œ ì‘ë‹µ (1ì´ˆ)
    else Cache Miss (30%)
        Worker->>AI: 8. GPT-4o Vision API
        AI-->>Worker: ë¶„ë¥˜ ê²°ê³¼
        Worker->>Redis: 9. ê²°ê³¼ ìºì‹± (7ì¼)
        Worker-->>App: ë¶„ì„ ê²°ê³¼ (2-4ì´ˆ)
    end
    
    App->>CDN: 10. ì´ë¯¸ì§€ í‘œì‹œ (CDN URL)
    CDN-->>App: ë¹ ë¥¸ ë¡œë“œ!
```

**íŠ¹ì§•**:
- âœ… CDN: ì´ë¯¸ì§€ íŒŒì¼ ìºì‹± (Edge Location)
- âœ… Redis: AI ë¶„ì„ ê²°ê³¼ ìºì‹± (job_id ê¸°ë°˜)
- âœ… 70% AI ë¹„ìš© ì ˆê° ìœ ì§€
- âœ… í”„ë¡ íŠ¸ì—”ë“œ ì´ë¯¸ì§€ ë¡œë“œ ë¹ ë¦„
- âœ… Worker ë„¤íŠ¸ì›Œí¬ ë¶€í•˜ ê°ì†Œ

---

## ğŸ¯ êµ¬í˜„ ìš°ì„ ìˆœìœ„

### Phase 1: CloudFront ì¸í”„ë¼ (ì´ë²ˆ PR)
- [ ] `terraform/cloudfront.tf` ìƒì„±
- [ ] `terraform/main.tf` provider ì¶”ê°€
- [ ] `terraform/s3.tf` Bucket Policy ìˆ˜ì •
- [ ] `terraform apply` ì‹¤í–‰
- [ ] DNS ì „íŒŒ í™•ì¸

### Phase 2: Backend ë³€ê²½ (ë‹¤ìŒ PR)
- [ ] API: CDN URL ì‘ë‹µ ì¶”ê°€
- [ ] Worker: CDN ì´ë¯¸ì§€ ë¡œë“œ êµ¬í˜„
- [ ] Worker: job_id ê¸°ë°˜ ê²°ê³¼ ìºì‹± êµ¬í˜„ (Redis DB 1 ì¬í™œìš©)
- [ ] Worker: pHash ê³„ì‚° ì œê±°
- [ ] í…ŒìŠ¤íŠ¸

### Phase 3: í”„ë¡ íŠ¸ì—”ë“œ ë³€ê²½ (ë‹¤ìŒ PR)
- [ ] API ì‘ë‹µ íƒ€ì… ì—…ë°ì´íŠ¸
- [ ] CDN URL ì‚¬ìš© êµ¬í˜„
- [ ] í…ŒìŠ¤íŠ¸

### Phase 4: ê²€ì¦ ë° ìµœì í™”
- [ ] CloudFront ë©”íŠ¸ë¦­ ëª¨ë‹ˆí„°ë§
- [ ] ë¹„ìš© ì¶”ì 
- [ ] ì„±ëŠ¥ ì¸¡ì •
- [ ] ë¬¸ì„œ ì—…ë°ì´íŠ¸

---

## ğŸ“š ì°¸ê³  ìë£Œ

- [ìš°ì•„í•œí˜•ì œë“¤ - S3 ì—…ë¡œë“œ ì„¸ ê°€ì§€ ë°©ë²•](https://techblog.woowahan.com/11392/)
- [AWS CloudFront ë¬¸ì„œ](https://docs.aws.amazon.com/cloudfront/)
- [AWS S3 Presigned URL](https://docs.aws.amazon.com/AmazonS3/latest/userguide/PresignedUrlUploadObject.html)
- [í˜„ì¬ ì´ë¯¸ì§€ ì²˜ë¦¬ ì•„í‚¤í…ì²˜](docs/architecture/image-processing-architecture.md)

---

**ì‘ì„±ì¼**: 2025-11-06  
**ì‘ì„±ì**: AI Assistant  
**ë¸Œëœì¹˜**: feature/cdn-image-caching


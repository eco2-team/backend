# ğŸ—ï¸ ìµœì¢… Worker ë…¸ë“œ ë°°ì¹˜ (GPT-5 ë©€í‹°ëª¨ë‹¬ ê¸°ë°˜)

## ğŸ“Š ì „ì œ ì¡°ê±´

### AI íŒŒì´í”„ë¼ì¸ (4ë‹¨ê³„)

```yaml
Stage 1: Preprocess
  - S3 ì—…ë¡œë“œ, ì´ë¯¸ì§€ ì „ì²˜ë¦¬
  - Pool: processes
  - íŠ¹ì„±: I/O Bound (S3)

Stage 2: GPT-5 ë©€í‹°ëª¨ë‹¬ â­
  - ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ ë™ì‹œ ì…ë ¥
  - ê°ì²´ ì¸ì‹, ìƒíƒœ ë¶„ì„, í’ˆëª© ë¶„ë¥˜
  - Pool: gevent
  - íŠ¹ì„±: Network Bound (ì™¸ë¶€ API)

Stage 3: RAG
  - JSON ì¡°íšŒ, ì»¨í…ìŠ¤íŠ¸ ê²°í•©
  - Pool: processes
  - íŠ¹ì„±: Compute Bound (ê²½ëŸ‰)

Stage 4: GPT-4o mini
  - 3ê°€ì§€ ì…ë ¥ ê²°í•©, ì‘ë‹µ ìƒì„±
  - Pool: gevent
  - íŠ¹ì„±: Network Bound (ì™¸ë¶€ API)

Scheduler: Celery Beat
  - ì£¼ê¸° ì‘ì—… ìŠ¤ì¼€ì¤„ë§
  - íŠ¹ì„±: ê·¹íˆ ê²½ëŸ‰
```

---

## ğŸ¯ ë°°ì¹˜ ì „ëµ

### ì›ì¹™

```yaml
1. ì›Œí¬ë¡œë“œ íŠ¹ì„±ë³„ ë¶„ë¦¬:
   âœ… I/O + CPU ì§‘ì•½ (processes)
   âœ… Network ì§‘ì•½ (gevent)

2. ë¦¬ì†ŒìŠ¤ ê· í˜•:
   âœ… ë‘ ë…¸ë“œ ëª¨ë‘ 60-70% ì‚¬ìš©ë¥ 
   âœ… ì—¬ìœ  ë¦¬ì†ŒìŠ¤ í™•ë³´

3. ë‹¨ìˆœì„±:
   âœ… ìµœì†Œ ë…¸ë“œ ìˆ˜ (2ê°œ)
   âœ… ëª…í™•í•œ ë¶„ë¦¬
```

---

## ğŸ–¥ï¸ ìµœì¢… ë…¸ë“œ ë°°ì¹˜

### Worker-1: I/O + Compute

```yaml
ë…¸ë“œ: k8s-worker-1
ì¸ìŠ¤í„´ìŠ¤: t3.medium
ë¦¬ì†ŒìŠ¤: 2 vCPU (2000m), 4GB RAM (4096Mi)
ë¼ë²¨: workload=async-workers
ë„¤ì„ìŠ¤í˜ì´ìŠ¤: workers

ë°°ì¹˜ëœ Worker:
  1. preprocess-worker (Ã—3)
  2. rag-worker (Ã—2)
  3. celery-beat (Ã—1)

íŠ¹ì§•:
  - processes pool ìœ„ì£¼
  - I/O + CPU ì²˜ë¦¬
  - Beat ìŠ¤ì¼€ì¤„ëŸ¬ í¬í•¨
```

### Worker-2: Network (API)

```yaml
ë…¸ë“œ: k8s-worker-2
ì¸ìŠ¤í„´ìŠ¤: t3.medium
ë¦¬ì†ŒìŠ¤: 2 vCPU (2000m), 4GB RAM (4096Mi)
ë¼ë²¨: workload=async-workers
ë„¤ì„ìŠ¤í˜ì´ìŠ¤: workers

ë°°ì¹˜ëœ Worker:
  1. gpt5-worker (Ã—5)
  2. gpt4o-worker (Ã—3)

íŠ¹ì§•:
  - gevent pool ì „ìš©
  - ì™¸ë¶€ API í˜¸ì¶œ
  - ë†’ì€ concurrency
```

---

## ğŸ“‹ Worker-1 ìƒì„¸ êµ¬ì„±

### 1. preprocess-worker (Ã—3 Pods)

```yaml
ì—­í• : ì´ë¯¸ì§€ ì „ì²˜ë¦¬
í: q.preprocess

ì‘ì—…:
  - S3 ì—…ë¡œë“œ (boto3)
  - ì´ë¯¸ì§€ í•´ì‹œ ê³„ì‚° (hashlib)
  - ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì§• (PIL)
  - Redis ìºì‹œ ì²´í¬

ì›Œí¬ë¡œë“œ íŠ¹ì„±:
  I/O: ë§¤ìš° ë†’ìŒ (S3 ì—…ë¡œë“œ)
  CPU: ì¤‘ê°„ (ì´ë¯¸ì§€ ì²˜ë¦¬)
  Network: ë†’ìŒ (AWS API)

Pool ì„¤ì •:
  Pool: processes (ì´ë¯¸ì§€ ì²˜ë¦¬ GIL íšŒí”¼)
  Concurrency: 8
  Prefetch: 4

ë¦¬ì†ŒìŠ¤ (ê° Pod):
  requests:
    cpu: 300m
    memory: 256Mi
  limits:
    cpu: 1000m
    memory: 512Mi

ì´ ë¦¬ì†ŒìŠ¤ (3 Pods):
  CPU requests: 900m (45%)
  CPU limits: 3000m (150%)
  RAM requests: 768Mi (18.75%)
  RAM limits: 1536Mi (37.5%)

ì²˜ë¦¬ ëŠ¥ë ¥:
  ë™ì‹œ ì²˜ë¦¬: 24ê°œ (3 Pods Ã— 8 concurrency)
```

### 2. rag-worker (Ã—2 Pods)

```yaml
ì—­í• : RAG ì¡°íšŒ ë° ì»¨í…ìŠ¤íŠ¸ ê²°í•©
í: q.rag

ì‘ì—…:
  - item_id ê¸°ë°˜ JSON íŒŒì¼ ì¡°íšŒ
  - í•µì‹¬ ë¬¸ì¥ í•„í„°ë§
  - Prompt êµ¬ì„±
  - ì¤‘ë³µ ì œê±°

ì›Œí¬ë¡œë“œ íŠ¹ì„±:
  CPU: ë‚®ìŒ (í…ìŠ¤íŠ¸ ì²˜ë¦¬)
  I/O: ë‚®ìŒ (ë¡œì»¬ íŒŒì¼, ìºì‹±)
  Memory: ë‚®ìŒ
  Network: ì—†ìŒ

Pool ì„¤ì •:
  Pool: processes (CPU ë³‘ë ¬ ì²˜ë¦¬)
  Concurrency: 4
  Prefetch: 4

ë¦¬ì†ŒìŠ¤ (ê° Pod):
  requests:
    cpu: 200m
    memory: 256Mi
  limits:
    cpu: 800m
    memory: 512Mi

ì´ ë¦¬ì†ŒìŠ¤ (2 Pods):
  CPU requests: 400m (20%)
  CPU limits: 1600m (80%)
  RAM requests: 512Mi (12.5%)
  RAM limits: 1024Mi (25%)

ì²˜ë¦¬ ëŠ¥ë ¥:
  ë™ì‹œ ì²˜ë¦¬: 8ê°œ (2 Pods Ã— 4 concurrency)
  
íŠ¹ì§•:
  âœ… ë§¤ìš° ë¹ ë¦„ (<0.5ì´ˆ)
  âœ… Key-Value ì¡°íšŒ (Sentence-BERT ë¶ˆí•„ìš”)
  âœ… ê²½ëŸ‰ ì›Œí¬ë¡œë“œ
```

### 3. celery-beat (Ã—1 Pod)

```yaml
ì—­í• : ì£¼ê¸° ì‘ì—… ìŠ¤ì¼€ì¤„ëŸ¬
í: N/A (Task ë°œí–‰ë§Œ)

ì‘ì—…:
  - ìŠ¤ì¼€ì¤„ ê´€ë¦¬ (cron)
  - Task ë°œí–‰ (RabbitMQ)
  - ì˜ˆì•½ ì‘ì—… ì‹¤í–‰

ì˜ˆì‹œ ìŠ¤ì¼€ì¤„:
  - ë§¤ì¼ 03:00 â†’ ì˜¤ë˜ëœ ì´ë¯¸ì§€ ì •ë¦¬ (S3)
  - ë§¤ì‹œê°„ 00ë¶„ â†’ Redis ìºì‹œ ì •ë¦¬
  - ë§¤ì¼ 02:00 â†’ ì¼ì¼ í†µê³„ ì§‘ê³„

ì›Œí¬ë¡œë“œ íŠ¹ì„±:
  CPU: ê·¹íˆ ë‚®ìŒ
  Memory: ë‚®ìŒ
  Network: ë‚®ìŒ (ì£¼ê¸°ì  Task ë°œí–‰)

ë¦¬ì†ŒìŠ¤ (1 Pod):
  requests:
    cpu: 50m
    memory: 128Mi
  limits:
    cpu: 200m
    memory: 256Mi

ì œì•½ì‚¬í•­:
  âš ï¸ ë°˜ë“œì‹œ 1ê°œë§Œ ì‹¤í–‰ (ì¤‘ë³µ ë°©ì§€)
  âš ï¸ Recreate ì „ëµ (RollingUpdate ê¸ˆì§€)
  âš ï¸ PersistentScheduler ì‚¬ìš©

íŠ¹ì§•:
  âœ… ë§¤ìš° ê²½ëŸ‰
  âœ… ì–´ë””ë“  ë°°ì¹˜ ê°€ëŠ¥
  âœ… Worker-1ì— ë°°ì¹˜ (ë¦¬ì†ŒìŠ¤ ì—¬ìœ )
```

### Worker-1 ì´í•©

```yaml
ì´ Pod ìˆ˜: 6ê°œ
  - preprocess: 3 Pods
  - rag: 2 Pods
  - beat: 1 Pod

ì´ ë¦¬ì†ŒìŠ¤ (requests):
  CPU: 900m + 400m + 50m = 1350m / 2000m (67.5%) âœ…
  RAM: 768Mi + 512Mi + 128Mi = 1408Mi / 4096Mi (34%) âœ…

ì´ ë¦¬ì†ŒìŠ¤ (limits):
  CPU: 3000m + 1600m + 200m = 4800m (240%)
  RAM: 1536Mi + 1024Mi + 256Mi = 2816Mi (69%)

ì—¬ìœ  (requests ê¸°ì¤€):
  CPU: 650m (32.5%)
  RAM: 2688Mi (66%)

ìƒíƒœ: âœ… ë§¤ìš° ì•ˆì „

íŠ¹ì§•:
  - processes pool ìœ„ì£¼
  - I/O + CPU ì²˜ë¦¬
  - Beat ìŠ¤ì¼€ì¤„ëŸ¬ í¬í•¨
  - CPU over-commit (240%) í—ˆìš© (ìˆœì°¨ ì²˜ë¦¬)
```

---

## ğŸ“‹ Worker-2 ìƒì„¸ êµ¬ì„±

### 1. gpt5-worker (Ã—5 Pods) â­

```yaml
ì—­í• : GPT-5 ë©€í‹°ëª¨ë‹¬ ë¶„ì„
í: q.gpt5

ì‘ì—…:
  - GPT-5 API í˜¸ì¶œ (ë©€í‹°ëª¨ë‹¬)
  - ì´ë¯¸ì§€ + ì‚¬ìš©ì ì§ˆë¬¸ ë™ì‹œ ì…ë ¥
  - ê°ì²´ ì¸ì‹ (waste_category, subcategory)
  - ìƒíƒœ ë¶„ì„ (ëšœê»‘, ì„¸ì²™, ì˜¤ì—¼ë„)
  - í’ˆëª© ë¶„ë¥˜ (item_id)

ì›Œí¬ë¡œë“œ íŠ¹ì„±:
  Network: ë§¤ìš° ë†’ìŒ (ì™¸ë¶€ API)
  CPU: ë§¤ìš° ë‚®ìŒ (JSON íŒŒì‹±ë§Œ)
  Memory: ë‚®ìŒ

API ìƒì„¸:
  ëª¨ë¸: gpt-5-turbo (ë˜ëŠ” gpt-5)
  ì…ë ¥: ì´ë¯¸ì§€ URL + ì‚¬ìš©ì ì§ˆë¬¸
  ì¶œë ¥: JSON (í’ˆëª© ì •ë³´ + ìƒíƒœ)
  ì‘ë‹µ ì‹œê°„: 3-5ì´ˆ
  ë¹„ìš©: GPT-4o ëŒ€ë¹„ 55-90% ì ˆê°

Pool ì„¤ì •:
  Pool: gevent (ë¹„ë™ê¸° I/O)
  Concurrency: 20 (ë„¤íŠ¸ì›Œí¬ ëŒ€ê¸° í™œìš©)
  Prefetch: 1 (Rate Limit ì¤€ìˆ˜)

ë¦¬ì†ŒìŠ¤ (ê° Pod):
  requests:
    cpu: 100m
    memory: 256Mi
  limits:
    cpu: 500m
    memory: 512Mi

ì´ ë¦¬ì†ŒìŠ¤ (5 Pods):
  CPU requests: 500m (25%)
  CPU limits: 2500m (125%)
  RAM requests: 1280Mi (31.25%)
  RAM limits: 2560Mi (62.5%)

ì²˜ë¦¬ ëŠ¥ë ¥:
  ë™ì‹œ ì²˜ë¦¬: 100ê°œ (5 Pods Ã— 20 concurrency)

ë³‘ëª©:
  ğŸ”´ GPT-5 API Rate Limit
  ğŸ”´ API ì‘ë‹µ ì‹œê°„ (3-5ì´ˆ)
  
ì¤‘ìš”:
  âœ… Vision ê¸°ëŠ¥ ë‚´ì¥ (ë³„ë„ ëª¨ë¸ ë¶ˆí•„ìš”)
  âœ… ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬
  âœ… ê³ ì„±ëŠ¥, ì €ë¹„ìš©
```

### 2. gpt4o-worker (Ã—3 Pods)

```yaml
ì—­í• : GPT-4o mini ì‘ë‹µ ìƒì„±
í: q.gpt4o

ì‘ì—…:
  - GPT-4o mini API í˜¸ì¶œ
  - 3ê°€ì§€ ì…ë ¥ ê²°í•©:
    1ï¸âƒ£ ì‚¬ìš©ì ì§ˆë¬¸
    2ï¸âƒ£ GPT-5 ë¶„ì„ ê²°ê³¼
    3ï¸âƒ£ RAG ì»¨í…ìŠ¤íŠ¸
  - ë¶„ë¦¬ë°°ì¶œ ì•ˆë‚´ë¬¸ ìƒì„±

ì›Œí¬ë¡œë“œ íŠ¹ì„±:
  Network: ë†’ìŒ (ì™¸ë¶€ API)
  CPU: ë§¤ìš° ë‚®ìŒ
  Memory: ë‚®ìŒ

API ìƒì„¸:
  ëª¨ë¸: gpt-4o-mini
  ì…ë ¥: ì‚¬ìš©ì ì§ˆë¬¸ + GPT-5 ê²°ê³¼ + RAG
  ì¶œë ¥: ë¶„ë¦¬ë°°ì¶œ ì•ˆë‚´ë¬¸
  ì‘ë‹µ ì‹œê°„: 1-2ì´ˆ
  ë¹„ìš©: GPT-5 ëŒ€ë¹„ 1/10

Pool ì„¤ì •:
  Pool: gevent (ë¹„ë™ê¸° I/O)
  Concurrency: 10
  Prefetch: 2

ë¦¬ì†ŒìŠ¤ (ê° Pod):
  requests:
    cpu: 100m
    memory: 256Mi
  limits:
    cpu: 500m
    memory: 512Mi

ì´ ë¦¬ì†ŒìŠ¤ (3 Pods):
  CPU requests: 300m (15%)
  CPU limits: 1500m (75%)
  RAM requests: 768Mi (18.75%)
  RAM limits: 1536Mi (37.5%)

ì²˜ë¦¬ ëŠ¥ë ¥:
  ë™ì‹œ ì²˜ë¦¬: 30ê°œ (3 Pods Ã— 10 concurrency)

ë³‘ëª©:
  ğŸŸ¡ GPT-4o mini API Rate Limit
  ğŸŸ¡ API ì‘ë‹µ ì‹œê°„ (1-2ì´ˆ)

íŠ¹ì§•:
  âœ… ê²½ëŸ‰ ëª¨ë¸ (ë¹„ìš© 1/10)
  âœ… ì§§ì€ ì•ˆë‚´ë¬¸ ìƒì„± íŠ¹í™”
  âœ… Fine-tuning ê°€ëŠ¥ (í–¥í›„)
```

### Worker-2 ì´í•©

```yaml
ì´ Pod ìˆ˜: 8ê°œ
  - gpt5: 5 Pods
  - gpt4o: 3 Pods

ì´ ë¦¬ì†ŒìŠ¤ (requests):
  CPU: 500m + 300m = 800m / 2000m (40%) âœ…
  RAM: 1280Mi + 768Mi = 2048Mi / 4096Mi (50%) âœ…

ì´ ë¦¬ì†ŒìŠ¤ (limits):
  CPU: 2500m + 1500m = 4000m (200%)
  RAM: 2560Mi + 1536Mi = 4096Mi (100%)

ì—¬ìœ  (requests ê¸°ì¤€):
  CPU: 1200m (60%)
  RAM: 2048Mi (50%)

ìƒíƒœ: âœ… ì•ˆì „

íŠ¹ì§•:
  - gevent pool ì „ìš©
  - ì™¸ë¶€ API í˜¸ì¶œ
  - ëŒ€ë¶€ë¶„ ì‹œê°„ì„ API ëŒ€ê¸°
  - ì‹¤ì œ CPU ì‚¬ìš© 10-20%
  - CPU over-commit (200%) í—ˆìš© (ë¹„ë™ê¸° I/O)
```

---

## ğŸ“Š ì „ì²´ í´ëŸ¬ìŠ¤í„° ìš”ì•½

### ì´ ë¦¬ì†ŒìŠ¤

```yaml
ì´ ë…¸ë“œ: 2ê°œ (Worker-1, Worker-2)
ì´ Pod: 14ê°œ
  Worker-1: 6 Pods (preprocess Ã—3, rag Ã—2, beat Ã—1)
  Worker-2: 8 Pods (gpt5 Ã—5, gpt4o Ã—3)

ì´ vCPU: 4 cores (4000m)
ì´ RAM: 8GB (8192Mi)

ì‚¬ìš©ëŸ‰ (requests):
  CPU: 1350m + 800m = 2150m / 4000m (53.75%) âœ…
  RAM: 1408Mi + 2048Mi = 3456Mi / 8192Mi (42%) âœ…

ì—¬ìœ  (requests):
  CPU: 1850m (46.25%)
  RAM: 4736Mi (58%)

ìƒíƒœ: âœ… ë§¤ìš° ì•ˆì „
```

### ì²˜ë¦¬ ëŠ¥ë ¥

```yaml
Preprocess:
  ë™ì‹œ ì²˜ë¦¬: 24ê°œ (3Ã—8)
  ì²˜ë¦¬ ì†ë„: ë¶€í•˜ í…ŒìŠ¤íŠ¸ í›„ ì¸¡ì •

GPT-5:
  ë™ì‹œ ì²˜ë¦¬: 100ê°œ (5Ã—20)
  ì‘ë‹µ ì‹œê°„: 3-5ì´ˆ
  ë³‘ëª©: API Rate Limit

RAG:
  ë™ì‹œ ì²˜ë¦¬: 8ê°œ (2Ã—4)
  ì²˜ë¦¬ ì†ë„: <0.5ì´ˆ (ë§¤ìš° ë¹ ë¦„)

GPT-4o mini:
  ë™ì‹œ ì²˜ë¦¬: 30ê°œ (3Ã—10)
  ì‘ë‹µ ì‹œê°„: 1-2ì´ˆ
  ë³‘ëª©: API Rate Limit

ì‹¤ì œ ë³‘ëª©:
  ğŸ”´ GPT-5 API (3-5ì´ˆ)
  ğŸŸ¡ GPT-4o mini API (1-2ì´ˆ)
  âš ï¸ Worker ì¦ì„¤ë³´ë‹¤ API Rate Limit í˜‘ìƒ í•„ìš”
```

---

## ğŸ¨ ì‹œê°í™”

### ë…¸ë“œë³„ ë°°ì¹˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Kubernetes Cluster                         â”‚
â”‚                  (2 Worker Nodes)                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€ Worker-1 (I/O + Compute) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚                                                    â”‚      â”‚
â”‚  â”‚  ğŸ“¦ preprocess-worker (Ã—3)                        â”‚      â”‚
â”‚  â”‚    â”œâ”€ S3 ì—…ë¡œë“œ                                   â”‚      â”‚
â”‚  â”‚    â”œâ”€ ì´ë¯¸ì§€ ì „ì²˜ë¦¬                               â”‚      â”‚
â”‚  â”‚    â”œâ”€ Pool: processes                             â”‚      â”‚
â”‚  â”‚    â””â”€ CPU: 900m, RAM: 768Mi                       â”‚      â”‚
â”‚  â”‚                                                    â”‚      â”‚
â”‚  â”‚  ğŸ“¦ rag-worker (Ã—2)                               â”‚      â”‚
â”‚  â”‚    â”œâ”€ JSON ì¡°íšŒ                                   â”‚      â”‚
â”‚  â”‚    â”œâ”€ ì»¨í…ìŠ¤íŠ¸ ê²°í•©                               â”‚      â”‚
â”‚  â”‚    â”œâ”€ Pool: processes                             â”‚      â”‚
â”‚  â”‚    â””â”€ CPU: 400m, RAM: 512Mi                       â”‚      â”‚
â”‚  â”‚                                                    â”‚      â”‚
â”‚  â”‚  â° celery-beat (Ã—1)                              â”‚      â”‚
â”‚  â”‚    â”œâ”€ ìŠ¤ì¼€ì¤„ëŸ¬                                     â”‚      â”‚
â”‚  â”‚    â””â”€ CPU: 50m, RAM: 128Mi                        â”‚      â”‚
â”‚  â”‚                                                    â”‚      â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚      â”‚
â”‚  â”‚  ì´: CPU 1350m (67.5%), RAM 1408Mi (34%)         â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€ Worker-2 (Network - API) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚                                                    â”‚      â”‚
â”‚  â”‚  ğŸ¤– gpt5-worker (Ã—5)                              â”‚      â”‚
â”‚  â”‚    â”œâ”€ GPT-5 ë©€í‹°ëª¨ë‹¬ ë¶„ì„                         â”‚      â”‚
â”‚  â”‚    â”œâ”€ ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ ë™ì‹œ ì…ë ¥                   â”‚      â”‚
â”‚  â”‚    â”œâ”€ Pool: gevent                                â”‚      â”‚
â”‚  â”‚    â”œâ”€ Concurrency: 20                             â”‚      â”‚
â”‚  â”‚    â””â”€ CPU: 500m, RAM: 1280Mi                      â”‚      â”‚
â”‚  â”‚                                                    â”‚      â”‚
â”‚  â”‚  ğŸ¤– gpt4o-worker (Ã—3)                             â”‚      â”‚
â”‚  â”‚    â”œâ”€ GPT-4o mini ì‘ë‹µ ìƒì„±                       â”‚      â”‚
â”‚  â”‚    â”œâ”€ 3ê°€ì§€ ì…ë ¥ ê²°í•©                             â”‚      â”‚
â”‚  â”‚    â”œâ”€ Pool: gevent                                â”‚      â”‚
â”‚  â”‚    â”œâ”€ Concurrency: 10                             â”‚      â”‚
â”‚  â”‚    â””â”€ CPU: 300m, RAM: 768Mi                       â”‚      â”‚
â”‚  â”‚                                                    â”‚      â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚      â”‚
â”‚  â”‚  ì´: CPU 800m (40%), RAM 2048Mi (50%)            â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ì›Œí¬í”Œë¡œìš°

```mermaid
graph LR
    User["`**ì‚¬ìš©ì**
    ì‚¬ì§„ + ì§ˆë¬¸`"] --> API["`**FastAPI**
    Query ìƒì„±`"]
    
    API --> Q1["`**q.preprocess**
    Worker-1`"]
    Q1 --> W1["`**Preprocess**
    S3 ì—…ë¡œë“œ
    í•´ì‹œ ê³„ì‚°`"]
    
    W1 --> Q2["`**q.gpt5**
    Worker-2`"]
    Q2 --> W2["`**GPT-5**
    ë©€í‹°ëª¨ë‹¬ ë¶„ì„
    í’ˆëª© ë¶„ë¥˜`"]
    
    W2 --> Q3["`**q.rag**
    Worker-1`"]
    Q3 --> W3["`**RAG**
    JSON ì¡°íšŒ
    ì»¨í…ìŠ¤íŠ¸ ê²°í•©`"]
    
    W3 --> Q4["`**q.gpt4o**
    Worker-2`"]
    Q4 --> W4["`**GPT-4o mini**
    ì‘ë‹µ ìƒì„±`"]
    
    W4 --> Result["`**Result**
    ë¶„ë¦¬ë°°ì¶œ ì•ˆë‚´`"]
    
    style User fill:#FFE066,stroke:#F59F00,stroke-width:2px,color:#000
    style API fill:#7B68EE,stroke:#4B3C8C,stroke-width:3px,color:#fff
    style Q1 fill:#E6F7FF,stroke:#B3E0FF,stroke-width:2px,color:#000
    style Q2 fill:#FFE4E1,stroke:#FFC0CB,stroke-width:2px,color:#000
    style Q3 fill:#FFF9E6,stroke:#FFE4B3,stroke-width:2px,color:#000
    style Q4 fill:#E6F7FF,stroke:#B3E0FF,stroke-width:2px,color:#000
    style W1 fill:#4A90E2,stroke:#2E5C8A,stroke-width:2px,color:#fff
    style W2 fill:#E74C3C,stroke:#C0392B,stroke-width:3px,color:#fff
    style W3 fill:#2ECC71,stroke:#27AE60,stroke-width:2px,color:#fff
    style W4 fill:#F39C12,stroke:#C87F0A,stroke-width:2px,color:#000
    style Result fill:#51CF66,stroke:#2F9E44,stroke-width:3px,color:#fff
```

---

## ğŸ” ë³´ì•ˆ ë° ê²©ë¦¬

### NetworkPolicy

```yaml
# Worker-1 â†’ Worker-2 ì°¨ë‹¨ (ë¶ˆí•„ìš”)
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: worker-isolation
  namespace: workers
spec:
  podSelector:
    matchLabels:
      tier: compute
  policyTypes:
  - Ingress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          tier: compute
    ports:
    - protocol: TCP
      port: 5672  # RabbitMQ
```

---

## âœ… ìµœì¢… ê²°ë¡ 

### ë°°ì¹˜ ìš”ì•½

```yaml
Worker-1 (I/O + Compute):
  âœ… preprocess-worker (Ã—3): S3 ì—…ë¡œë“œ
  âœ… rag-worker (Ã—2): JSON ì¡°íšŒ
  âœ… celery-beat (Ã—1): ìŠ¤ì¼€ì¤„ëŸ¬
  âœ… CPU: 67.5%, RAM: 34%

Worker-2 (Network - API):
  âœ… gpt5-worker (Ã—5): GPT-5 ë©€í‹°ëª¨ë‹¬
  âœ… gpt4o-worker (Ã—3): GPT-4o mini
  âœ… CPU: 40%, RAM: 50%

ì „ì²´:
  âœ… ì´ 14 Pods
  âœ… CPU ì‚¬ìš©: 53.75% (requests)
  âœ… RAM ì‚¬ìš©: 42% (requests)
  âœ… ì•ˆì •ì , í™•ì¥ ê°€ëŠ¥
```

### ì¥ì 

```yaml
1. ëª…í™•í•œ ë¶„ë¦¬:
   âœ… Worker-1: processes (I/O + CPU)
   âœ… Worker-2: gevent (Network)

2. ë¦¬ì†ŒìŠ¤ ê· í˜•:
   âœ… ë‘ ë…¸ë“œ ëª¨ë‘ ì•ˆì •ì  ì‚¬ìš©ë¥ 
   âœ… ì¶©ë¶„í•œ ì—¬ìœ  ë¦¬ì†ŒìŠ¤

3. í™•ì¥ì„±:
   âœ… GPT-5 ë³‘ëª© ì‹œ Worker-2 ì¦ì„¤
   âœ… Preprocess ë³‘ëª© ì‹œ Worker-1 ì¦ì„¤

4. ë¹„ìš© íš¨ìœ¨:
   âœ… ìµœì†Œ ë…¸ë“œ (2ê°œ)
   âœ… ê³ ì • replica (HPA ë¶ˆí•„ìš”)
```

---

**ê²°ë¡ **: Worker-1(preprocess+rag+beat), Worker-2(gpt5+gpt4o)ë¡œ ìµœì  ë°°ì¹˜ ì™„ë£Œ! âœ…


# 13-Node í´ëŸ¬ìŠ¤í„° ìë™ ì¬êµ¬ì¶• ê°€ì´ë“œ

## ğŸ“Š ê°œìš”

`auto-rebuild.sh`ëŠ” 13-Node Kubernetes í´ëŸ¬ìŠ¤í„°ë¥¼ ì™„ì „íˆ ìë™ìœ¼ë¡œ ì¬êµ¬ì¶•í•˜ê³ , v0.6.0 ê¸°ëŠ¥(ëª¨ë‹ˆí„°ë§ + WAL Workers)ê¹Œì§€ ë°°í¬í•˜ëŠ” í†µí•© ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.

## ğŸ¯ ì‹¤í–‰ ìˆœì„œ

### ì „ì²´ í”„ë¡œì„¸ìŠ¤ (ìë™)

1. **Terraform Destroy** - ê¸°ì¡´ ì¸í”„ë¼ ì‚­ì œ
2. **Terraform Apply** - 13-Node ì¸í”„ë¼ êµ¬ì¶•
3. **Ansible Playbook** - Kubernetes ì„¤ì¹˜
4. **Monitoring Stack** - Prometheus/Grafana ë°°í¬ (ì›ê²©)
5. **Worker Images** - ì´ë¯¸ì§€ ë¹Œë“œ & GHCR í‘¸ì‹œ (ë¡œì»¬)
6. **Worker Deployment** - WAL Workers ë°°í¬ (ì›ê²©)

### ì˜ˆìƒ ì†Œìš” ì‹œê°„
- **ì „ì²´**: 50-70ë¶„
  - Terraform destroy: 5-10ë¶„
  - Terraform apply: 10-15ë¶„
  - Ansible playbook: 15-20ë¶„
  - Monitoring ë°°í¬: 5ë¶„
  - Worker ë¹Œë“œ: 10ë¶„
  - Worker ë°°í¬: 5ë¶„

## ğŸš€ ì‚¬ìš© ë°©ë²•

### 1. ì‚¬ì „ ì¤€ë¹„

```bash
# í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
export GITHUB_TOKEN=<your-github-token>
export GITHUB_USERNAME=<your-github-username>
export VERSION=v0.6.0  # ì„ íƒì‚¬í•­ (ê¸°ë³¸ê°’: v0.6.0)

# AWS ìê²©ì¦ëª… í™•ì¸
aws sts get-caller-identity

# Terraform ë³€ìˆ˜ í™•ì¸
cd terraform
cat terraform.tfvars
```

**í•„ìˆ˜ Terraform ë³€ìˆ˜**:
- `cluster_name`
- `environment`
- `domain_name`
- `key_name` (SSH í‚¤)
- `aws_region`

### 2. ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰

```bash
cd /Users/mango/workspace/SeSACTHON/backend
./scripts/cluster/auto-rebuild.sh
```

### 3. ì‹¤í–‰ ëª¨ë“œ

**ìë™ ëª¨ë“œ** (ê¸°ë³¸):
- ëª¨ë“  ë‹¨ê³„ë¥¼ í™•ì¸ ì—†ì´ ìë™ ì‹¤í–‰
- ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ ê°€ëŠ¥í•œ í•œ ê³„ì† ì§„í–‰
- `AUTO_MODE=true` í™˜ê²½ ë³€ìˆ˜ ì„¤ì •ë¨

**GitHub ì¸ì¦ ì—†ì´ ì‹¤í–‰**:
```bash
# Worker ë¹Œë“œë¥¼ ê±´ë„ˆë›°ê³  ì‹¤í–‰
unset GITHUB_TOKEN
unset GITHUB_USERNAME
./scripts/cluster/auto-rebuild.sh
```

## ğŸ“¦ ë°°í¬ë˜ëŠ” êµ¬ì„±

### 13-Node í´ëŸ¬ìŠ¤í„°

| ë…¸ë“œ ìœ í˜• | ê°œìˆ˜ | ì¸ìŠ¤í„´ìŠ¤ íƒ€ì… | ì—­í•  |
|----------|------|--------------|------|
| Master | 1 | t3a.large | Kubernetes Control Plane |
| API | 6 | t3a.medium | API Services (6ê°œ) |
| Worker | 2 | t3a.large | Celery Workers (2ê°œ) |
| Infrastructure | 4 | t3a.medium | RabbitMQ, PostgreSQL, Redis, Prometheus |

### ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ

- **Prometheus**
  - ServiceMonitor (API 6ê°œ + Worker 2ê°œ)
  - Alert Rules (20ê°œ)
  - 30ì¼ ë©”íŠ¸ë¦­ ë³´ê´€ (50GB PVC)

- **Grafana**
  - 13-Node ì „ìš© ëŒ€ì‹œë³´ë“œ (12ê°œ Panel)
  - ê´€ë¦¬ì ì¸ì¦ (Secret)

- **Node Exporter**
  - DaemonSet (13ê°œ ë…¸ë“œ ëª¨ë‹ˆí„°ë§)

### Worker Services

- **Storage Worker**
  - S3 ì—…ë¡œë“œ ì‘ì—…
  - Local SQLite WAL
  - PostgreSQL ë¹„ë™ê¸° ë™ê¸°í™”
  - 10GB PVC

- **AI Worker**
  - AI ì¶”ë¡  ì‘ì—… (ì¤€ë¹„)
  - Local SQLite WAL
  - 10GB PVC

## ğŸ” ë‹¨ê³„ë³„ ìƒì„¸

### Step 1: Terraform Destroy

```bash
# ê¸°ì¡´ ë¦¬ì†ŒìŠ¤ í™•ì¸
terraform state list

# ìë™ ì‚­ì œ
terraform destroy -auto-approve

# ëŒ€ê¸° ì‹œê°„: 30ì´ˆ (AWS ë¦¬ì†ŒìŠ¤ ì™„ì „ ì‚­ì œ)
```

**ì²˜ë¦¬ ë°©ì‹**:
- ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
- ë¦¬ì†ŒìŠ¤ ê°œìˆ˜ í™•ì¸
- ìƒíƒœ ì¶œë ¥

### Step 2: Terraform Apply (13-Node)

```bash
# 13-Node ì¸í”„ë¼ êµ¬ì¶•
terraform apply -auto-approve

# ìƒì„±ë˜ëŠ” ë¦¬ì†ŒìŠ¤:
# - 13 EC2 Instances
# - VPC, Subnets, Security Groups
# - S3 Bucket (images)
# - CloudFront Distribution
# - Route53 Records
# - ACM Certificates

# ëŒ€ê¸° ì‹œê°„: 90ì´ˆ (SSM Agent ë“±ë¡)
```

### Step 3: Ansible Playbook

```bash
# Inventory ìë™ ìƒì„±
terraform output -raw ansible_inventory > ansible/inventory/hosts.ini

# Kubernetes ì„¤ì¹˜ (13 nodes)
ansible-playbook -i inventory/hosts.ini site.yml \
    -e "vpc_id=$VPC_ID" \
    -e "acm_certificate_arn=$ACM_ARN"

# ì„¤ì¹˜ë˜ëŠ” ì»´í¬ë„ŒíŠ¸:
# - Docker
# - Kubernetes (kubeadm)
# - Calico CNI
# - AWS EBS CSI Driver
# - AWS ALB Ingress Controller
# - Cert-Manager

# ëŒ€ê¸° ì‹œê°„: 60ì´ˆ (í´ëŸ¬ìŠ¤í„° ì´ˆê¸°í™”)
```

### Step 4: Monitoring Stack ë°°í¬ (ì›ê²©)

```bash
# Master ë…¸ë“œë¡œ íŒŒì¼ ë³µì‚¬
scp -r k8s/monitoring ubuntu@$MASTER_IP:~/
scp scripts/deploy-monitoring.sh ubuntu@$MASTER_IP:~/

# ì›ê²© ì‹¤í–‰ (SSH)
ssh ubuntu@$MASTER_IP
  kubectl apply -f ~/monitoring/node-exporter.yaml
  kubectl create configmap prometheus-rules --from-file=...
  kubectl apply -f ~/monitoring/prometheus-deployment.yaml
  kubectl create configmap grafana-dashboards --from-file=...
  kubectl apply -f ~/monitoring/grafana-deployment.yaml
```

### Step 5: Worker ì´ë¯¸ì§€ ë¹Œë“œ (ë¡œì»¬)

```bash
# GHCR ë¡œê·¸ì¸
echo $GITHUB_TOKEN | docker login ghcr.io -u $GITHUB_USERNAME --password-stdin

# ì´ë¯¸ì§€ ë¹Œë“œ ë° í‘¸ì‹œ
export VERSION=v0.6.0
./scripts/build-workers.sh

# ë¹Œë“œë˜ëŠ” ì´ë¯¸ì§€:
# - ghcr.io/$GITHUB_USERNAME/ecoeco-storage-worker:v0.6.0
# - ghcr.io/$GITHUB_USERNAME/ecoeco-ai-worker:v0.6.0
```

**ê±´ë„ˆë›°ëŠ” ê²½ìš°**:
- `GITHUB_TOKEN` ë˜ëŠ” `GITHUB_USERNAME`ì´ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ê±´ë„ˆëœ€
- ìˆ˜ë™ìœ¼ë¡œ ë‚˜ì¤‘ì— ì‹¤í–‰ ê°€ëŠ¥

### Step 6: Worker ë°°í¬ (ì›ê²©)

```bash
# Master ë…¸ë“œë¡œ íŒŒì¼ ë³µì‚¬
scp -r k8s/workers ubuntu@$MASTER_IP:~/

# ì›ê²© ì‹¤í–‰ (SSH)
ssh ubuntu@$MASTER_IP
  kubectl apply -f ~/workers/worker-wal-deployments.yaml
  kubectl get pods -l component=worker
  kubectl get pvc -l component=wal
```

## ğŸ“Š ë°°í¬ í™•ì¸

### í´ëŸ¬ìŠ¤í„° ì ‘ì†

```bash
# Master ë…¸ë“œ ì ‘ì†
ssh ubuntu@$(cd terraform && terraform output -raw master_public_ip)

# ë…¸ë“œ í™•ì¸ (13ê°œ)
kubectl get nodes -o wide

# Pod í™•ì¸
kubectl get pods -A
```

### ëª¨ë‹ˆí„°ë§ í™•ì¸

```bash
# Prometheus ì ‘ì†
kubectl port-forward svc/prometheus 9090:9090
# http://localhost:9090

# Grafana ì ‘ì†
kubectl port-forward svc/grafana 3000:3000
# http://localhost:3000

# Grafana ë¹„ë°€ë²ˆí˜¸ í™•ì¸
kubectl get secret grafana-admin -o jsonpath='{.data.password}' | base64 -d
```

### Worker í™•ì¸

```bash
# Worker Pod ìƒíƒœ
kubectl get pods -l component=worker

# WAL PVC í™•ì¸
kubectl get pvc -l component=wal

# Worker ë¡œê·¸
kubectl logs -l app.kubernetes.io/name=storage-worker --tail=100
kubectl logs -l app.kubernetes.io/name=ai-worker --tail=100
```

## ğŸ› íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 1. Terraform Destroy ì‹¤íŒ¨

**ì¦ìƒ**: VPC ì‚­ì œ ì‹œ ì¥ì‹œê°„ ëŒ€ê¸°

**ì›ì¸**: ENI, Security Group ë“±ì´ ë‚¨ì•„ìˆìŒ

**í•´ê²°**:
```bash
# VPC ID í™•ì¸
cd terraform
VPC_ID=$(terraform output -raw vpc_id)

# ë‚¨ì€ ë¦¬ì†ŒìŠ¤ í™•ì¸ ë° ì‚­ì œ
aws ec2 describe-network-interfaces --filters Name=vpc-id,Values=$VPC_ID
aws ec2 describe-security-groups --filters Name=vpc-id,Values=$VPC_ID

# ì¬ì‹œë„
terraform destroy -auto-approve
```

### 2. Ansible Playbook ì‹¤íŒ¨

**ì¦ìƒ**: SSH ì—°ê²° ì‹¤íŒ¨

**ì›ì¸**: SSM Agent ë¯¸ë“±ë¡ ë˜ëŠ” SSH í‚¤ ë¬¸ì œ

**í•´ê²°**:
```bash
# SSH í…ŒìŠ¤íŠ¸
ansible all -i ansible/inventory/hosts.ini -m ping

# ìˆ˜ë™ SSH ì ‘ì†
ssh -i ~/.ssh/your-key.pem ubuntu@<master-ip>

# SSM Session Manager ì‚¬ìš©
aws ssm start-session --target <instance-id>
```

### 3. Monitoring ë°°í¬ ì‹¤íŒ¨

**ì¦ìƒ**: Podê°€ Pending ìƒíƒœ

**ì›ì¸**: PVC ë°”ì¸ë”© ì‹¤íŒ¨ ë˜ëŠ” ë¦¬ì†ŒìŠ¤ ë¶€ì¡±

**í•´ê²°**:
```bash
# PVC ìƒíƒœ í™•ì¸
kubectl get pvc

# StorageClass í™•ì¸
kubectl get storageclass

# Pod ìƒì„¸ ì •ë³´
kubectl describe pod <pod-name>

# EBS CSI Driver í™•ì¸
kubectl get pods -n kube-system -l app.kubernetes.io/name=aws-ebs-csi-driver
```

### 4. Worker ì´ë¯¸ì§€ ë¹Œë“œ ì‹¤íŒ¨

**ì¦ìƒ**: Docker ë¹Œë“œ ì—ëŸ¬

**ì›ì¸**: Dockerfile ë¬¸ì œ ë˜ëŠ” ì˜ì¡´ì„± ëˆ„ë½

**í•´ê²°**:
```bash
# ë¡œê·¸ í™•ì¸
docker build -f workers/Dockerfile.storage -t test .

# ê°œë³„ ë¹Œë“œ í…ŒìŠ¤íŠ¸
cd workers
docker build -f Dockerfile.storage -t storage-worker-test .
docker build -f Dockerfile.ai -t ai-worker-test .
```

### 5. Worker Pod ì‹œì‘ ì‹¤íŒ¨

**ì¦ìƒ**: CrashLoopBackOff

**ì›ì¸**: í™˜ê²½ ë³€ìˆ˜ ëˆ„ë½ ë˜ëŠ” WAL ë””ë ‰í† ë¦¬ ê¶Œí•œ

**í•´ê²°**:
```bash
# Pod ë¡œê·¸ í™•ì¸
kubectl logs <worker-pod-name>

# í™˜ê²½ ë³€ìˆ˜ í™•ì¸
kubectl get pod <worker-pod-name> -o yaml | grep -A 20 env:

# Secret í™•ì¸
kubectl get secret postgresql-secret -o yaml
kubectl get secret aws-credentials -o yaml
```

## ğŸ’¡ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

### ì‹¤í–‰ ì „

1. **ë°±ì—…**
   - Terraform state ë°±ì—…
   - ì¤‘ìš” ë°ì´í„° ë°±ì—… (DB, S3)

2. **ë³€ìˆ˜ í™•ì¸**
   - `terraform.tfvars` ê²€ì¦
   - í™˜ê²½ ë³€ìˆ˜ ì„¤ì • í™•ì¸

3. **ë¦¬ì†ŒìŠ¤ í™•ì¸**
   - AWS í• ë‹¹ëŸ‰ í™•ì¸ (EC2 ì¸ìŠ¤í„´ìŠ¤, Elastic IP)
   - ë„ë©”ì¸ ì„¤ì • í™•ì¸

### ì‹¤í–‰ ì¤‘

1. **ëª¨ë‹ˆí„°ë§**
   - í„°ë¯¸ë„ ì¶œë ¥ ì£¼ì‹œ
   - AWS Consoleì—ì„œ ë¦¬ì†ŒìŠ¤ ìƒì„± í™•ì¸

2. **ì—ëŸ¬ ëŒ€ì‘**
   - ì—ëŸ¬ ë°œìƒ ì‹œ ë¡œê·¸ ì €ì¥
   - ê°€ëŠ¥í•œ ë‹¨ê³„ëŠ” ê³„ì† ì§„í–‰

### ì‹¤í–‰ í›„

1. **ê²€ì¦**
   - 13ê°œ ë…¸ë“œ ëª¨ë‘ Ready ìƒíƒœ
   - ëª¨ë“  Pod Running ìƒíƒœ
   - ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ ì •ìƒ ì‘ë™

2. **ë³´ì•ˆ**
   - Grafana admin ë¹„ë°€ë²ˆí˜¸ ë³€ê²½
   - Security Group ê·œì¹™ ê²€í† 

## ğŸ“ ìˆ˜ë™ ì‹¤í–‰ ì˜µì…˜

### Worker ë¹Œë“œë§Œ ë³„ë„ ì‹¤í–‰

```bash
export GITHUB_TOKEN=<token>
export GITHUB_USERNAME=<username>
export VERSION=v0.6.0
./scripts/build-workers.sh
```

### Worker ë°°í¬ë§Œ ë³„ë„ ì‹¤í–‰

```bash
# Master ë…¸ë“œì—ì„œ
kubectl apply -f k8s/workers/worker-wal-deployments.yaml
```

### ëª¨ë‹ˆí„°ë§ë§Œ ë³„ë„ ì‹¤í–‰

```bash
# Master ë…¸ë“œì—ì„œ
./scripts/deploy-monitoring.sh
```

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„

ë°°í¬ ì™„ë£Œ í›„:

1. **ë„ë©”ì¸ í™•ì¸**
   ```
   https://ecoeco.app
   https://api.ecoeco.app
   ```

2. **ArgoCD ë°°í¬** (GitOps)
   ```bash
   kubectl apply -f argocd/
   ```

3. **ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬** (Helm)
   ```bash
   kubectl apply -f charts/ecoeco-backend/
   ```

## ğŸ”— ê´€ë ¨ ë¬¸ì„œ

- [Terraform 13-Node ì„¤ì •](../../terraform/README.md)
- [Ansible Playbook ê°€ì´ë“œ](../../ansible/README.md)
- [ëª¨ë‹ˆí„°ë§ ì„¤ì • ê°€ì´ë“œ](../../docs/deployment/MONITORING_SETUP.md)
- [WAL êµ¬í˜„ ê°€ì´ë“œ](../../docs/guides/WORKER_WAL_IMPLEMENTATION.md)
- [v0.6.0 ì™„ë£Œ ê°€ì´ë“œ](../../docs/development/V0.6.0_COMPLETION_GUIDE.md)


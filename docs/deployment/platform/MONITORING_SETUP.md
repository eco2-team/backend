# Ecoeco 13-Node Monitoring Stack

## ğŸ“Š ê°œìš”

Ecoecoì˜ 13-Node Microservices Architectureë¥¼ ìœ„í•œ ì™„ì „í•œ ëª¨ë‹ˆí„°ë§ ìŠ¤íƒì…ë‹ˆë‹¤.

### ì•„í‚¤í…ì²˜ êµ¬ì„±

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Grafana Dashboard                        â”‚
â”‚                    (Visualization)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Prometheus                              â”‚
â”‚              (Metrics Collection & Storage)                 â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚        â”‚        â”‚        â”‚        â”‚
    â–¼        â–¼        â–¼        â–¼        â–¼
â”Œâ”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ API â”‚  â”‚Workerâ”‚ â”‚Infra  â”‚ â”‚Nodes â”‚ â”‚RabbitMQ  â”‚
â”‚ 6ê°œ â”‚  â”‚ 2ê°œ  â”‚ â”‚(PG/R) â”‚ â”‚ 13ê°œ â”‚ â”‚PostgreSQLâ”‚
â””â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ êµ¬ì„± ìš”ì†Œ

### 1. Prometheus (ë©”íŠ¸ë¦­ ìˆ˜ì§‘)
- **ì—­í• **: ëª¨ë“  ì„œë¹„ìŠ¤/ë…¸ë“œì—ì„œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ì €ì¥
- **ìŠ¤í† ë¦¬ì§€**: 50GB PVC (30ì¼ ë³´ê´€)
- **ìŠ¤í¬ë© ì£¼ê¸°**: 30ì´ˆ
- **ìœ„ì¹˜**: Infrastructure Node

### 2. Grafana (ì‹œê°í™”)
- **ì—­í• **: ë©”íŠ¸ë¦­ ì‹œê°í™” ë° ëŒ€ì‹œë³´ë“œ
- **ìŠ¤í† ë¦¬ì§€**: 10GB PVC
- **ì¸ì¦**: Secret ê¸°ë°˜ (grafana-admin)
- **ìœ„ì¹˜**: Infrastructure Node

### 3. Node Exporter (ë…¸ë“œ ëª¨ë‹ˆí„°ë§)
- **ì—­í• **: 13ê°œ ë…¸ë“œì˜ ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
- **ë°°í¬ ë°©ì‹**: DaemonSet (ëª¨ë“  ë…¸ë“œ)
- **ë©”íŠ¸ë¦­**: CPU, ë©”ëª¨ë¦¬, ë””ìŠ¤í¬, ë„¤íŠ¸ì›Œí¬

### 4. ServiceMonitor (ì„œë¹„ìŠ¤ ë””ìŠ¤ì»¤ë²„ë¦¬)
- **ì—­í• **: Kubernetes ì„œë¹„ìŠ¤ ìë™ ë°œê²¬
- **ëŒ€ìƒ**: API 6ê°œ + Worker 2ê°œ

## ğŸ¯ ëª¨ë‹ˆí„°ë§ ëŒ€ìƒ

### API Services (6ê°œ)
| Service | Endpoint | Interval | Metrics |
|---------|----------|----------|---------|
| waste-api | `:8000/metrics` | 15s | ìš”ì²­ë¥ , ì‘ë‹µì‹œê°„, ì—ëŸ¬ìœ¨ |
| auth-api | `:8000/metrics` | 30s | ì¸ì¦ ì„±ê³µ/ì‹¤íŒ¨, í† í° ë°œê¸‰ |
| userinfo-api | `:8000/metrics` | 30s | ì‚¬ìš©ì ì¡°íšŒ, DB ì—°ê²° |
| location-api | `:8000/metrics` | 30s | ìœ„ì¹˜ ê²€ìƒ‰, ìºì‹œ íˆíŠ¸ìœ¨ |
| recycle-info-api | `:8000/metrics` | 30s | ì •ë³´ ì¡°íšŒ, ìºì‹œ ì‚¬ìš©ë¥  |
| chat-llm-api | `:8000/metrics` | 15s | LLM í˜¸ì¶œ, ì‘ë‹µì‹œê°„ |

### Worker Services (2ê°œ)
| Service | Endpoint | Interval | Metrics |
|---------|----------|----------|---------|
| storage-worker | `:9090/metrics` | 30s | S3 ì—…ë¡œë“œ, ì‘ì—… ì²˜ë¦¬ìœ¨ |
| ai-worker | `:9090/metrics` | 30s | AI ì¶”ë¡ , GPU ì‚¬ìš©ë¥  |

### Infrastructure Services (4ê°œ)
| Service | Endpoint | Metrics |
|---------|----------|---------|
| RabbitMQ | `:15692/metrics` | Queue í¬ê¸°, ë©”ì‹œì§€ ì²˜ë¦¬ìœ¨ |
| PostgreSQL | `:9187/metrics` | ì—°ê²° ìˆ˜, ì¿¼ë¦¬ ì„±ëŠ¥ |
| Redis | `:9121/metrics` | ë©”ëª¨ë¦¬ ì‚¬ìš©, ìºì‹œ íˆíŠ¸ìœ¨ |
| Prometheus | `:9090/metrics` | ìì²´ ë©”íŠ¸ë¦­ |

### Nodes (13ê°œ)
- **Master Node (1)**: t3a.large
- **API Nodes (6)**: t3a.medium
- **Worker Nodes (2)**: t3a.large
- **Infrastructure Nodes (4)**: t3a.medium

**Node Exporter ë©”íŠ¸ë¦­**:
- CPU ì‚¬ìš©ë¥  (idle, user, system)
- ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  (total, available, used)
- ë””ìŠ¤í¬ ì‚¬ìš©ë¥  (filesystem)
- ë„¤íŠ¸ì›Œí¬ I/O

## ğŸš¨ Alert Rules

### API ì•Œë¦¼
| Alert | Condition | Duration | Severity |
|-------|-----------|----------|----------|
| HighAPILatency | p95 > 1s | 5ë¶„ | warning |
| HighAPIErrorRate | ì—ëŸ¬ìœ¨ > 5% | 5ë¶„ | critical |
| APIPodDown | Pod ì •ì§€ | 2ë¶„ | critical |
| HighAPICPUUsage | CPU > 80% | 10ë¶„ | warning |
| HighAPIMemoryUsage | ë©”ëª¨ë¦¬ > 90% | 10ë¶„ | warning |

### Worker ì•Œë¦¼
| Alert | Condition | Duration | Severity |
|-------|-----------|----------|----------|
| HighWorkerTaskFailureRate | ì‹¤íŒ¨ìœ¨ > 10% | 5ë¶„ | critical |
| WorkerQueueSizeHigh | Queue > 1000 | 10ë¶„ | warning |
| WorkerPodDown | Pod ì •ì§€ | 2ë¶„ | critical |
| HighWorkerTaskDuration | p95 > 60s | 10ë¶„ | warning |

### Infrastructure ì•Œë¦¼
| Alert | Condition | Duration | Severity |
|-------|-----------|----------|----------|
| RabbitMQDown | Pod ì •ì§€ | 2ë¶„ | critical |
| PostgreSQLDown | Pod ì •ì§€ | 2ë¶„ | critical |
| RedisDown | Pod ì •ì§€ | 2ë¶„ | critical |
| HighPostgreSQLConnectionPoolUsage | ì—°ê²° > 80% | 10ë¶„ | warning |
| HighRedisMemoryUsage | ë©”ëª¨ë¦¬ > 90% | 10ë¶„ | warning |

### Node ì•Œë¦¼
| Alert | Condition | Duration | Severity |
|-------|-----------|----------|----------|
| HighNodeCPUUsage | CPU > 85% | 10ë¶„ | warning |
| HighNodeMemoryUsage | ë©”ëª¨ë¦¬ > 90% | 10ë¶„ | warning |
| HighNodeDiskUsage | ë””ìŠ¤í¬ > 85% | 10ë¶„ | warning |
| NodeDown | Node ì •ì§€ | 5ë¶„ | critical |

## ğŸ“ˆ Grafana Dashboard

### Ecoeco 13-Node Microservices Dashboard

**íŒ¨ë„ êµ¬ì„±**:

1. **API Services - Request Rate** (Graph)
   - 6ê°œ API ì„œë¹„ìŠ¤ë³„ ìš”ì²­ë¥  (req/s)

2. **API Services - Error Rate** (Graph)
   - 6ê°œ API ì„œë¹„ìŠ¤ë³„ ì—ëŸ¬ìœ¨ (%)

3. **API Services - Response Time (p95)** (Graph)
   - 6ê°œ API ì„œë¹„ìŠ¤ë³„ 95th percentile ì‘ë‹µì‹œê°„

4. **Worker Services - Task Processing Rate** (Graph)
   - 2ê°œ Worker ì„œë¹„ìŠ¤ë³„ ì‘ì—… ì²˜ë¦¬ìœ¨ (task/s)

5. **Worker Services - Task Failure Rate** (Graph)
   - 2ê°œ Worker ì„œë¹„ìŠ¤ë³„ ì‘ì—… ì‹¤íŒ¨ìœ¨ (%)

6. **RabbitMQ - Queue Size** (Graph)
   - íë³„ ëŒ€ê¸° ë©”ì‹œì§€ ìˆ˜

7. **Node CPU Usage (13 Nodes)** (Graph)
   - 13ê°œ ë…¸ë“œë³„ CPU ì‚¬ìš©ë¥  (%)

8. **Node Memory Usage (13 Nodes)** (Graph)
   - 13ê°œ ë…¸ë“œë³„ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  (%)

9. **Pod Status by Node** (Table)
   - ë…¸ë“œë³„ Pod ë°°ì¹˜ í˜„í™©

10. **API Services - Active Pods** (Stat)
    - í™œì„± API Pod ìˆ˜

11. **Worker Services - Active Pods** (Stat)
    - í™œì„± Worker Pod ìˆ˜

12. **Infrastructure - Active Services** (Stat)
    - í™œì„± ì¸í”„ë¼ ì„œë¹„ìŠ¤ ìˆ˜

## ğŸš€ ë°°í¬

### 1. ìë™ ë°°í¬ (ê¶Œì¥)

```bash
# ì „ì²´ ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ ë°°í¬
./scripts/deploy-monitoring.sh
```

### 2. ìˆ˜ë™ ë°°í¬

```bash
# 1. Node Exporter ë°°í¬ (13 Nodes)
kubectl apply -f k8s/monitoring/node-exporter.yaml

# 2. Prometheus ë°°í¬
kubectl create configmap prometheus-rules \
  --from-file=k8s/monitoring/prometheus-rules.yaml \
  --namespace=default

kubectl apply -f k8s/monitoring/prometheus-deployment.yaml

# 3. Grafana ë°°í¬
kubectl create configmap grafana-dashboards \
  --from-file=k8s/monitoring/grafana-dashboard-13nodes.json \
  --namespace=default

kubectl apply -f k8s/monitoring/grafana-deployment.yaml

# 4. ServiceMonitors ë°°í¬ (Prometheus Operator ì‚¬ìš© ì‹œ)
kubectl apply -f k8s/monitoring/servicemonitors.yaml
```

### 3. ë°°í¬ í™•ì¸

```bash
# Pod ìƒíƒœ í™•ì¸
kubectl get pods -l component=monitoring

# Service í™•ì¸
kubectl get svc prometheus grafana

# DaemonSet í™•ì¸ (13ê°œ ë…¸ë“œì— ëª¨ë‘ ë°°í¬ë˜ì—ˆëŠ”ì§€)
kubectl get daemonset node-exporter
```

## ğŸ” ì ‘ì†

### Prometheus

```bash
# Port Forward
kubectl port-forward svc/prometheus 9090:9090

# ë¸Œë¼ìš°ì €
http://localhost:9090
```

**ì£¼ìš” ì¿¼ë¦¬**:
- API ìš”ì²­ë¥ : `sum(rate(http_requests_total{job=~".*-api"}[5m])) by (service)`
- Worker ì‘ì—… ì²˜ë¦¬ìœ¨: `sum(rate(celery_task_total[5m])) by (worker)`
- Node CPU ì‚¬ìš©ë¥ : `(1 - avg by (instance) (rate(node_cpu_seconds_total{mode="idle"}[5m]))) * 100`

### Grafana

```bash
# Port Forward
kubectl port-forward svc/grafana 3000:3000

# ë¸Œë¼ìš°ì €
http://localhost:3000

# ë¹„ë°€ë²ˆí˜¸ í™•ì¸
kubectl get secret grafana-admin -o jsonpath='{.data.password}' | base64 -d
```

**ê¸°ë³¸ ì¸ì¦ ì •ë³´**:
- Username: `admin`
- Password: `changeme123!` (ë³€ê²½ ê¶Œì¥)

## ğŸ¨ ëŒ€ì‹œë³´ë“œ ì‚¬ìš©

1. Grafana ë¡œê·¸ì¸ í›„ `Ecoeco` í´ë” ì´ë™
2. `Ecoeco 13-Node Microservices` ëŒ€ì‹œë³´ë“œ ì„ íƒ
3. ì‹œê°„ ë²”ìœ„ ì„ íƒ (ê¸°ë³¸: ìµœê·¼ 6ì‹œê°„)
4. ì„œë¹„ìŠ¤ë³„ ë©”íŠ¸ë¦­ í™•ì¸

**í•„í„°ë§**:
- íŠ¹ì • ì„œë¹„ìŠ¤ë§Œ ë³´ê¸°: ë ˆì „ë“œ í´ë¦­
- ì‹œê°„ ë²”ìœ„ ë³€ê²½: ìš°ì¸¡ ìƒë‹¨ ì‹œê°„ ì„ íƒ
- ìë™ ìƒˆë¡œê³ ì¹¨: 30ì´ˆ ê°„ê²©

## ğŸ”§ ì»¤ìŠ¤í„°ë§ˆì´ì§•

### ìƒˆë¡œìš´ ë©”íŠ¸ë¦­ ì¶”ê°€

1. **FastAPI ì•±ì— ë©”íŠ¸ë¦­ ì¶”ê°€**:

```python
from prometheus_client import Counter, Histogram

# ì¹´ìš´í„° ì •ì˜
request_count = Counter('http_requests_total', 'Total HTTP requests', ['method', 'endpoint', 'status'])

# íˆìŠ¤í† ê·¸ë¨ ì •ì˜
request_duration = Histogram('http_request_duration_seconds', 'HTTP request duration', ['method', 'endpoint'])
```

2. **Prometheus Scrape ì„¤ì • ì—…ë°ì´íŠ¸**:

`prometheus-deployment.yaml`ì˜ ConfigMapì— ìƒˆ íƒ€ê²Ÿ ì¶”ê°€

3. **Grafana ëŒ€ì‹œë³´ë“œ ì—…ë°ì´íŠ¸**:

`grafana-dashboard-13nodes.json`ì— ìƒˆ íŒ¨ë„ ì¶”ê°€

### Alert Rule ì¶”ê°€

1. `k8s/monitoring/prometheus-rules.yaml` ìˆ˜ì •
2. ConfigMap ì—…ë°ì´íŠ¸:

```bash
kubectl create configmap prometheus-rules \
  --from-file=k8s/monitoring/prometheus-rules.yaml \
  --namespace=default \
  --dry-run=client -o yaml | kubectl apply -f -
```

3. Prometheus Reload:

```bash
kubectl rollout restart deployment prometheus
```

## ğŸ“Š ë©”íŠ¸ë¦­ ë³´ê´€

- **Prometheus**: 30ì¼ (50GB PVC)
- **Grafana**: ë¬´ì œí•œ (ëŒ€ì‹œë³´ë“œ ì„¤ì •)

**ì¥ê¸° ë³´ê´€ì´ í•„ìš”í•œ ê²½ìš°**:
- Thanos / Cortex ì‚¬ìš© ê³ ë ¤
- S3 ë°±ì—”ë“œ ìŠ¤í† ë¦¬ì§€ ì—°ê²°

## ğŸ› íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### Prometheusê°€ ë©”íŠ¸ë¦­ì„ ìˆ˜ì§‘í•˜ì§€ ëª»í•¨

```bash
# íƒ€ê²Ÿ ìƒíƒœ í™•ì¸
kubectl port-forward svc/prometheus 9090:9090
# http://localhost:9090/targets í™•ì¸

# Pod ë¡œê·¸ í™•ì¸
kubectl logs -l app=prometheus --tail=100
```

### Grafana ëŒ€ì‹œë³´ë“œê°€ ë¹„ì–´ìˆìŒ

1. Datasource í™•ì¸: Configuration > Data Sources
2. Prometheus URL í™•ì¸: `http://prometheus:9090`
3. Test í´ë¦­í•˜ì—¬ ì—°ê²° í™•ì¸

### Node Exporterê°€ ì¼ë¶€ ë…¸ë“œì—ì„œ ë™ì‘í•˜ì§€ ì•ŠìŒ

```bash
# DaemonSet ìƒíƒœ í™•ì¸
kubectl get daemonset node-exporter -o wide

# íŠ¹ì • ë…¸ë“œì˜ Pod ë¡œê·¸ í™•ì¸
kubectl logs -l app=node-exporter -n default --all-containers=true
```

### Alertê°€ ë°œìƒí•˜ì§€ ì•ŠìŒ

```bash
# Alert ê·œì¹™ í™•ì¸
kubectl get configmap prometheus-rules -o yaml

# Prometheusì—ì„œ Alert ìƒíƒœ í™•ì¸
# http://localhost:9090/alerts
```

## ğŸ“š ì°¸ê³  ìë£Œ

- [Prometheus ê³µì‹ ë¬¸ì„œ](https://prometheus.io/docs/)
- [Grafana ê³µì‹ ë¬¸ì„œ](https://grafana.com/docs/)
- [Node Exporter](https://github.com/prometheus/node_exporter)
- [Kubernetes Monitoring Best Practices](https://kubernetes.io/docs/tasks/debug-application-cluster/resource-usage-monitoring/)

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„

- [ ] AlertManager ì—°ë™ (Slack/Email)
- [ ] Thanos ì„¤ì • (ì¥ê¸° ë©”íŠ¸ë¦­ ë³´ê´€)
- [ ] Custom Metrics ì¶”ê°€ (ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§)
- [ ] SLO/SLI ëŒ€ì‹œë³´ë“œ ìƒì„±


# ğŸ• Celery Beat Scheduler ë°°ì¹˜ ë¶„ì„

## ğŸ“Š í˜„ì¬ ìƒí™©

### ë¬¸ì œì 

```yaml
âŒ Celery Beatê°€ ì‹¤ì œë¡œ ë°°í¬ë˜ì§€ ì•ŠìŒ
  - ë¬¸ì„œì—ë§Œ ê¸°ìˆ ë¨ (docs/architecture/task-queue-design.md)
  - Kubernetes Deployment ì—†ìŒ
  - Worker ì½”ë“œ ì—†ìŒ
  
âŒ ë¬¸ì„œ ë¶ˆì¼ì¹˜:
  - final-k8s-architecture.md: "Worker-3ì— Beat ë°°ì¹˜"
  - task-queue-design.md: "analytics namespace"
  - ì‹¤ì œ: ë°°í¬ ì—†ìŒ
```

---

## ğŸ¯ Celery Beatë€?

### ì—­í• 

```yaml
Celery Beat:
  ì—­í• : ì£¼ê¸°ì  ì‘ì—… ìŠ¤ì¼€ì¤„ëŸ¬
  ë¹„ìœ : Linux cronê³¼ ìœ ì‚¬
  
ê¸°ëŠ¥:
  âœ… ì˜ˆì•½ëœ ì‹œê°„ì— Task ë°œí–‰
  âœ… ë°˜ë³µ ì‘ì—… (ë§¤ì‹œê°„, ë§¤ì¼, ë§¤ì£¼)
  âœ… Cron ìŠ¤ì¼€ì¤„ ì§€ì›
  
ì˜ˆì‹œ:
  - ë§¤ì¼ 03:00 â†’ ì˜¤ë˜ëœ ì´ë¯¸ì§€ ì •ë¦¬
  - ë§¤ì‹œê°„ 00ë¶„ â†’ ìºì‹œ ì •ë¦¬
  - ë§¤ì£¼ ì›”ìš”ì¼ â†’ ì£¼ê°„ ë¦¬í¬íŠ¸
```

### ì œì•½ì‚¬í•­

```yaml
âš ï¸ ë°˜ë“œì‹œ 1ê°œë§Œ ì‹¤í–‰!
  ì´ìœ :
    - Beatê°€ 2ê°œ ì´ìƒ â†’ ì¤‘ë³µ Task ë°œí–‰
    - ì¤‘ë³µ ì‹¤í–‰ = ë°ì´í„° ì¤‘ë³µ, ë¹„ìš© ì¦ê°€
    - ì˜ˆ: ì´ë¯¸ì§€ ì •ë¦¬ 2ë²ˆ ì‹¤í–‰ âŒ

í•´ê²°ì±…:
  âœ… Deployment replicas: 1
  âœ… PersistentScheduler ì‚¬ìš© (ì¬ì‹œì‘ ì‹œ ìƒíƒœ ë³µêµ¬)
  âœ… Redis ê¸°ë°˜ ìŠ¤ì¼€ì¤„ ì €ì¥
```

---

## ğŸ—ï¸ ë°°ì¹˜ ì „ëµ

### ì˜µì…˜ 1: Worker-Networkì— ë°°ì¹˜ (ì¶”ì²œ) âœ…

```yaml
ë…¸ë“œ: Worker-Network (t3.medium, 4GB)
ë„¤ì„ìŠ¤í˜ì´ìŠ¤: workers

ì¥ì :
  âœ… ì´ë¯¸ Worker ë…¸ë“œì— ë°°ì¹˜
  âœ… ë¦¬ì†ŒìŠ¤ ì‚¬ìš© ê·¹íˆ ë‚®ìŒ (50m CPU, 128Mi RAM)
  âœ… ì¶”ê°€ ë…¸ë“œ ë¶ˆí•„ìš”
  âœ… RabbitMQ ì ‘ê·¼ ìš©ì´

ë‹¨ì :
  âš ï¸ Worker-Network ì¥ì•  ì‹œ Beatë„ ì¤‘ë‹¨
  âš ï¸ ì—¬ìœ  ë¦¬ì†ŒìŠ¤ ì ìŒ (0.3GB)

ë°°ì¹˜:
  Worker-Network (4GB):
    - vision-worker: 5-8 Pods (HPA)
    - llm-worker: 3 Pods
    - beat: 1 Pod â† ì—¬ê¸°!
```

### ì˜µì…˜ 2: Master ë…¸ë“œì— ë°°ì¹˜

```yaml
ë…¸ë“œ: Master (t3.large, 8GB)
ë„¤ì„ìŠ¤í˜ì´ìŠ¤: workers

ì¥ì :
  âœ… MasterëŠ” ë¦¬ì†ŒìŠ¤ ì—¬ìœ  ìˆìŒ (8GB)
  âœ… ë…ë¦½ì„± (Worker ì¥ì• ì™€ ê²©ë¦¬)
  âœ… BeatëŠ” ì¤‘ìš” ì»´í¬ë„ŒíŠ¸

ë‹¨ì :
  âš ï¸ Masterì— Application Pod ë°°ì¹˜ (ì›ì¹™ ìœ„ë°˜)
  âš ï¸ Master Taint ì œê±° í•„ìš”

ë°°ì¹˜:
  Master (8GB):
    - Control Plane
    - ArgoCD
    - beat: 1 Pod â† ì—¬ê¸°!
```

### ì˜µì…˜ 3: ì „ìš© ë…¸ë“œ ì¶”ê°€

```yaml
ë…¸ë“œ: Scheduler (t3.small, 2GB) â† ì‹ ê·œ
ë„¤ì„ìŠ¤í˜ì´ìŠ¤: workers

ì¥ì :
  âœ… ì™„ì „ ê²©ë¦¬
  âœ… ì•ˆì •ì„± ìµœëŒ€
  âœ… í™•ì¥ ì—¬ì§€ (ë¯¸ë˜ Scheduler ì¶”ê°€)

ë‹¨ì :
  âŒ ì¶”ê°€ ë¹„ìš© (~$15/ì›”)
  âŒ Beatë§Œì„ ìœ„í•œ ë…¸ë“œëŠ” ë¹„íš¨ìœ¨

ë°°ì¹˜:
  Scheduler (2GB):
    - beat: 1 Pod
    - (ì—¬ìœ : 1.5GB ë‚­ë¹„)
```

---

## ğŸ¯ ìµœì¢… ê¶Œì¥: ì˜µì…˜ 1 (Worker-Network)

### ì´ìœ 

```yaml
1. ë¹„ìš© íš¨ìœ¨:
   âœ… ì¶”ê°€ ë…¸ë“œ ë¶ˆí•„ìš”
   âœ… Beat ë¦¬ì†ŒìŠ¤ ê·¹íˆ ë‚®ìŒ

2. ì¶©ë¶„í•œ ê²©ë¦¬:
   âœ… BeatëŠ” Task ë°œí–‰ë§Œ ìˆ˜í–‰
   âœ… ì‹¤ì œ ì‘ì—…ì€ ë‹¤ë¥¸ Workerê°€ ì²˜ë¦¬
   âœ… Beat ì¥ì•  â†’ ìƒˆ Task ë°œí–‰ ì¤‘ë‹¨
   âœ… ê¸°ì¡´ TaskëŠ” ê³„ì† ì²˜ë¦¬ë¨

3. ì‹¤ìš©ì„±:
   âœ… ëŒ€ë¶€ë¶„ì˜ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì‚¬ìš©
   âœ… Instagram, Robinhoodë„ ìœ ì‚¬ êµ¬ì¡°
```

### ë¦¬ì†ŒìŠ¤ ê³„ì‚°

```yaml
Worker-Network (t3.medium, 4GB):

  ê¸°ì¡´:
    - vision-worker (5 Pods): 5 Ã— 256Mi = 1.25GB
    - llm-worker (3 Pods): 3 Ã— 256Mi = 768Mi
    - ì†Œê³„: 2.02GB
  
  ì¶”ê°€:
    - beat (1 Pod): 128Mi
  
  ì´ ì‚¬ìš©: 2.15GB
  ê°€ìš©: 4GB
  ì—¬ìœ : 1.85GB âœ…

ê²°ë¡ : ì¶©ë¶„íˆ ë°°ì¹˜ ê°€ëŠ¥!
```

---

## ğŸ“ êµ¬í˜„ ê³„íš

### 1. Beat Worker ì½”ë“œ ìƒì„±

```python
# workers/beat_worker.py
from celery import Celery
from celery.schedules import crontab

app = Celery("beat")

app.conf.update(
    broker_url="amqp://admin:password@rabbitmq.messaging:5672//",
    result_backend="redis://redis.default:6379/0",
    
    # Beat Schedule
    beat_schedule={
        # ë§¤ì¼ ìƒˆë²½ 3ì‹œ: ì˜¤ë˜ëœ ì´ë¯¸ì§€ ì •ë¦¬
        "cleanup-old-images": {
            "task": "app.tasks.preprocess.cleanup_old_images",
            "schedule": crontab(hour=3, minute=0),
            "args": (30,),  # 30ì¼ ì´ìƒ
            "options": {
                "queue": "q.preprocess",
            },
        },
        
        # ë§¤ì‹œê°„: ìºì‹œ ì •ë¦¬
        "cleanup-cache": {
            "task": "app.tasks.preprocess.cleanup_cache",
            "schedule": crontab(minute=0),  # ë§¤ì‹œê°„
            "options": {
                "queue": "q.preprocess",
            },
        },
        
        # ë§¤ì¼ 02:00: ì¼ì¼ í†µê³„
        "daily-stats": {
            "task": "app.tasks.analytics.daily_stats",
            "schedule": crontab(hour=2, minute=0),
            "options": {
                "queue": "q.rag",  # ê°€ë²¼ìš´ ì‘ì—…
            },
        },
    },
    
    # Persistent Scheduler (ì¬ì‹œì‘ ì‹œ ìƒíƒœ ë³µêµ¬)
    beat_scheduler="celery.beat:PersistentScheduler",
    beat_schedule_filename="/tmp/celerybeat-schedule",
    
    timezone="Asia/Seoul",
)

if __name__ == "__main__":
    app.start()
```

### 2. Kubernetes Deployment

```yaml
# k8s/workers/beat-deployment.yaml
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: celery-beat
  namespace: workers
  labels:
    app: celery-beat
    component: scheduler
spec:
  replicas: 1  # âš ï¸ ë°˜ë“œì‹œ 1ê°œë§Œ!
  strategy:
    type: Recreate  # âš ï¸ RollingUpdate ê¸ˆì§€ (ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€)
  selector:
    matchLabels:
      app: celery-beat
  template:
    metadata:
      labels:
        app: celery-beat
        component: scheduler
    spec:
      nodeSelector:
        workload: compute-network  # Worker-Networkì— ë°°ì¹˜
      
      # Anti-Affinity: ë™ì¼ ë…¸ë“œì— Beat 2ê°œ ë°©ì§€
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app: celery-beat
            topologyKey: kubernetes.io/hostname
      
      containers:
      - name: beat
        image: ghcr.io/your-org/growbin-backend:latest
        command:
        - celery
        - -A
        - workers.beat_worker
        - beat
        - --loglevel=info
        - --scheduler=celery.beat:PersistentScheduler
        
        env:
        - name: CELERY_BROKER_URL
          value: "amqp://admin:password@rabbitmq.messaging:5672//"
        - name: CELERY_RESULT_BACKEND
          value: "redis://redis.default:6379/0"
        
        resources:
          requests:
            cpu: 50m      # ë§¤ìš° ë‚®ìŒ
            memory: 128Mi
          limits:
            cpu: 200m
            memory: 256Mi
        
        # Liveness Probe (Beat ì •ìƒ ë™ì‘ í™•ì¸)
        livenessProbe:
          exec:
            command:
            - celery
            - -A
            - workers.beat_worker
            - inspect
            - ping
          initialDelaySeconds: 30
          periodSeconds: 60
          timeoutSeconds: 10
        
        # Volume Mount (Beat Schedule ì˜êµ¬ ì €ì¥)
        volumeMounts:
        - name: beat-schedule
          mountPath: /tmp
      
      volumes:
      - name: beat-schedule
        emptyDir: {}  # ë˜ëŠ” PersistentVolumeClaim

---
# Service (ë©”íŠ¸ë¦­ ìˆ˜ì§‘ìš©)
apiVersion: v1
kind: Service
metadata:
  name: celery-beat
  namespace: workers
  labels:
    app: celery-beat
spec:
  selector:
    app: celery-beat
  ports:
  - name: metrics
    port: 9090
    targetPort: 9090
  type: ClusterIP
```

### 3. Task êµ¬í˜„

```python
# app/tasks/preprocess.py
from celery import shared_task
from datetime import datetime, timedelta
import boto3

@shared_task(name="app.tasks.preprocess.cleanup_old_images")
def cleanup_old_images(days: int = 30):
    """ì˜¤ë˜ëœ ì´ë¯¸ì§€ ì •ë¦¬ (S3)"""
    s3 = boto3.client("s3")
    bucket = "growbin-waste-images"
    
    cutoff_date = datetime.now() - timedelta(days=days)
    
    deleted = 0
    for obj in s3.list_objects_v2(Bucket=bucket).get("Contents", []):
        if obj["LastModified"] < cutoff_date:
            s3.delete_object(Bucket=bucket, Key=obj["Key"])
            deleted += 1
    
    return f"Deleted {deleted} images older than {days} days"


@shared_task(name="app.tasks.preprocess.cleanup_cache")
def cleanup_cache():
    """Redis ìºì‹œ ì •ë¦¬"""
    import redis
    r = redis.from_url("redis://redis.default:6379/1")
    
    # ì˜¤ë˜ëœ ìºì‹œ í‚¤ ì •ë¦¬
    pattern = "image:hash:*"
    keys = r.keys(pattern)
    
    deleted = 0
    for key in keys:
        ttl = r.ttl(key)
        if ttl == -1:  # TTL ì—†ìŒ
            r.delete(key)
            deleted += 1
    
    return f"Deleted {deleted} expired cache keys"


# app/tasks/analytics.py
@shared_task(name="app.tasks.analytics.daily_stats")
def daily_stats():
    """ì¼ì¼ í†µê³„ ì§‘ê³„"""
    from app.models import WasteAnalysis
    from datetime import date
    
    today = date.today()
    
    # í†µê³„ ì§‘ê³„
    stats = WasteAnalysis.objects.filter(
        created_at__date=today
    ).aggregate(
        total=Count("id"),
        by_category=Count("id", distinct="category"),
    )
    
    # ê²°ê³¼ ì €ì¥ ë˜ëŠ” ì•Œë¦¼
    return f"Daily stats: {stats}"
```

---

## ğŸ“Š ëª¨ë‹ˆí„°ë§

### Prometheus ë©”íŠ¸ë¦­

```yaml
# Celery Beat ë©”íŠ¸ë¦­
celery_beat_tasks_total:
  ì„¤ëª…: Beatê°€ ë°œí–‰í•œ Task ìˆ˜
  ë¼ë²¨: task_name

celery_beat_scheduler_heartbeat:
  ì„¤ëª…: Beat ë§ˆì§€ë§‰ Heartbeat ì‹œê°„
  ì•ŒëŒ: 5ë¶„ ì´ìƒ ì‘ë‹µ ì—†ìœ¼ë©´ Critical

celery_beat_schedule_entries:
  ì„¤ëª…: ë“±ë¡ëœ ìŠ¤ì¼€ì¤„ ìˆ˜
  ì˜ˆìƒ: 3ê°œ (cleanup-images, cleanup-cache, daily-stats)
```

### Grafana Dashboard

```promql
# Beat ì •ìƒ ë™ì‘ í™•ì¸
up{job="celery-beat"} == 1

# ë§ˆì§€ë§‰ Task ë°œí–‰ ì‹œê°„
time() - celery_beat_last_task_time < 3600  # 1ì‹œê°„ ì´ë‚´

# ì˜ˆì•½ ì‘ì—… ì‹¤í–‰ íšŸìˆ˜
sum(rate(celery_beat_tasks_total[1h])) by (task_name)
```

---

## âœ… ìµœì¢… êµ¬ì¡° (8 ë…¸ë“œ + Beat)

```yaml
ì´ ë…¸ë“œ: 8ê°œ
ì¶”ê°€ ë¹„ìš©: $60/ì›”

ë„¤ì„ìŠ¤í˜ì´ìŠ¤:
  api:
    - ëª¨ë“  FastAPI ì„œë¹„ìŠ¤
    - ë…¸ë“œ: API-1, API-2
  
  workers:
    - preprocess-worker (Worker-CPU)
    - rag-worker (Worker-CPU)
    - vision-worker (Worker-Network)
    - llm-worker (Worker-Network)
    - beat â† ì—¬ê¸°! (Worker-Network)
  
  data, messaging, monitoring, argocd: ê¸°ì¡´ ìœ ì§€

Beat ë°°ì¹˜:
  âœ… Worker-Network (4GB)
  âœ… replicas: 1
  âœ… ë¦¬ì†ŒìŠ¤: 50m CPU, 128Mi RAM
  âœ… ì—¬ìœ  ë¦¬ì†ŒìŠ¤: 1.85GB
```

---

**ê²°ë¡ **: Celery Beatë¥¼ Worker-Network ë…¸ë“œì— ë°°ì¹˜í•˜ëŠ” ê²ƒì´ ê°€ì¥ íš¨ìœ¨ì ì…ë‹ˆë‹¤! â°


# Rapid Diagnostics Runbook

> README.mdê°€ ë‚´ë¹„ê²Œì´ì…˜ í—ˆë¸Œë¥¼ ë‹´ë‹¹í•˜ë©°, ì´ ë¬¸ì„œëŠ” **í˜„ì¥ ì¦‰ì‘ì„ ìœ„í•œ ì§„ë‹¨/ë³µêµ¬ ì ˆì°¨**ë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤. ì¦ìƒë³„ ìƒì„¸ ì‚¬ë¡€ëŠ” READMEì—ì„œ ë§í¬ëœ ì „ìš© ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì„¸ìš”.

---

## 1. ìƒíƒœ ì ê²€ ì ˆì°¨

### 1.1 í´ëŸ¬ìŠ¤í„° ìŠ¤ëƒ…ìƒ·
```bash
# ë…¸ë“œ Â· Pod Â· ArgoCD Application
kubectl get nodes -o wide
kubectl get pods -A
kubectl get applications -n argocd
kubectl get applicationset -n argocd

# ë…¸ë“œ ë¼ë²¨/taint í™•ì¸
kubectl get nodes --show-labels | grep sesacthon.io
kubectl describe node <node> | grep -A4 Taints
```

### 1.2 ì¦ìƒë³„ 1ì°¨ ì²´í¬
| ì¦ìƒ | ì¦‰ì‹œ í™•ì¸ | í›„ì† ë¬¸ì„œ |
|------|-----------|-----------|
| ë…¸ë“œ NotReady / CoreDNS Pending | `kubectl describe node <node>` / `kubectl get pods -n kube-system` | `ansible-label-sync.md#3` |
| ArgoCD Unknown / OutOfSync | `kubectl describe application <app>` / `argocd app logs <app>` | `argocd-applicationset-patterns.md`, `gitops-deployment.md` |
| ALB/Service ìƒì„± ì‹¤íŒ¨ | `kubectl logs -n kube-system deploy/aws-load-balancer-controller` | `gitops-deployment.md#10`, `cluster-cases.md` |
| GHCR ImagePullBackOff | `kubectl describe pod <pod>` Events | `gitops-deployment.md#4` |
| IRSA / ExternalSecret ì§€ì—° | `kubectl get externalsecret -A`, ESO logs | `cluster-cases.md`, `ansible-label-sync.md` |

> IRSA Hookê°€ 600ì´ˆ ì´ìƒ ëŒ€ê¸°í•˜ëŠ” ê²½ìš°, Wave 10~11 ì „ì— í•„ìˆ˜ Secretì„ ìˆ˜ë™ìœ¼ë¡œ ì¤€ë¹„í•´ Hook ì‹¤íŒ¨ë¥¼ ë°©ì§€í•˜ì„¸ìš”.
>
> ğŸ” **AWS ìê²©ì¦ëª… Secret ì²´í¬**  
> - IRSA ë¯¸ì‚¬ìš© êµ¬ì„±ì—ì„œëŠ” `aws-global-credentials` Secretì´ `kube-system`ê³¼ `platform-system` ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì— ë°˜ë“œì‹œ ì¡´ì¬í•´ì•¼ í•©ë‹ˆë‹¤.  
> - Secretì´ ì—†ë‹¤ë©´ `docs/deployment/LOCAL_CLUSTER_BOOTSTRAP.md` Step 1.5ì— ë”°ë¼ ì¦‰ì‹œ ìƒì„±í•˜ì„¸ìš”.

---

## 2. ë¶€íŠ¸ìŠ¤íŠ¸ë© ì²´í¬ë¦¬ìŠ¤íŠ¸

```bash
# 1. vCPU í•œë„ í™•ì¸
aws service-quotas get-service-quota \
    --service-code ec2 \
    --quota-code L-1216C47A \
    --region ap-northeast-2

# 2. ì”ì¡´ ë¦¬ì†ŒìŠ¤ ì •ë¦¬
../../scripts/maintenance/destroy-with-cleanup.sh

# 3. ë…¸ë“œ ë¼ë²¨/taint ë™ê¸°í™”
# - docs/infrastructure/k8s-label-annotation-system.md
# - ansible/playbooks/fix-node-labels.yml
# - workloads/domains/*/base/deployment.yaml

# 4. Git ìƒíƒœ
git status
git push origin <branch>

# 5. Ansible ë¶€íŠ¸ìŠ¤íŠ¸ë©
ansible-playbook -i ansible/inventory/hosts.ini ansible/site.yml
```

- **CNI í™•ì¸**: `kubectl wait --for=condition=ready pod -l k8s-app=calico-node -n calico-system --timeout=300s`  
- **IRSA ì„ í–‰ ì¡°ê±´**: `/sesacthon/{env}/iam/*` SSM íŒŒë¼ë¯¸í„° ì¡´ì¬ ì—¬ë¶€ í™•ì¸ â†’ ExternalSecretsê°€ ì½ê¸° ì „ì— ë¬¸ì œ ì—†ë„ë¡ í•¨.

---

## 3. Incident Response Flow

1. **ë¡œê·¸ ìˆ˜ì§‘**
```bash
kubectl get events -A --sort-by='.lastTimestamp'
   kubectl logs -n argocd sts/argocd-application-controller --tail=100
   ```
2. **ì˜í–¥ ë²”ìœ„ íŒŒì•…**
   - OutOfSync/Unknown Application ìˆ˜
   - Pending/CrashLoop Podê°€ ì†í•œ ë„¤ì„ìŠ¤í˜ì´ìŠ¤
   - AWS ALB/TargetGroup ì”ì¡´ ì—¬ë¶€ (`aws elbv2 describe-*`)
3. **ê¸´ê¸‰ ë³µêµ¬**
   - ê° ë¬¸ì„œì˜ â€œê¸´ê¸‰ ë³µêµ¬â€ ì„¹ì…˜ ì‹¤í–‰
   - í•„ìš” ì‹œ `kubectl scale`, `argocd app sync --force`, `kubectl rollout undo`
4. **ê·¼ë³¸ í•´ê²°**
   - Gitì—ì„œ Helm/Kustomize ìˆ˜ì • â†’ PR â†’ `argocd app diff`
   - Terraform/Ansible ë³€ê²½ì€ ì¬ì ìš© ì „ README ì²´í¬ë¦¬ìŠ¤íŠ¸ ì¬í™•ì¸

---

## 4. ëª¨ë‹ˆí„°ë§ ì§€í‘œ & ì—ìŠ¤ì»¬ë ˆì´ì…˜

| ì§€í‘œ | ì •ìƒ | ê²½ë³´ ê¸°ì¤€ | ëŒ€ì‘ |
|------|------|-----------|------|
| Ready Nodes | 14 | < 13 | ë¼ë²¨/taint ì¬ì ìš©, CNI í™•ì¸ |
| ArgoCD OutOfSync | 0 | â‰¥ 3 (10ë¶„ ì´ìƒ) | Webhook/IRSA/ë„¤íŠ¸ì›Œí¬ ì ê²€ |
| ExternalSecret ìƒíƒœ | All Synced | Pending/Failed â‰¥1 | SSM ê¶Œí•œ, IRSA Secret í™•ì¸ |
| AWS TargetGroup ì”ì¡´ | 0 | ì¡´ì¬ ì‹œ destroy ì‹¤íŒ¨ | `scripts/cleanup-vpc-resources.sh` ì‹¤í–‰ |

- **ì§€ì› ì±„ë„**  
- GitHub Issues: https://github.com/SeSACTHON/backend/issues
  - Slack: #backend-support (ë¡œê·¸/ëª…ë ¹ ê²°ê³¼ ì²¨ë¶€)  
  - AWS ë¦¬ì†ŒìŠ¤ ì¥ì• : Terraform ë‹´ë‹¹ìì™€ ì¦‰ì‹œ ê³µìœ 

---

> ğŸ“Œ ì¶”ê°€ ì‚¬ë¡€Â·ì‹¬ì¸µ ë¶„ì„ì€ READMEì˜ â€œë¹ ë¥¸ ì°¸ì¡°â€ ë° ë¬¸ì„œ ì¹´íƒˆë¡œê·¸ì—ì„œ í™•ì¸í•˜ì„¸ìš”. ì´ Runbookì€ â€œë¬´ì—‡ì„ ì–´ë–¤ ìˆœì„œë¡œ ì ê²€/ë³µêµ¬í• ì§€â€ì— ì§‘ì¤‘í•©ë‹ˆë‹¤.

---

## 5. Incident Log â€“ Calico/Tigera ì¬ë°°í¬ ì‹¤íŒ¨ (2025-11-18)

| ì‹œê°(KST) | Action | ê²°ê³¼/ë©”ì‹œì§€ |
|-----------|--------|-------------|
| 19:00~20:30 | `kubectl get application dev-root -n argocd` | í•˜ìœ„ ì•± `dev-external-dns`, `dev-external-secrets`, `dev-grafana`, `dev-calico`ê°€ OutOfSyncÂ·Missing. ëª¨ë“  ë…¸ë“œ `node.kubernetes.io/network-unavailable` taint ìœ ì§€. |
| 20:30 | `kubectl get application dev-calico -o yaml` | `operationState.message` = â€œwaiting for deletion of operator.tigera.io/Installation/defaultâ€. ArgoëŠ” tigera ë¦¬ì†ŒìŠ¤ë¥¼ pruneë§Œ ë°˜ë³µ. |
| 20:35~21:00 | SSA ë„ì… ì‹œë„<br>`kubectl get application dev-calico -o jsonpath='{.spec.syncPolicy.syncOptions}'` â†’ patchë¡œ `ServerSideApply=true` ì¶”ê°€ | Annotation 256KiB ì—ëŸ¬ëŠ” í•´ì†Œë˜ì—ˆìœ¼ë‚˜ ê¸°ì¡´ Installation CRì´ ì‚­ì œë˜ì§€ ì•Šì•„ ì—¬ì „íˆ â€œDeletion ëŒ€ê¸°â€ ìƒíƒœ. |
| 21:00 | `kubectl patch installation.operator.tigera.io default --type='json' -p='[{"op":"remove","path":"/metadata/finalizers/0"}]'` (ë‘ ë²ˆ) | `Installation/default` ì‚­ì œ ì„±ê³µ. ê·¸ëŸ¬ë‚˜ ê´€ë ¨ CRD(`installations.operator.tigera.io`, `apiservers.operator.tigera.io`) ë° Ansible ì”ì¡´ ë¦¬ì†ŒìŠ¤ ë•Œë¬¸ì— Argoê°€ ìƒˆ Syncë¥¼ ì‹œì‘í•˜ì§€ ëª»í•¨. |
| 21:10~21:40 | `kubectl delete crd installations.operator.tigera.io apiservers.operator.tigera.io` ë“± Calico CRD ì •ë¦¬ | ì œê±° ì™„ë£Œí–ˆìœ¼ë‚˜ Application OperationStateê°€ resetë˜ì§€ ì•Šì•„ ì»¨íŠ¸ë¡¤ëŸ¬ ì´ë²¤íŠ¸ê°€ ë” ì´ìƒ ê°±ì‹ ë˜ì§€ ì•ŠìŒ. `kubectl patch application dev-calico ... {"status":{"reconciledAt":null}}` í•„ìš”í–ˆìœ¼ë‚˜ ë„¤íŠ¸ì›Œí¬ ë¶ˆëŠ¥ìœ¼ë¡œ íš¨ê³¼ í™•ì¸ ë¶ˆê°€. |
| 21:45 ì´í›„ | `kubectl logs -n argocd argocd-application-controller-0` | PodëŠ” Runningì´ë‚˜ ë…¸ë“œ(10.0.3.88) kubelet í¬íŠ¸ ì—°ê²° ì‹¤íŒ¨ë¡œ ë¡œê·¸ ìˆ˜ì§‘ ì‹¤íŒ¨. ëª¨ë“  ë…¸ë“œê°€ `node.kubernetes.io/network-unavailable`ì´ë¼ Logging/PortForward ëª¨ë‘ ì°¨ë‹¨. |
| 22:00 | ê²°ë¡ : Calicoë¥¼ GitOps(Helm)ì—ì„œ ì œê±°í•˜ê³  Ansible Playbook(`04-cni-install.yml`)ë¡œë§Œ ì„¤ì¹˜Â·ìš´ì˜. GitOps ê²½ë¡œ(`clusters/dev/apps/05-calico.yaml`, `platform/helm/calico/**`) ì‚­ì œ. |

> ğŸ“Œ Calico/Tigera GitOps ì¶©ëŒ ì‚¬ë¡€, ì „ì²´ Application ë¦¬ìŠ¤íŠ¸, ì´ë²¤íŠ¸/describe ì¶œë ¥ì€ `docs/troubleshooting/CALICO_GITOPS_INCIDENT_2025-11-18.md` ë¬¸ì„œì—ì„œ í™•ì¸í•˜ì„¸ìš”. ì—¬ê¸°ì„œëŠ” ë‹¤ë¥¸ ì¦ìƒ ê³µí†µ ì ˆì°¨ë§Œ ìœ ì§€í•©ë‹ˆë‹¤.

---

## 6. Incident Log â€“ ALB 503 (TargetGroup empty) due to missing providerID (2025-12-09)

| ì‹œê°(KST) | Action | ê²°ê³¼/ë©”ì‹œì§€ |
|-----------|--------|-------------|
| ~10:00 | ì™¸ë¶€ 503 ë°œìƒ, `describe-target-health` ì „ë¶€ `[]` | ALBì—ëŠ” íƒ€ê²Ÿ ë¯¸ë“±ë¡ ìƒíƒœ |
| 10:05~10:20 | ì»¨íŠ¸ë¡¤ëŸ¬ ë¡œê·¸ í™•ì¸ | `Reconciler error â€¦ providerID is not specified for node: k8s-ingress-gateway` ë°˜ë³µ |
| 10:20 | `kubectl get nodes -o custom-columns=NAME,PID` | `k8s-ingress-gateway`, `k8s-master`ì— providerID ì—†ìŒ í™•ì¸ |
| 10:25 | ë…¸ë“œ ë©”íƒ€ë°ì´í„°ë¡œ patch | `kubectl patch node <node> -p '{"spec":{"providerID":"aws:///<az>/<instance-id>"}}'` |
| 10:30 | ALB ì»¨íŠ¸ë¡¤ëŸ¬ ì¬ì‹œì‘ í›„ TG í™•ì¸ | Targets ë“±ë¡, 503 í•´ì†Œ |

ìš”ì•½ ë° ì¬ë°œ ë°©ì§€
- ì›ì¸: ALB ì»¨íŠ¸ë¡¤ëŸ¬ íƒ€ê²Ÿ íƒ€ì… `instance` ì‚¬ìš© ì‹œ, providerID ì—†ëŠ” ë…¸ë“œê°€ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ TGB ë¦¬ì½˜ì‹¤ì´ ì‹¤íŒ¨í•˜ì—¬ íƒ€ê²Ÿì´ ë¹„ì–´ 503 ë°œìƒ.
- ì¡°ì¹˜: ë¬¸ì œ ë…¸ë“œ(providerID ì—†ìŒ)ë¥¼ `aws:///<AZ>/<INSTANCE_ID>`ë¡œ íŒ¨ì¹˜ í›„ ì»¨íŠ¸ë¡¤ëŸ¬ ì¬ì‹œì‘. í•„ìš” ì‹œ `scripts/utilities/fix-providerid.sh`ë¡œ ì¼ê´„ ì ìš©.
- ì˜ˆë°©: Ansible `03-1-set-provider-id.yml`ì˜ í•„í„°ì— `k8s-ingress-gateway`(ë° control-plane) í¬í•¨, ë˜ëŠ” Ingress `alb.ingress.kubernetes.io/target-type: ip`ë¡œ ì „í™˜í•˜ì—¬ providerID ì˜ì¡´ë„ ì œê±°(ë³´ì•ˆê·¸ë£¹ì€ Pod CIDR ê³ ë ¤).

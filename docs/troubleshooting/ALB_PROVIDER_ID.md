# ALB Controller Provider ID ë¬¸ì œ í•´ê²°

## ğŸ“Œ ë¬¸ì œ ìš”ì•½

**ì¦ìƒ**:
- ALBê°€ ìƒì„±ë˜ì—ˆì§€ë§Œ Target Groupì— Instanceê°€ ë“±ë¡ë˜ì§€ ì•ŠìŒ
- `https://growbin.app` ì ‘ì† ì‹œ `503 Service Unavailable` ë°œìƒ
- Ingressì˜ `ADDRESS` í•„ë“œê°€ ë¹„ì–´ìˆìŒ

**ì›ì¸**:
- Worker ë…¸ë“œì˜ `spec.providerID`ê°€ ë¶ˆì™„ì „í•˜ê²Œ ì„¤ì •ë¨
- í˜„ì¬ ê°’: `aws:///ap-northeast-2a/` (Instance ID ëˆ„ë½)
- í•„ìš”í•œ ê°’: `aws:///ap-northeast-2b/i-09bcfaaae046d7b4c`

---

## ğŸ” ë¬¸ì œ ë°œê²¬ ê³¼ì •

### 1. ALBëŠ” ìƒì„±ë˜ì—ˆì§€ë§Œ 503 ì—ëŸ¬ ë°œìƒ

```bash
$ curl -I https://growbin.app
HTTP/2 503
server: awselb/2.0
```

### 2. Target Groupì— Instanceê°€ ì—†ìŒ

```bash
$ aws elbv2 describe-target-health --target-group-arn <TG_ARN>
{
    "TargetHealthDescriptions": []
}
```

### 3. ALB Controller ë¡œê·¸ì—ì„œ ì—ëŸ¬ ë°œê²¬

```bash
$ kubectl logs -n kube-system deployment/aws-load-balancer-controller --tail=50 | grep error

{"level":"error","msg":"Reconciler error","error":"providerID is not specified for node: k8s-worker-1"}
{"level":"error","msg":"Reconciler error","error":"providerID is not specified for node: k8s-worker-2"}
{"level":"error","msg":"Reconciler error","error":"providerID is not specified for node: k8s-monitoring"}
```

### 4. ë…¸ë“œì˜ Provider ID í™•ì¸

```bash
$ kubectl get nodes -o custom-columns='NAME:.metadata.name,PROVIDER_ID:.spec.providerID'

NAME             PROVIDER_ID
k8s-master       <none>
k8s-monitoring   aws:///ap-northeast-2a/
k8s-postgresql   aws:///ap-northeast-2a/
k8s-rabbitmq     aws:///ap-northeast-2a/
k8s-redis        aws:///ap-northeast-2a/
k8s-worker-1     aws:///ap-northeast-2a/
k8s-worker-2     aws:///ap-northeast-2a/
```

**ë¬¸ì œ**: Instance IDê°€ ëˆ„ë½ë¨!

---

## âš ï¸ ì™œ ì´ ë¬¸ì œê°€ ë°œìƒí–ˆëŠ”ê°€?

### ê·¼ë³¸ ì›ì¸

**Ansible Worker Join Playbookì—ì„œ Provider ID ìë™ ì„¤ì •ì´ ëˆ„ë½ë¨**

`ansible/playbooks/03-worker-join.yml`ì—ì„œ Worker ë…¸ë“œê°€ í´ëŸ¬ìŠ¤í„°ì— joiní•œ í›„, kubeletì˜ Provider IDë¥¼ ì„¤ì •í•˜ëŠ” ë¡œì§ì´ ì—†ì—ˆìŠµë‹ˆë‹¤.

### Provider IDê°€ ì¤‘ìš”í•œ ì´ìœ 

AWS Load Balancer ControllerëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê³¼ì •ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤:

1. Ingress ë¦¬ì†ŒìŠ¤ë¥¼ ê°ì§€
2. Serviceì˜ NodePort í™•ì¸
3. **ê° ë…¸ë“œì˜ `spec.providerID`ì—ì„œ AWS Instance ID ì¶”ì¶œ**
4. ALB Target Groupì— Instance ë“±ë¡

**Provider IDê°€ ë¶ˆì™„ì „í•˜ë©´ 3ë²ˆ ë‹¨ê³„ì—ì„œ Instance IDë¥¼ ì°¾ì§€ ëª»í•˜ê³ , Target ë“±ë¡ì´ ì‹¤íŒ¨í•©ë‹ˆë‹¤.**

---

## âœ… í•´ê²° ë°©ë²•

### Option 1: ìˆ˜ë™ ìˆ˜ì • (í˜„ì¬ í´ëŸ¬ìŠ¤í„°)

#### ê° Worker ë…¸ë“œì—ì„œ ì§ì ‘ ìˆ˜ì •:

```bash
# Worker ë…¸ë“œ SSH ì ‘ì†
ssh ubuntu@<WORKER_NODE_IP>

# 1. kubelet ì¤‘ì§€
sudo systemctl stop kubelet

# 2. kubeadm-flags.env ë°±ì—…
sudo cp /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/kubeadm-flags.env.bak

# 3. Provider ID ì¶”ê°€
# Instance IDì™€ AZë¥¼ ì‹¤ì œ ê°’ìœ¼ë¡œ ë³€ê²½
sudo sed -i 's/"$/ --cloud-provider=external --provider-id=aws:\/\/\/ap-northeast-2b\/i-09bcfaaae046d7b4c"/' /var/lib/kubelet/kubeadm-flags.env

# 4. ìˆ˜ì •ëœ ë‚´ìš© í™•ì¸
cat /var/lib/kubelet/kubeadm-flags.env

# 5. kubelet ì¬ì‹œì‘
sudo systemctl start kubelet
sudo systemctl status kubelet
```

#### ëª¨ë“  Worker ë…¸ë“œ ì •ë³´:

| Node Name       | Instance ID         | Availability Zone | Private IP  |
|-----------------|---------------------|-------------------|-------------|
| k8s-worker-1    | i-09bcfaaae046d7b4c | ap-northeast-2b   | 10.0.2.57   |
| k8s-worker-2    | i-05a8ef39f9a7c8973 | ap-northeast-2c   | 10.0.3.125  |
| k8s-rabbitmq    | i-039672e9dbef43093 | ap-northeast-2a   | 10.0.1.146  |
| k8s-postgresql  | i-08f64b8d6e8ca0a22 | ap-northeast-2b   | 10.0.2.134  |
| k8s-redis       | i-049ff392632813341 | ap-northeast-2c   | 10.0.3.175  |
| k8s-monitoring  | i-0956fd40bdaaaaf80 | ap-northeast-2b   | 10.0.2.243  |

### Option 2: Ansible Playbook ìˆ˜ì • (ê·¼ë³¸ í•´ê²°)

**`ansible/playbooks/03-worker-join.yml` ìˆ˜ì • ì™„ë£Œ!**

Worker join í›„ ìë™ìœ¼ë¡œ Provider IDë¥¼ ì„¤ì •í•˜ë„ë¡ ë‹¤ìŒ ë¡œì§ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤:

```yaml
# Provider ID ì„¤ì • (AWS ALB Controller í•„ìˆ˜)
- name: AWS Instance ID ë° AZ ê°€ì ¸ì˜¤ê¸°
  shell: |
    INSTANCE_ID=$(ec2-metadata --instance-id | cut -d ' ' -f 2)
    AZ=$(ec2-metadata --availability-zone | cut -d ' ' -f 2)
    echo "$INSTANCE_ID:$AZ"
  register: aws_metadata
  when: not kubelet_conf.stat.exists

- name: Provider ID íŒŒì‹±
  set_fact:
    instance_id: "{{ aws_metadata.stdout.split(':')[0] }}"
    availability_zone: "{{ aws_metadata.stdout.split(':')[1] }}"
  when: not kubelet_conf.stat.exists and aws_metadata is defined

- name: kubelet Provider ID ì„¤ì •
  lineinfile:
    path: /var/lib/kubelet/kubeadm-flags.env
    regexp: '^KUBELET_KUBEADM_ARGS='
    line: 'KUBELET_KUBEADM_ARGS="--container-runtime-endpoint=unix:///var/run/containerd/containerd.sock --cloud-provider=external --provider-id=aws:///{{ availability_zone }}/{{ instance_id }}"'
    backup: yes
  when: not kubelet_conf.stat.exists and instance_id is defined
  notify: restart kubelet

- name: kubelet ì¬ì‹œì‘ (Provider ID ì ìš©)
  systemd:
    name: kubelet
    state: restarted
  when: not kubelet_conf.stat.exists and instance_id is defined
```

---

## ğŸ”„ ë‹¤ìŒ ë°°í¬ ì‹œ ìë™ ì ìš©

ë‹¤ìŒ í´ëŸ¬ìŠ¤í„° ì¬êµ¬ì¶• ì‹œ Provider IDê°€ ìë™ìœ¼ë¡œ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë©ë‹ˆë‹¤:

```bash
./scripts/cluster/build-cluster.sh
```

**í™•ì¸ ë°©ë²•**:

```bash
# Master ë…¸ë“œ ì ‘ì†
ssh ubuntu@<MASTER_IP>

# Provider ID í™•ì¸
kubectl get nodes -o custom-columns='NAME:.metadata.name,PROVIDER_ID:.spec.providerID'

# ì˜ˆìƒ ê²°ê³¼:
# NAME             PROVIDER_ID
# k8s-worker-1     aws:///ap-northeast-2b/i-09bcfaaae046d7b4c
# k8s-worker-2     aws:///ap-northeast-2c/i-05a8ef39f9a7c8973
# ...
```

---

## ğŸ“Š Target ë“±ë¡ í™•ì¸

Provider ID ìˆ˜ì • í›„ ì•½ 30ì´ˆ ì´ë‚´ì— ALB Controllerê°€ ìë™ìœ¼ë¡œ Targetì„ ë“±ë¡í•©ë‹ˆë‹¤.

```bash
# TargetGroupBinding ìƒíƒœ í™•ì¸
kubectl get targetgroupbinding -A

# Target Health í™•ì¸
aws elbv2 describe-target-health \
  --region ap-northeast-2 \
  --target-group-arn <TG_ARN>

# ì˜ˆìƒ ê²°ê³¼:
# {
#     "TargetHealthDescriptions": [
#         {
#             "Target": {
#                 "Id": "i-09bcfaaae046d7b4c",
#                 "Port": 31493
#             },
#             "HealthCheckPort": "31493",
#             "TargetHealth": {
#                 "State": "healthy"
#             }
#         }
#     ]
# }
```

---

## ğŸš¨ ì¶”ê°€ë¡œ í™•ì¸í•´ì•¼ í•  ì‚¬í•­

### 1. IAM ê¶Œí•œ

ALB Controllerê°€ ì‘ë™í•˜ë ¤ë©´ ë‹¤ìŒ IAM ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤:

```json
{
  "Effect": "Allow",
  "Action": [
    "elasticloadbalancing:AddTags",
    "elasticloadbalancing:DescribeListenerAttributes",
    "elasticloadbalancing:CreateTargetGroup",
    "elasticloadbalancing:RegisterTargets",
    "elasticloadbalancing:DeregisterTargets"
  ],
  "Resource": "*"
}
```

**ì´ë¯¸ ìˆ˜ì • ì™„ë£Œ**: `terraform/alb-controller-iam.tf`

### 2. Service íƒ€ì…

Ingressì˜ backend ServiceëŠ” ë°˜ë“œì‹œ `NodePort` ë˜ëŠ” `LoadBalancer` íƒ€ì…ì´ì–´ì•¼ í•©ë‹ˆë‹¤.

```bash
# Service íƒ€ì… í™•ì¸
kubectl get svc -A | grep -E "NodePort|LoadBalancer"

# Service íƒ€ì… ë³€ê²½ (í•„ìš”ì‹œ)
kubectl patch svc <SERVICE_NAME> -n <NAMESPACE> -p '{"spec":{"type":"NodePort"}}'
```

**ì´ë¯¸ ìˆ˜ì • ì™„ë£Œ**:
- `argocd-server`: NodePort (31441)
- `prometheus-grafana`: NodePort (31371)
- `default-backend`: NodePort (31493)

### 3. Security Group

Worker ë…¸ë“œì˜ Security Groupì—ì„œ ALBë¡œë¶€í„°ì˜ Ingressë¥¼ í—ˆìš©í•´ì•¼ í•©ë‹ˆë‹¤.

```bash
# ALB Security Group ID í™•ì¸
aws elbv2 describe-load-balancers \
  --region ap-northeast-2 \
  --query 'LoadBalancers[0].SecurityGroups[]' \
  --output text

# Worker Security Groupì— Ingress ê·œì¹™ ì¶”ê°€ (Terraformìœ¼ë¡œ ê´€ë¦¬ë¨)
```

**ì´ë¯¸ ì„¤ì • ì™„ë£Œ**: Terraformì—ì„œ ìë™ìœ¼ë¡œ ALB SG â†’ Worker SG Ingress ê·œì¹™ ìƒì„±

---

## ğŸ“ ê´€ë ¨ íŒŒì¼

- **Ansible Playbook**: `ansible/playbooks/03-worker-join.yml`
- **IAM Policy**: `terraform/alb-controller-iam.tf`
- **Ingress ì„¤ì •**: `ansible/playbooks/07-ingress-resources.yml`
- **Build Script**: `scripts/cluster/build-cluster.sh`

---

## ğŸ¯ ìš”ì•½

| í•­ëª© | ë¬¸ì œ | í•´ê²° |
|------|------|------|
| **Provider ID** | Instance ID ëˆ„ë½ | Ansible playbook ìˆ˜ì • ì™„ë£Œ |
| **IAM ê¶Œí•œ** | AddTags, DescribeListenerAttributes ëˆ„ë½ | IAM policy ì—…ë°ì´íŠ¸ ì™„ë£Œ |
| **Service íƒ€ì…** | ClusterIPë¡œ ì„¤ì •ë¨ | NodePortë¡œ ìˆ˜ë™ ë³€ê²½ ì™„ë£Œ |
| **Route53 DNS** | Master Node IPë¥¼ ê°€ë¦¬í‚´ | ALB DNSë¡œ ì—…ë°ì´íŠ¸ ì™„ë£Œ |

**ë‹¤ìŒ ë°°í¬ë¶€í„°ëŠ” ëª¨ë“  ì„¤ì •ì´ ìë™ìœ¼ë¡œ ì˜¬ë°”ë¥´ê²Œ ì ìš©ë©ë‹ˆë‹¤.** âœ…

---

## ğŸ“š ì°¸ê³  ìë£Œ

- [AWS Load Balancer Controller ê³µì‹ ë¬¸ì„œ](https://kubernetes-sigs.github.io/aws-load-balancer-controller/)
- [Kubernetes Provider ID ë¬¸ì„œ](https://kubernetes.io/docs/concepts/architecture/nodes/#provider-id)
- [kubeadm ì™¸ë¶€ Cloud Provider ì„¤ì •](https://kubernetes.io/docs/tasks/administer-cluster/running-cloud-controller/)


# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# Chat Worker KEDA ScaledObject
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# RabbitMQ Queue 길이 기반 오토스케일링 (chat.process 큐)
# TaskIQ Worker의 처리량에 맞춰 동적으로 Pod 수 조절
#
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# 리소스 계산 (k8s-worker-ai: t3.small, 2 vCPU, 3.7GB)
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# - 노드 Allocatable: 2000m CPU, 3826Mi Memory
# - 시스템 Pods (DaemonSets): ~330m CPU, ~200Mi Memory
# - 가용 리소스: ~1670m CPU, ~3600Mi Memory
# - chat-worker 1개: 500m CPU (limit), 1Gi Memory
# - scan-worker와 공유: 최대 4개 (scan + chat 합산)
# ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: chat-worker-scaledobject
  labels:
    app: chat-worker
spec:
  scaleTargetRef:
    name: chat-worker
    kind: Deployment
  # 스케일링 범위
  minReplicaCount: 1    # E2E 테스트용 (부하테스트 후 2로 조정)
  maxReplicaCount: 4    # 노드 리소스 기반 (scan-worker와 공유)
  # 쿨다운 기간 (스케일다운 전 최소 대기 시간)
  cooldownPeriod: 300   # 5분 (LLM 처리 시간 고려)
  # 폴링 간격
  pollingInterval: 30   # 30초마다 큐 길이 확인
  # Fallback: 메트릭 실패 시 기본 replicas 유지
  fallback:
    failureThreshold: 3
    replicas: 1
  # 고급 설정
  advanced:
    restoreToOriginalReplicaCount: false
    horizontalPodAutoscalerConfig:
      behavior:
        scaleDown:
          stabilizationWindowSeconds: 300  # 5분 안정화
          policies:
          - type: Percent
            value: 50
            periodSeconds: 60
        scaleUp:
          stabilizationWindowSeconds: 0    # 즉시 스케일업
          policies:
          - type: Pods
            value: 2
            periodSeconds: 30
  triggers:
  # RabbitMQ HTTP API 트리거 (chat.process)
  # HTTP 프로토콜: ready + unacked 메시지 수 모니터링
  - type: rabbitmq
    metadata:
      protocol: http
      host: http://admin:admin123@eco2-rabbitmq.rabbitmq.svc.cluster.local:15672
      queueName: chat.process
      vhostName: eco2
      mode: QueueLength    # messages (ready + unacked)
      value: '5'           # 5개 이상 → 스케일업 (LLM은 처리 시간이 김)

# Core Infrastructure Alerts
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: eco2-core-alerts
  namespace: prometheus
  labels:
    release: kube-prometheus-stack
    app: kube-prometheus-stack
spec:
  groups:
    # ===========================================
    # ðŸ”´ CRITICAL - Pod ìž¥ì• 
    # ===========================================
  - name: pod-critical
    rules:
    - alert: PodCrashLoopBackOff
      expr: |
        increase(kube_pod_container_status_restarts_total[15m]) > 3
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: Pod {{ $labels.namespace }}/{{ $labels.pod }} is crash looping
        description: Pod {{ $labels.pod }} in namespace {{ $labels.namespace }} has restarted {{ $value }} times in the last 15 minutes.

    - alert: PodOOMKilled
      expr: |
        kube_pod_container_status_last_terminated_reason{reason="OOMKilled"} == 1
      for: 0m
      labels:
        severity: critical
      annotations:
        summary: Pod {{ $labels.namespace }}/{{ $labels.pod }} was OOMKilled
        description: Container {{ $labels.container }} in pod {{ $labels.pod }} was terminated due to OOM (Out of Memory).

    - alert: PodNotReady
      expr: |
        kube_pod_status_ready{condition="false"} == 1
      for: 10m
      labels:
        severity: warning
      annotations:
        summary: Pod {{ $labels.namespace }}/{{ $labels.pod }} is not ready
        description: Pod {{ $labels.pod }} has been in a non-ready state for more than 10 minutes.

    # ===========================================
    # ðŸ”´ CRITICAL - Node ìž¥ì• 
    # ===========================================
  - name: node-critical
    rules:
    - alert: NodeNotReady
      expr: |
        kube_node_status_condition{condition="Ready",status="true"} == 0
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: Node {{ $labels.node }} is not ready
        description: Node {{ $labels.node }} has been unready for more than 5 minutes.

    - alert: NodeMemoryPressure
      expr: |
        kube_node_status_condition{condition="MemoryPressure",status="true"} == 1
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: Node {{ $labels.node }} has memory pressure
        description: Node {{ $labels.node }} is under memory pressure.

    - alert: NodeDiskPressure
      expr: |
        kube_node_status_condition{condition="DiskPressure",status="true"} == 1
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: Node {{ $labels.node }} has disk pressure
        description: Node {{ $labels.node }} is under disk pressure.

    # ===========================================
    # ðŸŸ  WARNING - ë¦¬ì†ŒìŠ¤ ìž„ê³„ì¹˜
    # ===========================================
  - name: resource-warnings
    rules:
    - alert: HighCPUUsage
      expr: |
        100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: High CPU usage on {{ $labels.instance }}
        description: 'CPU usage is above 80% (current: {{ $value | printf "%.1f" }}%) on {{ $labels.instance }}.'

    - alert: HighMemoryUsage
      expr: |
        (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: High memory usage on {{ $labels.instance }}
        description: 'Memory usage is above 85% (current: {{ $value | printf "%.1f" }}%) on {{ $labels.instance }}.'

    - alert: HighDiskUsage
      expr: |
        (1 - (node_filesystem_avail_bytes{fstype!~"tmpfs|overlay"} / node_filesystem_size_bytes{fstype!~"tmpfs|overlay"})) * 100 > 80
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: High disk usage on {{ $labels.instance }}
        description: 'Disk usage is above 80% (current: {{ $value | printf "%.1f" }}%) on {{ $labels.instance }} mount {{ $labels.mountpoint }}.'

    # ===========================================
    # ðŸŸ  WARNING - Elasticsearch
    # ===========================================
  - name: elasticsearch-alerts
    rules:
    - alert: ElasticsearchHighMemory
      expr: |
        (container_memory_usage_bytes{namespace="logging", pod=~"eco2-logs-es.*"} / container_spec_memory_limit_bytes{namespace="logging", pod=~"eco2-logs-es.*"}) * 100 > 80
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: Elasticsearch memory usage high
        description: 'Elasticsearch pod {{ $labels.pod }} memory usage is above 80% (current: {{ $value | printf "%.1f" }}%).'

    - alert: ElasticsearchClusterHealth
      expr: |
        elasticsearch_cluster_health_status{color="red"} == 1
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: Elasticsearch cluster health is RED
        description: Elasticsearch cluster health status is RED. Immediate attention required.

    - alert: ElasticsearchClusterYellow
      expr: |
        elasticsearch_cluster_health_status{color="yellow"} == 1
      for: 15m
      labels:
        severity: warning
      annotations:
        summary: Elasticsearch cluster health is YELLOW
        description: Elasticsearch cluster health status is YELLOW for more than 15 minutes.

    # ===========================================
    # ðŸ”´ CRITICAL - Database ì—°ê²°
    # ===========================================
  - name: database-critical
    rules:
    - alert: RedisDown
      expr: |
        up{job=~".*redis.*"} == 0
      for: 1m
      labels:
        severity: critical
      annotations:
        summary: Redis is down
        description: Redis instance {{ $labels.instance }} is not responding.

    - alert: RedisMemoryHigh
      expr: |
        redis_memory_used_bytes / redis_memory_max_bytes > 0.9
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: Redis memory usage is high
        description: Redis {{ $labels.redis_cluster }} memory usage is above 90% (current {{ $value | printf "%.1f" }}%).

    - alert: RedisSentinelDown
      expr: |
        redis_sentinel_masters < 1
      for: 1m
      labels:
        severity: critical
      annotations:
        summary: Redis Sentinel has no masters
        description: Redis Sentinel {{ $labels.instance }} cannot find any master.

    - alert: RedisReplicationBroken
      expr: |
        redis_connected_slaves == 0 and redis_instance_info{role="master"} == 1
      for: 2m
      labels:
        severity: critical
      annotations:
        summary: Redis replication is broken
        description: Redis master {{ $labels.redis_cluster }} has no connected slaves.

    - alert: RedisConnectionsHigh
      expr: |
        redis_connected_clients > 1000
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: Redis has too many connections
        description: Redis {{ $labels.redis_cluster }} has {{ $value }} connected clients.

    - alert: PostgreSQLDown
      expr: |
        up{job=~".*postgres.*"} == 0
      for: 1m
      labels:
        severity: critical
      annotations:
        summary: PostgreSQL is down
        description: PostgreSQL instance {{ $labels.instance }} is not responding.

    # ===========================================
    # ðŸŸ  WARNING - ArgoCD
    # ===========================================
  - name: argocd-alerts
    rules:
    - alert: ArgoCDSyncFailed
      expr: |
        argocd_app_info{sync_status="OutOfSync"} == 1
      for: 10m
      labels:
        severity: warning
      annotations:
        summary: ArgoCD app {{ $labels.name }} is out of sync
        description: Application {{ $labels.name }} has been out of sync for more than 10 minutes.

    - alert: ArgoCDAppDegraded
      expr: |
        argocd_app_info{health_status="Degraded"} == 1
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: ArgoCD app {{ $labels.name }} is degraded
        description: Application {{ $labels.name }} health status is Degraded.

    # ===========================================
    # ðŸŸ  WARNING - TLS Certificate
    # ===========================================
  - name: certificate-alerts
    rules:
    - alert: TLSCertificateExpiringSoon
      expr: |
        (certmanager_certificate_expiration_timestamp_seconds - time()) / 86400 < 7
      for: 1h
      labels:
        severity: warning
      annotations:
        summary: TLS certificate expiring soon
        description: Certificate {{ $labels.name }} in namespace {{ $labels.namespace }} will expire in {{ $value | printf "%.0f" }} days.
